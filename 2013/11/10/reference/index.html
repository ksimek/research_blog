
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
<head>
   <meta http-equiv="content-type" content="text/html; charset=utf-8" />
   <title>Gradient w.r.t. Indices &larr; </title>
   <meta name="author" content="Kyle Simek" />

   <link rel="start" href="/ksimek/research/" />

	
	
    <link rel="shortcut icon" href="/ksimek/research/favicon.ico">

	
	

   <!-- syntax highlighting CSS -->
   <link rel="stylesheet" href="/ksimek/research/assets/themes/mark-reid/css/syntax.css" type="text/css" />

   <!-- Jquery UI CSS --!>
   <link media="screen" rel="stylesheet" href="/ksimek/research/css/ui-smoothness/jquery-ui-1.8.22.custom.css" type="text/css" />

   <!-- Homepage CSS -->
   <link media="screen" rel="stylesheet" href="/ksimek/research/assets/themes/mark-reid/css/screen.css" type="text/css" />

   <!-- Handheld CSS -->
   <link media="handheld, only screen and (max-width: 480px), only screen and (max-device-width: 480px)" href="/ksimek/research/assets/themes/mark-reid/css/handheld.css" type="text/css" rel="stylesheet" />


<!--[if IEMobile]>
<link rel="stylesheet" type="text/css" href="/ksimek/research/assets/themes/mark-reid/css/handheld.css" media="screen" />
<![endif]-->

   <!-- Mathjax Javascript -->
   <script type="text/javascript"
     src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
   </script>

   <!-- three.js Javascript -->
    <script src="/ksimek/research/js/jquery.js"></script>
    <script src="/ksimek/research/js/jquery-ui-1.8.22.custom.min.js"></script>

    

    <script type="text/javascript">
        $(document).ready(function(){
                $('#javascript_error').hide();
        });
    </script>



</head>
<body id="">
<div id="site">
  
  <div id="header">
    <h1>
    	<a href="/ksimek/research/" title="KLS Research Blog">KLS Research Blog</a>
    	<span class="byline">&larr; <a href="/ksimek/research/">Nothing to see here...</a></span>
    </h1>
    <ul class="nav">
      <li><a class="home" href="/ksimek/research/">Home</a></li>
      <li><a href="/ksimek/research/about.html">About</a></li>
      <li><a href="/ksimek/research/contact.html">Contact</a></li>
      <li><a  href="/ksimek/research/archive.html">Archive</a></li>
      <li><a  href="/ksimek/research/categories.html">Categories</a></li>
      <li><a  href="/ksimek/research/projects">Projects</a></li>
      <li><a  href="/ksimek/research/events">Events</a></li>
      <li><a  href="/ksimek/research/feeds.html"><img src="/ksimek/research/img/feed-icon.gif" /></a></li> 

    </ul>
  </div>


  
<div id="page" class="article">
	
  
  
    


  <h1 class="title">
        [Reference] Gradient w.r.t. Indices
    </h1>

  <div class="date emphnext">November 10, 2013</div>
    


  
    <p>To optimize indices, we'll need to compute the derivative of the marginal log-likelihood w.r.t. changing indices.</p>

<p>I first tried to derive this using the generalization of the chain rule to matrix expressions (see matrix cookbook, section 2.8.1), but the computation exploded.  Since ultimately, the derivative is a simple single-input, single output function, we can use differentials to derive the solution.</p>

<p>Let the marginal likelihood as a function of indices be \(g(x)\):</p>

<div>
\[
    \frac{\partial g(x)}{\partial x_i} = \frac{\partial}{\partial x_i} 
        \frac{1}{2}(-y^\top S^\top ( I + S K(x) S^\top)^{-1} S y)
\]

Let \(U = I + S K(x) S^\top\), and \(V = U^{-1}\).  Working inside out, lets find \(\frac{\partial U}{\partial x_i}\).

\[
\begin{align}
    U + dU  &= I + S (K + dK) S ^\top \\
            &= I + S K S^\top + S dK S ^\top \\
        dU  &= S \, dK\, S^\top \\
        U'  &= S K' S^\top
\end{align}
\]

Where \(M'\) is the derivative of the elements of \(M\) w.r.t. \(x_i\).  Next, \(\frac{\partial V}{\partial x_i}\), which comes from the matrix cookbook, equation (36).

\[
    dV = -U^{-1} \, dU \, U^{-1} \\
    V' = -U^{-1} U' U^{-1}
\]

Finally,  \(\frac{\partial g(x)}{\partial x_i}\):
    
\[
\begin{align}
    g + dg  &= -\frac{1}{2}y^\top S^\top (V + dV) S y \\
    g + dg  &= -\frac{1}{2}y^\top S^\top \, V \, S y - \frac{1}{2} y^\top S^\top \,dV \,S y \\
        dg  &= -\frac{1}{2}y^\top S^\top \,dV \,S y \\
        g'  &= -\frac{1}{2}y^\top S^\top \, V' \,S y \\
\end{align}
\]

Expanding \(V\) gives the final formula:
\[
\begin{align}
        g'  &= \frac{1}{2}y^\top S^\top U^{-1} S K' S^\top U^{-1} S y \\
        g'  &= \frac{1}{2}y^\top M K' M y \\
        g'  &= \frac{1}{2}z^\top K' z \tag{1}\\
\end{align}
\]

<p>
Here, \(M = S^\top U^{-1} S \), (which is symmetric), and \(z = M y\).  
</p>

<p>
This equation gives us a single element of the gradient, namely \(d g(x)/dx_i\).  However, once \(z\) is computed, we can reuse it  when recomputing (1) for all other \(x_j\)'s.  The cost of each subsequent gradient element becomes \(O(n^2)\), making the total gradient \(O(n^3)\), which is pretty good. (This assumes the K's can be computed efficiently, which is true; see below.)  However, we also observe that \(K'\) is sparse with size \(O(n)\), so we can do sparse multiplication to reduce the running time to linear, and <strong>the full gradient takes \(O(n^2)\)</strong>, assuming \(z\) is precomputed.  Cool! 
</p>

</div>


<p></p>


<h2>Derivatives of K(x)</h2>

<p>First, we'll layout the general form of K', whose elements are the full derivative of the kernel w.r.t.  \(x_k\).</p>

<div>
\[
\frac{\partial K_{ij}}{\partial x_k} = \frac{\partial k(x_i, x_j)}{\partial x_i} \frac{d x_i}{d x_k} + \frac{\partial k(x_i, x_j)}{\partial x_j} \frac{d x_j}{d x_k}\\
\]
</div>


<p>The first term is nonzero only on the i-th row of K', and the second term is nonzero on the i-th column of K'.  This suggests the following convenient sparse representation  for K'.</p>

<p>Let the vector \(\delta_i\)  be the vector whose j-th element is \( \frac{\partial k(x_i, x_j) }{\partial x_i} \).  Using this notation, we can rewrite \(K'\) as</p>

<div>
\[
    \frac{\partial K}{\partial x_i} = K' = C + C^\top  \tag{4}
\]
</div>


<p>where \(C = \left(0 \, \dots \, \delta_i \, \dots \, 0 \right)  \).</p>

<p>Below we derive the derivative \(\frac{\partial k(x_i, x_j)}{\partial x_i}\) for each of the three covariance expresssions.</p>

<p><em>Cubic covariance</em></p>

<p>Recall the cubic covariance expression:</p>

<div>
\[
k(x_i, x_j) = (x_a - x_b) x_b^2 / 2 + x_b^3/3
\]

Where \(x_b = min(x_i, x_i)\) and \(x_a = max(x_i, x_i)\).
</div>


<p>Taking the derivative w.r.t. (x_i) gives:</p>

<div>
\[
\begin{align}
\frac{\partial k(x_i, x_j)}{\partial x_i} &= 
    \begin{cases}
         x_j^2 / 2 & \text{if } x_i >= x_j \\
         x_i x_j - x_i^2/2 & \text{if } x_i < x_i
    \end{cases} \\
            &= 
    \begin{cases}
         x_b^2 / 2 & \text{if } x_i >= x_j \\
         x_a x_b - x_b^2/2 & \text{if } x_i < x_j
    \end{cases} \\
\end{align}
\]
</div>


<p>Or equivalently</p>

<div>
\[
\frac{\partial k(x_i, x_j)}{\partial x_i} = 
         x_b \left ( x_j  - x_b/2 \right ) \tag{2}
\]
</div>


<p><em>Linear Covariance</em></p>

<p>Recall the linear covariance expression:</p>

<div>
\[
k(x_i, x_j) = x_i x_j
\]

The derivative w.r.t. \(x_i\) is simply \(x_j\).

</div>


<p><em>Offset Covariance</em></p>

<p>Recall the offset covariance expression:</p>

<div>
\[
k(x_i, x_j) = k
\]

The derivative w.r.t. \(x_i\) is zero.
</div>


<p><em>Implementation</em></p>

<p>Implemented end-to-end version in <code>kernel/get_model_kernel_derivative.m</code>; see also components in <code>kernel/get_spacial_kernel_derivative.m</code> and <code>kernel/cubic_kernel_derivative.m</code>.</p>

<p>These functions return all of the partial derivatives of the matrix with respect to the first input.   The i-th row of the result make up the nonzero values in \(\frac{\partial K}{\partial x_i}\).  Below is example code that computes all of the partial derivative matrices.</p>

<pre><code>N = 100;
% construct indices
x = linspace(0, 10, N);
% construct derivative rows
d_kernel = get_model_kernel_derivative(...);
d_K = eval_kernel(d_kernel, x, x);
% construct dK/dx_i, for each i = 1..N
d_K_d_x = dcell(1,N);
for i = 1:N
    tmp = sparse(N, N);
    tmp(i,:) = d_K(i,:);
    tmp(:,i) = d_K(i,:)';
    d_K_d_x{i} = tmp;
end
</code></pre>

<p><em>Directional Derivatives</em></p>

<p>I think we can get directional derivatives of \(K\) by taking the weighted sum of partial derivatives, where the weights are the component lengths of the direction vector.  I have yet to confirm this beyond a hand-wavy hunch, and in practice, this might not even be needed, since computing the full gradient is so efficient.</p>

<h2>Full gradient</h2>

<p>As we saw earlier, \(\frac{\partial K}{\partial x_i}\) is sparse, and has the form in equation (4).  We can use the sparsity to ultimately compute the entire gradient in a single matrix multiplication.</p>

<p>First we'll rewrite \(g'\) in terms if \(\delta_i\)</p>

<div>
\[
\begin{align}
g' &= \frac{1}{2} z^\top K' z \\
   &= \frac{1}{2} z^\top C z + z^\top C^\top z \\
   &= \frac{1}{2} \left \{ (0 \, \dots \, z^\top \delta_i \, \dots \, 0) z + z^\top (0 \, \dots \, \delta_i^\top z \, \dots \, 0)^\top \right \} \\
   &= z_i (\delta_i \cdot z)
\end{align}
\]
</div>


<p>We can generalize this to the entire gradient using matrix operations:</p>

<div>
\[
\begin{align}
    \nabla g = z \odot (\Delta z) \tag{4}
\end{align}
\]

</div>


<p>Where \(\Delta\) is the matrix whose ith row is \(\delta_i\), and \(\odot\) denotes element-wise multiplication.</p>

<p>To handle multiple dimensions, simply apply to each dimension independently and sum the results.</p>

      <address class="signature">
        Posted by
        <a class="author" href="/ksimek/research/">Kyle Simek</a> 
      </address>
  


  
  
  <div class="prev-next">
    <a href="/ksimek/research/2013/11/10/work-log" class="next" title="Work Log">Work Log &rarr;</a>
  
  
    <a href="/ksimek/research/2013/11/08/meeting-notes" class="prev" title="iPlant Literature Review Planning Meetings">&larr; iPlant Literature Review Planning Meetings</a>
  
  </div>
  <div class="clearer"> </div>

<div class="post-sharing">
 

</div>




  <div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_developer = 1;
    var disqus_shortname = 'klsresearch'; // required: replace example with your forum shortname
    
    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">blog comments powered by <span class="logo-disqus">Disqus</span></a>




  
</div><!-- End Page -->



  
  <div id="footer">
  	<address>
  		<span class="copyright">
  			Content by <a href="/ksimek/research/about.html">Kyle Simek</a>. Original design by 
  			<a href="http://mark.reid.name/">Mark Reid</a>
  			<br/>
  			(<a rel="licence" href="http://creativecommons.org/licenses/by-nc-sa/3.0/">Some rights reserved</a>)			
  		</span>
  		<span class="engine">
  			Powered by <a href="http://github.com/mojombo/jekyll/" title="A static, minimalist CMS">Jekyll</a>
  		</span>
  	</address>
  </div>
  
</div>

<!--[if IE 6]>
<script type="text/javascript"> 
	/*Load jQuery if not already loaded*/ if(typeof jQuery == 'undefined'){ document.write("<script type=\"text/javascript\"   src=\"http://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js\"></"+"script>"); var __noconflict = true; } 
	var IE6UPDATE_OPTIONS = {
		icons_path: "http://static.ie6update.com/hosted/ie6update/images/"
	}
</script>
<script type="text/javascript" src="http://static.ie6update.com/hosted/ie6update/ie6update.js"></script>
<![endif]-->

  


  <script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-33692744-2']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>




</body>
</html>

