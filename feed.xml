<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>KLS Research Blog</title>
		<description>Nothing to see here...</description>
		<link>http://vision.sista.arizona.edu/ksimek/research</link>
		<atom:link href="http://vision.sista.arizona.edu/ksimek/research/feed.xml" rel="self" type="application/rss+xml" />
		
			<item>
				<title>Work Log - KJB EM GMM</title>
				<description>&lt;p&gt;Still struggling with the EM GMM algorithm.  Found/fixed one bug where responsibilities aren't initialized if NULL is passed to the function.&lt;/p&gt;

&lt;p&gt;Ran overnight and it hadn't finished at the end.  Found/fixed a bug where the entire @M element responsibility matrix is rescaled 2M times (once per point).&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Getting rank-deficient errors.  Looks like this is a result of the huge dataset; covariance matrix is divided by 1e6 (the number of soft-members of the cluster).&lt;/p&gt;

&lt;p&gt;For now, hack by trying to thin the dataset.  Long-term, adding a minimum offset to the emperical covariance seems to be the common solution.&lt;/p&gt;

&lt;p&gt;Possibly normalizing the data would be good.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Added offset to covariance (command-line options and file-static variable already existed, just needed to add it to the full_GMM logic).&lt;/p&gt;

&lt;p&gt;Added &lt;code&gt;read_gmm.m&lt;/code&gt; matlab routine, and plotted along with scatter plot of data.  Results look pretty good:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ksimek/research/img/2013-10-20-kjb-gmm-result.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Moving trained gmm to ~/data/arabidopsis/training/bd_likelihood_gmm/blur_2.0.gmm&lt;/p&gt;

&lt;hr /&gt;

&lt;h2&gt;TODO&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;increase spacing between reconstructed points&lt;/li&gt;
&lt;li&gt;get this running on cuda server&lt;/li&gt;
&lt;li&gt;re-train GMM on held-out dataset.&lt;/li&gt;
&lt;li&gt;implement matlab likelihood sampling&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;Open issues&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;how to sync datasets on matlab and c++ server?&lt;/li&gt;
&lt;li&gt;Wacv multi-view reconstruction for training&lt;/li&gt;
&lt;li&gt;saving wacv to files for training&lt;/li&gt;
&lt;li&gt;fixing issues in wacv reconstructions&lt;/li&gt;
&lt;li&gt;evaluation methodology&lt;/li&gt;
&lt;li&gt;split/merge&lt;/li&gt;
&lt;/ul&gt;

</description>
				<pubDate>Sun, 20 Oct 2013 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2013/10/20/work-log</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2013/10/20/work-log</guid>
			</item>
		
			<item>
				<title>Work Log</title>
				<description>&lt;h2&gt;Training likelihood&lt;/h2&gt;

&lt;p&gt;Fitting a three-component GMM resulted in a null model having a higher likelihood than the ground truth model.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Spent a lot of time troubleshooting this and finally realized I had scaled all values up by 100x so Matlab wouldn't choke, but I wasn't accounting for this when evaluating.  Blame it on this blasted cold, killing my focus!&lt;/p&gt;

&lt;p&gt;Ground truth model looks much better than null model now.&lt;/p&gt;

&lt;p&gt;--&lt;/p&gt;

&lt;p&gt;Trying different blurring levels.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1.0 is to small.&lt;/li&gt;
&lt;li&gt;2.0 seems okay&lt;/li&gt;
&lt;li&gt;5.0 gives a wide variance for true-positives.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;In the end, running max likleihood on this will be best, but this gives us a ballpark.&lt;/p&gt;

&lt;p&gt;--&lt;/p&gt;

&lt;p&gt;Trying to get KJB EM algorithm working on my 2M element dataset.  Getting NaN errors at the moment.&lt;/p&gt;
</description>
				<pubDate>Sat, 19 Oct 2013 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2013/10/19/work-log</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2013/10/19/work-log</guid>
			</item>
		
			<item>
				<title>Work Log - Uninformative likelihood?</title>
				<description>

&lt;div class=&quot;meta-info&quot;&gt;
&lt;table&gt;
    &lt;tr&gt;
        &lt;th&gt;Project&lt;/th&gt;
        &lt;td&gt;&lt;a href=&quot;/ksimek/research/projects/tulips.html&quot;&gt;Tulips&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Subproject&lt;/th&gt;
        &lt;td&gt;Data Association v3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Working path&lt;/th&gt;
        &lt;td&gt;projects/&amp;#8203;tulips/&amp;#8203;trunk/&amp;#8203;src/&amp;#8203;matlab/&amp;#8203;data_association_3&lt;/td&gt;
    &lt;/tr&gt;

    &lt;tr&gt;
        &lt;th&gt;SVN Revision&lt;/th&gt;
        &lt;td&gt;15701&lt;/td&gt;
    &lt;/tr&gt;


&lt;/table&gt;

    Unless otherwise noted, all filesystem paths are relative to the &quot;Working path&quot; named above.
&lt;/div&gt;


&lt;h2&gt;Likelihood sanity check (ctd)&lt;/h2&gt;

&lt;p&gt;An empty model should have a significantly worse likelihood than the ground truth model.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ground truth model:  -3.38064e+08
empty model: -3.28279e+08
full model: -1.20572e+08
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Both empty and full are better than ground truth.  Why??&lt;/p&gt;

&lt;p&gt;At least possiblities here:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Noise level is so high that fitting is impossible (remember the paper &quot;Fundamental limits of Bayesian Inference: Order Parameters and Phase Transitions for Road Tracking&quot;)&lt;/li&gt;
&lt;li&gt;Bug.  maybe renderings are just waaaay off?&lt;/li&gt;
&lt;li&gt;Bad calibration.  Looking at the GMM plot from yesterday (see below) it looks like the one-sigma contour is very very large.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;img src=&quot;/ksimek/research/img/2013-10-17-bd.gmm.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Case 1 is what's left over once 2 and 3 are ruled out.&lt;/p&gt;

&lt;h2&gt;Rendering sanity check.&lt;/h2&gt;

&lt;p&gt;This seems to be a culprit.&lt;/p&gt;

&lt;p&gt;Here's first data view:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ksimek/research/img/2013-10-17-data-view-1.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Not a good match to the actual first data image:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ksimek/research/img/2013-10-17-ler_2_36_0.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;But a good match to the second data image:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ksimek/research/img/2013-10-17-ler_2_36_1.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Must be an off-by-one error when reading data.&lt;/p&gt;

&lt;p&gt;The cameras are not off-by one.  Here's the rendering of the model under the first camera:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ksimek/research/img/2013-10-17-model-view-1.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Good match to the first data image above.&lt;/p&gt;

&lt;p&gt;Bug is in the config file:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;view-indices=1:4:36  # bug here
view-indices=0:4:35  # should be this
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;Good news, bad news.&lt;/p&gt;

&lt;p&gt;Good news: after fixing config file, data and rendering look good (use slider to swap between images)&lt;/p&gt;

&lt;script&gt;
$(function(){
    var urls = [
        &quot;/ksimek/research/img/2013-10-17-data.jpg&quot;,
        &quot;/ksimek/research/img/2013-10-17-model.jpg&quot;
        ]

    construct_animation($(&quot;#data-model-anim&quot;), urls);
});
&lt;/script&gt;


&lt;div id=&quot;data-model-anim&quot; style=&quot;width:530px&quot;&gt; &lt;/div&gt;


&lt;p&gt;Bad news: likelihood gets &lt;strong&gt;worse&lt;/strong&gt;!&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fixed likelhood: -3.38298e+08
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It looks like the rendered model is lighter than the data model.  This might account for the issues we're seeing.  We're in the region to the right of the diagonal &quot;true positive&quot; component in the GMM (see contour plot above).  In this region, the noise model has a stronger pull than the true positive model, which partially explains why we get better when fewer model pixels are on the screen.   It doesn't explain why the model gets better when we shift left and right -- maybe it fits better in the tails of the blurred data, but we'd expect it to eventually get worse.  Lets test it.&lt;/p&gt;

&lt;p&gt;Recall that this GMM was trained on a manipulated version of the data image, not a rendered 3D model image.  The process taken was (a) removing all background pixels from the data image and (b) perturbing the foreground pixels. We may have removed a few foreground pixels to add false positives, but the amount was small, if memory serves.  Now we have far fewer model pixels, so we expect the &quot;true positive&quot; region to be slanted more upward.&lt;/p&gt;

&lt;h2&gt;Optimality test (redux)&lt;/h2&gt;

&lt;p&gt;Code:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x_values=&quot;-80 -40 -20 -10 -5 -2 -1 0 1 2 5 10 20 40 80&quot;
for x in $x_values; do
    echo -n &quot;$x &quot;;
    ./likelihood_server \
        --config=test.conf  \
        --image-bounds &quot;0 530 397 0 200 2000&quot;  \
        --cam-convention &quot;1 0 0&quot;  \
        --dbg_save_frames  \
        --dbg_load_message  \
        --dbg-ppo-x-offset=$x 2&amp;gt; /dev/null | grep ^3 | sed -e 's/3 //' -e 's/,//';
done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Output (delta-x vs log-likelihood):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-80 -3.36866e+08
-40 -3.36987e+08
-20 -3.37434e+08
-10 -3.37864e+08
-5 -3.38169e+08
-2 -3.38279e+08
-1 -3.38294e+08
0 -3.38298e+08
1 -3.38292e+08
2 -3.38275e+08
5 -3.38172e+08
10 -3.37912e+08
20 -3.37479e+08
40 -3.36958e+08
80 -3.36991e+08
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Plot:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ksimek/research/img/2013-10-17-likelihood_plot_vs_x.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2&gt;&quot;Full&quot; model issue&lt;/h2&gt;

&lt;p&gt;One of the strangest things is the fact that a rendering full of &quot;1.0's&quot; performs far better than the ground truth or empty model.  This area lies along the x-axis in the GMM contour plot, where there is no support.&lt;/p&gt;

&lt;p&gt;Lets debug this.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Found an insane bug.  Below is the loop that compares all the pixels of the data and rendered model:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    for(size_t i = 0; i &amp;lt;= size_; ++i)
    {
        kjb::Vector2 x;
        x[0] = model[i];
        x[1] = data_[i] + 1;

        ...  // compute p(x[1] | x[0])
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I have no idea why we're adding 1.0 to &lt;code&gt;data_[i]&lt;/code&gt;, but this explains everything.  In the &quot;full&quot; model, it puts us right on the diagonal of the GMM.  In the empty model, we're right on the x-axis.  Both are well-supported regions.  In the ground truth model, we're lying between these extremes, which is a no-man's land of near-zero support.&lt;/p&gt;

&lt;p&gt;Spending 5 minutes to determine how this got added...&lt;/p&gt;

&lt;p&gt;...&lt;/p&gt;

&lt;p&gt;It was added between November 11 and December 13 last year.   No obvious reason.  Oh well.&lt;/p&gt;

&lt;p&gt;New sanity check numbers:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;full model -5.2217e+08
ground truth model 4.03273e+06
empty model: 4.01252e+06
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Much more sensible.  Missing data looks terrible, noise looks okay but not great,  ground truth looks best.  Lets do an offset plot just to be safe.&lt;/p&gt;

&lt;h2&gt;Optimality test (redux&lt;sup&gt;2)&lt;/sup&gt;&lt;/h2&gt;

&lt;p&gt;Results:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-80 3.1039e+06
-40 3.27557e+06
-20 3.58156e+06
-10 3.77333e+06
-5 3.93159e+06
-2 4.01459e+06
-1 4.02845e+06
0 4.03273e+06
1 4.02704e+06
2 4.01209e+06
5 3.93021e+06
10 3.78782e+06
20 3.60557e+06
40 3.26585e+06
80 3.26894e+06
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Plot&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ksimek/research/img/2013-10-17-likelihood_plot_vs_x_fixed.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Oh Yeah!!&lt;/p&gt;

&lt;h2&gt;BD Likelihood Data Dump Mode.&lt;/h2&gt;

&lt;p&gt;add a mode by which pixel likelihood will save pixel data to files for analysis or debugging&lt;/p&gt;

&lt;p&gt;changes will appear in:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;lib/evaluate/bd_likelihood.h - Bd_pixel_likelihood_cpu&lt;/li&gt;
&lt;li&gt;lib/evaluate/bd_likelihood.h - Bd_mv_likeliood_cpu&lt;/li&gt;
&lt;li&gt;./likelihood_server.cpp - Options&lt;/li&gt;
&lt;li&gt;./likelihood_server.cpp - main()&lt;/li&gt;
&lt;/ol&gt;


&lt;hr /&gt;

&lt;p&gt;Added dump mode.  Probably should move this into a separate directory, or at least a different program, since it has almost nothing to do with the likleihood server.&lt;/p&gt;

&lt;h2&gt;TODO&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;rename matlab &quot;render_client&quot; code to &quot;likelihood_client&quot;&lt;/li&gt;
&lt;li&gt;increase spacing between reconstructed points&lt;/li&gt;
&lt;li&gt;remove edges around image border.&lt;/li&gt;
&lt;li&gt;get this running on cuda server&lt;/li&gt;
&lt;li&gt;train likelihood&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;Open issues&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;how to sync datasets on matlab and c++ server?&lt;/li&gt;
&lt;li&gt;Wacv multi-view reconstruction for training&lt;/li&gt;
&lt;li&gt;saving wacv to files for training&lt;/li&gt;
&lt;li&gt;fixing issues in wacv reconstructions&lt;/li&gt;
&lt;li&gt;evaluation methodology&lt;/li&gt;
&lt;li&gt;split/merge&lt;/li&gt;
&lt;/ul&gt;

</description>
				<pubDate>Thu, 17 Oct 2013 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2013/10/17/work-log</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2013/10/17/work-log</guid>
			</item>
		
			<item>
				<title>Work Log - silhouettes, training likelihood, evaluating likelihood</title>
				<description>

&lt;div class=&quot;meta-info&quot;&gt;
&lt;table&gt;
    &lt;tr&gt;
        &lt;th&gt;Project&lt;/th&gt;
        &lt;td&gt;&lt;a href=&quot;/ksimek/research/projects/tulips.html&quot;&gt;Tulips&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Subproject&lt;/th&gt;
        &lt;td&gt;Likelihood Server&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Working path&lt;/th&gt;
        &lt;td&gt;projects/&amp;#8203;tulips/&amp;#8203;trunk/&amp;#8203;src/&amp;#8203;likelihood_server&lt;/td&gt;
    &lt;/tr&gt;

    &lt;tr&gt;
        &lt;th&gt;SVN Revision&lt;/th&gt;
        &lt;td&gt;15229&lt;/td&gt;
    &lt;/tr&gt;


&lt;/table&gt;

    Unless otherwise noted, all filesystem paths are relative to the &quot;Working path&quot; named above.
&lt;/div&gt;


&lt;p&gt;Enabled glPolygonOffset and it improved results somewhat.  Still getting stippling 10% of the time.&lt;/p&gt;

&lt;p&gt;Adding edge-detection code to show stippled edges helps, but adds some internal edges for some reason.&lt;/p&gt;

&lt;p&gt;Apparently, we have point spacing too close together.  This introduces lots of little ridges, which makes silhouette edges appear on the interior of the object incorrectly.  We should pro-process curves in matlab to force spacing to be greater than or equal to to the curve radius.&lt;/p&gt;

&lt;h2&gt;Likelihood rendering bugs&lt;/h2&gt;

&lt;p&gt;Image dumps from our likelihood show all edges are being rendered (not just silhouette edges).&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;seems to be an issue with Camera_render_wrapper.  Possibly the y-axis flipping?&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Yep.  Reverses the handedness of the projected model.&lt;/p&gt;

&lt;p&gt;Shader assumes orientation of forward-facing triangles isn't affected by projection.  Thus, cross-product can be used to determine whether a face is forward-facing (a fundamental operation for classifying silhouette edges).&lt;/p&gt;

&lt;p&gt;Can we solve by doing visibility test in world coordinates, which avoids the projection matrix altogether?&lt;/p&gt;

&lt;p&gt;Yes, but there's a bug causing a few faulty silhouette edges to appear.  Why?&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;It turns out, we were assuming the normal vector of opposite faces are parallel, and used this to .  Apparently not always the case, especially when sharp corners occur (which happens routinely when point spacing is close).&lt;/p&gt;

&lt;p&gt;During testing, we somehow corrupted the GPU's memory.  System sprites (e.g. cursor) are starting to be corrupted, and program keeps crashing  from GPU errors.  Probably constructed too many shaders in a single session.  Will reboot and continue.&lt;/p&gt;

&lt;p&gt;Summary: found silhouette rendering bug caused by projection matrix that didn't preserve handedness.  Rewrote silhouette pass 2 geometry shader to handle this case better.  Now renders correctly in both cases.&lt;/p&gt;

&lt;h2&gt;Next: determine cause of likleihood NaN's; train the likelihood.&lt;/h2&gt;

&lt;h2&gt;Blurred-difference (bd) likelihood issues&lt;/h2&gt;

&lt;p&gt;Getting &quot;NaN&quot; when evaluating.  Checking the result of blurring the model shows inf's everywhere.  Weird, because I can confirm that the input data is succesfully blurring:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ksimek/research/img/2013-10-16-blurred_data.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Same blurrer is used for data and model&lt;/li&gt;
&lt;li&gt;It isn't the input (tried substituting data in for model and still got corrupt stuff back).&lt;/li&gt;
&lt;li&gt;re-initializing blurrer doesn't seem to help&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Stepping through in GDB...&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;After convolution, values are on the order of 1e+158...  clearly invalid.  Converting to float causes inf.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Aside:  the padding added before convolution isn't zeros!  Fixing bug in lib/evaluate/convolve.h:fftw_convolution class.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Aside:  Need to remove edges around image border:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ksimek/research/img/2013-10-16-border_edges.jpg&quot; alt=&quot;border edges bug&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Aside: different blurrer for each view?  unnecessary!&lt;/p&gt;

&lt;p&gt;Wrong, same blurrer, different internal buffers.  Caused by calling blurrer.init_fttw_method() every time we add a view to the multi-view likelihood.  Removed that call.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Apparently, calling blurrer_.init_fftw_method() is wreaking all kinds of havok on the blurring results.  I have idea why.  Possibly calling init_fftw_method() more than once is simply not supported.  But that call simply destroys and object and creates a new one, so why is that different from the first time we called it?&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Theory: fftw wisdom is messing with us?&lt;/p&gt;

&lt;p&gt;Results: nope&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;We have a working case and a non-working case.  Can we walk from one case to the other and find the exact change that causes the error?&lt;/p&gt;

&lt;p&gt;Aside: Here's a bizarre result wer'e getting during failure:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ksimek/research/img/2013-10-16-weird_results.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Kind of cool!&lt;/p&gt;

&lt;p&gt;Actually, there might be a hint here... Notice the eliptical shapes that are about the same size as the turntable, but shifted and screwed up.&lt;/p&gt;

&lt;p&gt;It's possible what we're seeing is convolution with a random mask.  the two main ellipses we're seeing are two random bright pixels in the mask, and the miscellaneous roughness might be ca combinariton of small positive and negative values causing the texture we see.  Next step: inspect mask&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Bingo!  We're working with a random mask.&lt;/p&gt;

&lt;p&gt;Let's step back to the original failing case and see if the mask is still random.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Confirmed.  Here's an eample mask:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ksimek/research/img/2013-10-16-tmp.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Here it is dimmer:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ksimek/research/img/2013-10-16-bunk_maks_dimmer.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Anything look familiar?  It's derived from our plant image (notice the ellipses from the turntable).&lt;/p&gt;

&lt;p&gt;Theory: somehow the mask is getting overwritten with our blurred model.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Solved.  Simple bug but was obscured by several issues.&lt;/p&gt;

&lt;p&gt;The fundamental issue was that when the blurring mask was being padded, the padding wasn't being filled with zeros.  Thus, the padded mask consisted of a small section of real mask, surrounded by huge amounts of uninitialized memory.&lt;/p&gt;

&lt;p&gt;This was a bug that I discovered and fixed 12 months ago, but it got rolled back when Andrew revamped the FFTW convolution class.  Ultimately, I was able to restore my changes to the FFTW class without much trouble, but for the six hours that followed, these changes weren't being compiled, because they were in a header file, and the build system only rebuilds object files if the &quot;cpp&quot; file is changed.&lt;/p&gt;

&lt;p&gt;Further, there was a red-herring that appeared as &quot;re-initializing the blurrer causes the errors&quot;.  While this was true, it was only because re-initializing also re-initialized the blurring mask, and it was only during re-initialization did the uninitialized mask padding have junk -- on the first initialization, the memory just happened to be blank.  Go figure.&lt;/p&gt;

&lt;p&gt;This was an absolutely essential bug to find and fix.  Glad its fixed, just wish it hadn't regressed in the first place.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Okay time to reset.  Let's confirm that the rendered models are blurring correctly.  Then confirm non-zero log-likleihood result.    Then on to training.&lt;/p&gt;

&lt;p&gt;Model blurring: CHECK
Finite likelihood: CHECK  (result: -3.38064e+08)
Likelihood is near-optimal: &lt;strong&gt;FAIL&lt;/strong&gt;. see below&lt;/p&gt;

&lt;h2&gt;Optimality test&lt;/h2&gt;

&lt;p&gt;Added debugging option to shift rendering left/right/up/down in the image: &lt;code&gt;--dbg-ppo-x-offset&lt;/code&gt; and &lt;code&gt;--dbg-ppo-y-offset&lt;/code&gt;.   Ideally, the likleihood should be optimized at zero offset&lt;/p&gt;

&lt;p&gt;Log likelihood vs x-offset&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; 0  -3.38064e+08
+1  -3.38069e+08
+2  -3.38068e+08
+5  -3.38033e+08
+10 -3.37881e+08
-2  -3.38039e+08
-5  -3.37968e+08
-10 -3.37786e+08
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;/ksimek/research/img/2013-10-16-likleihood_plot_vs_x.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Weird... Why is it at a local &lt;em&gt;minimum&lt;/em&gt; at the center?&lt;/p&gt;

&lt;p&gt;Log likelihood vs y-offset&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; 0  -3.38064e+08
-2  -3.38062e+08
-5  -3.38033e+08
-10 -3.3789e+08
-20 -3.37321e+08
-40 -3.36139e+08
-80 -3.33693e+08
 2  -3.38052e+08
 5  -3.38025e+08
 10 -3.37983e+08
 20 -3.37955e+08
 40 -3.3785e+08
 80 -3.37523e+08
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;/ksimek/research/img/2013-10-16-likelihood_plot_vs_y.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Note that as y decreases, the top of the plant starts to fall off the screen. This suggests that having fewer model points might be over-preferred.  Need to sanity-check the GMM model we're using -- I trained it months ago and never really leaned on it hard, so it's the first place to look for problems.&lt;/p&gt;

&lt;p&gt;Also, might be a scaling issue.  Double-check that blurred model and blurred data have similar scale.&lt;/p&gt;

&lt;h2&gt;GMM sanity check&lt;/h2&gt;

&lt;p&gt;Plotting first and second standard deviation of the joint distribution of model-pixel-intensity and data-pixel-intensity.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ksimek/research/img/2013-10-17-bd.gmm.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This looks sensible.  The first component is the diagonal one, representing true postives (in the presence of random perturbations).&lt;/p&gt;

&lt;p&gt;The second component is at the origin -- true negatives.&lt;/p&gt;

&lt;p&gt;The third component is along the y-axis, representing false positives in the data, aka noise.&lt;/p&gt;

&lt;p&gt;The first component has roughly 10x less weight than the second and third.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;No component for the false negatives (aka missing data).  As I recall, running EM on a GMM with four or more components always resulted in redundant components.  Possibly hand-initializing the components in each of the four positions might help.&lt;/p&gt;

&lt;p&gt;I also recall some sort of GPU limitation that prevented me from evaluating more than three components in hardware.  That seems unusual though, and I may be misremembering.&lt;/p&gt;

&lt;p&gt;Does this provide any insight as to why we prefer our model to drift off of the screen?  This introduces more &quot;negative&quot; model pixels, pushing toward the well-supported y-axis are of our model.  Possibly this is the result of poor calibration?  Or wrong blurring sigma?&lt;/p&gt;

&lt;p&gt;TODO: re-run the x/y offset experiment with smaller blurring sigma.&lt;/p&gt;

&lt;h2&gt;Data Sanity check&lt;/h2&gt;

&lt;p&gt;To do.  Approach: instead of evaluating likelihood pixels against data, dump model/data pixel pairs into a list and (a) plot them or (b) train on them.  Maybe just dump to a file and do it in matlab?&lt;/p&gt;

&lt;h2&gt;Blooper reel&lt;/h2&gt;

&lt;p&gt;While writing miscellaneous blocks of memory to disk as images, got some interesting but totally wrong results.&lt;/p&gt;

&lt;p&gt;The following is partially due to rendering an array of doubles as floats.  Interesting banding pattern.  A mini-Mondrian!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ksimek/research/img/2013-10-16-fun-mess-1.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The next is just uninitialized memory.  Iteresting patterns :-)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ksimek/research/img/2013-10-16-fun-mess-2.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2&gt;TODO (new)&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;increase spacing between reconstructed points&lt;/li&gt;
&lt;li&gt;remove edges around image border.&lt;/li&gt;
&lt;li&gt;share blurrer between views&lt;/li&gt;
&lt;li&gt;get this running on cuda server&lt;/li&gt;
&lt;li&gt;why is it crashing on exit?&lt;/li&gt;
&lt;li&gt;Data sanity check - does it roughly match the GMM's distribution?&lt;/li&gt;
&lt;li&gt;train likelihood&lt;/li&gt;
&lt;li&gt;add &quot;dump&quot; mode to bd-likelihood which saves all image pairs to disk for analysis or debugging.&lt;/li&gt;
&lt;li&gt;test empty model likelihood&lt;/li&gt;
&lt;/ul&gt;

</description>
				<pubDate>Wed, 16 Oct 2013 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2013/10/16/work-log</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2013/10/16/work-log</guid>
			</item>
		
			<item>
				<title>Work Log - Finishing Likelihood Server, integrating to sampling engine</title>
				<description>

&lt;div class=&quot;meta-info&quot;&gt;
&lt;table&gt;
    &lt;tr&gt;
        &lt;th&gt;Project&lt;/th&gt;
        &lt;td&gt;&lt;a href=&quot;/ksimek/research/projects/tulips.html&quot;&gt;Tulips&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Subproject&lt;/th&gt;
        &lt;td&gt;Likelihood Server&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Working path&lt;/th&gt;
        &lt;td&gt;projects/&amp;#8203;tulips/&amp;#8203;trunk/&amp;#8203;src/&amp;#8203;likelihood_server&lt;/td&gt;
    &lt;/tr&gt;

    &lt;tr&gt;
        &lt;th&gt;SVN Revision&lt;/th&gt;
        &lt;td&gt;15229&lt;/td&gt;
    &lt;/tr&gt;


&lt;/table&gt;

    Unless otherwise noted, all filesystem paths are relative to the &quot;Working path&quot; named above.
&lt;/div&gt;


&lt;p&gt;Old silhouette rendering technique is failing.  Point spacing is much tighter than before.  Our old algorithm relied on segment-ids matching between the first-pass and second pass to work.&lt;/p&gt;

&lt;p&gt;Have a replacement algorithm that works reasonably well.  Basically edge-detection on the depth image.  The down side is we're getting double-edges in some areas, and you have to adjust a threshold.  It'll have to do for now, hopefully we can train a the likelihood to be robust to these issues.&lt;/p&gt;

&lt;h2&gt;Training Bd_likelihood&lt;/h2&gt;

&lt;p&gt;added 'train_bd_likelihood()' function to 'lib/evaluate/bd_likelihood.h'.  Uses 'kjb_c::get_full_GMM()'  to fit a three-component gaussian mixture model to model the relationship between model and data pixels.&lt;/p&gt;

&lt;h2&gt;Refactoring&lt;/h2&gt;

&lt;p&gt;Shader objects from './shader.h' are now in the project library, under 'lib/ogl/shader_2.h'.  Not the greatest name, but shader.h already exists and conflicts.  Consder refactoring them later.&lt;/p&gt;

&lt;p&gt;Silhouetter rendering from './render_util.h' are now in 'lib/graphics/silhouette_renderer.h'.  Much better encapsulation now, so we can use it in other projects.&lt;/p&gt;

&lt;p&gt;In the process of updating './likelihood_server.cpp' to reflect these changes.  At the moment, getting an &quot;invalid operation&quot; when rendering.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;It was a stray &lt;code&gt;glUseProgram(notzero)&lt;/code&gt; in the shader loading code.&lt;/p&gt;

&lt;hr /&gt;
</description>
				<pubDate>Tue, 15 Oct 2013 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2013/10/15/work-log</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2013/10/15/work-log</guid>
			</item>
		
			<item>
				<title>Work Log - Troubleshooting silhouette rendering</title>
				<description>

&lt;div class=&quot;meta-info&quot;&gt;
&lt;table&gt;
    &lt;tr&gt;
        &lt;th&gt;Project&lt;/th&gt;
        &lt;td&gt;&lt;a href=&quot;/ksimek/research/projects/tulips.html&quot;&gt;Tulips&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Subproject&lt;/th&gt;
        &lt;td&gt;Likelihood Server&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Working path&lt;/th&gt;
        &lt;td&gt;projects/&amp;#8203;tulips/&amp;#8203;trunk/&amp;#8203;src/&amp;#8203;likelihood_server&lt;/td&gt;
    &lt;/tr&gt;

    &lt;tr&gt;
        &lt;th&gt;SVN Revision&lt;/th&gt;
        &lt;td&gt;15229&lt;/td&gt;
    &lt;/tr&gt;


&lt;/table&gt;

    Unless otherwise noted, all filesystem paths are relative to the &quot;Working path&quot; named above.
&lt;/div&gt;


&lt;p&gt;Silhouettes are rendering badly&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ksimek/research/img/2013-10-13-dump_0.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Looks like internal edges are rendering.  Likely an issue with shader_src/silhouette2.gs.glsl.&lt;/p&gt;

&lt;p&gt;Need a quick way to tweak shader and re-run.&lt;/p&gt;

&lt;h2&gt;Building shader debugging mode&lt;/h2&gt;

&lt;p&gt;if enabled, results will display in viewer instead of being passed to likelihood.&lt;/p&gt;
</description>
				<pubDate>Mon, 14 Oct 2013 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2013/10/14/work-log</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2013/10/14/work-log</guid>
			</item>
		
			<item>
				<title>Work Log - Four days of OpenGL Debugging</title>
				<description>

&lt;div class=&quot;meta-info&quot;&gt;
&lt;table&gt;
    &lt;tr&gt;
        &lt;th&gt;Project&lt;/th&gt;
        &lt;td&gt;&lt;a href=&quot;/ksimek/research/projects/tulips.html&quot;&gt;Tulips&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Subproject&lt;/th&gt;
        &lt;td&gt;Likelihood Server&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Working path&lt;/th&gt;
        &lt;td&gt;projects/&amp;#8203;tulips/&amp;#8203;trunk/&amp;#8203;src/&amp;#8203;likelihood_server&lt;/td&gt;
    &lt;/tr&gt;

    &lt;tr&gt;
        &lt;th&gt;SVN Revision&lt;/th&gt;
        &lt;td&gt;15229&lt;/td&gt;
    &lt;/tr&gt;


&lt;/table&gt;

    Unless otherwise noted, all filesystem paths are relative to the &quot;Working path&quot; named above.
&lt;/div&gt;


&lt;h2&gt;Status&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Server is now running, connecting, receiving and decoding messages successfully.&lt;/li&gt;
&lt;li&gt;Matlab client is constructing, sending messages, and destroying successfully.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Since we've sent our first message and saved it to a file, we no longer need matlab to debug the server, using the --dbg-load-message flag.&lt;/p&gt;

&lt;h2&gt;OpenGL crashing &lt;/h2&gt;

&lt;p&gt;In render_util.cpp -&gt; render_silhouettes(), crash is occurring somewhere in these lines.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;39      GLenum draw_buffers[2] = {GL_COLOR_ATTACHMENT0, GL_COLOR_ATTACHMENT1};
(gdb) list
40      glDrawBuffers(2, draw_buffers);
41
42      glClearColor(0.0,0.0,0.0,0.0);
43      glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);
44      glEnable(GL_DEPTH_TEST);
45      DBG_GL_ETX();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The dreaded &quot;invalid operation&quot;&lt;/p&gt;

&lt;p&gt;I'm guessing opengl isn't in a valid rendering state yet; we may not have bound the fbo, or forgot to enable a rendering program.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;yep, fbo wasn't bound.&lt;/p&gt;

&lt;p&gt;now running to completion, but result is NaN.&lt;/p&gt;

&lt;p&gt;Probably because we're using random numbers for our curves.  Lets grab some real curve data and re-run.  We'll probably need to visualize the silhouette output soon.&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&quot;meta-info&quot;&gt;
&lt;table&gt;
    &lt;tr&gt;
        &lt;th&gt;Project&lt;/th&gt;
        &lt;td&gt;&lt;a href=&quot;/ksimek/research/projects/tulips.html&quot;&gt;Tulips&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Subproject&lt;/th&gt;
        &lt;td&gt;Data Association v3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Working path&lt;/th&gt;
        &lt;td&gt;projects/&amp;#8203;tulips/&amp;#8203;trunk/&amp;#8203;src/&amp;#8203;matlab/&amp;#8203;data_association_3&lt;/td&gt;
    &lt;/tr&gt;

    &lt;tr&gt;
        &lt;th&gt;SVN Revision&lt;/th&gt;
        &lt;td&gt;15229&lt;/td&gt;
    &lt;/tr&gt;


&lt;/table&gt;

    Unless otherwise noted, all filesystem paths are relative to the &quot;Working path&quot; named above.
&lt;/div&gt;


&lt;p&gt;added function &lt;code&gt;wacv-2012/get_wacv_result.m&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Code to get curves and send them to server:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;tmp = get_wacv_result(2);
tmp = cellfun(@(x) [x; ones(1,size(x,2))], tmp, 'UniformOutput', false);
socket = construct_render_client('localhost', '12345')'
send_curves(socket, tmp);
result = send_curves(socket, tmp);
destroy_render_client(socket)
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;Got first dumps.  issues&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;all black, no content&lt;/li&gt;
&lt;li&gt;reversed wrong aspect ratio&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Possible causees for 1.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;bad camera files&lt;/li&gt;
&lt;li&gt;bad code for converting intrinsic matrix to opengl&lt;/li&gt;
&lt;li&gt;bad curves?&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;2 seems most likely.  Can debug 1 and 2 by trying old camera object and see if they work;  if so, compare matrices with new matrices.&lt;/p&gt;

&lt;h2&gt;Possibly the mods I made to the multi-view likelihoods are the culprit.  I'm using raw matrices now instead of cmara objects in obj.add_view() and Camera_view_wrapper.&lt;/h2&gt;

&lt;p&gt;Added command-line option &quot;--dbg-save-frames&quot;.  Writes all rendered views to disk as &quot;dump_1.png, dump_2.png,...&quot;.  Only the most recent 10 are kept at any time.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;re-running using turntable camera; passing intrinsic and extrinsic matrices to likelihood.&lt;/p&gt;

&lt;p&gt;Renders are still black.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Forgot to set white color?&lt;/p&gt;

&lt;p&gt;No; its in the render_silhouette function.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Found something: wacv results were aritficially centered on zero.  fixed.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Did matlab test on modelview and projection matrices and curve points -- z coordinate falls outside of [-1 1].  Beyond far plane.&lt;/p&gt;

&lt;p&gt;reason: not negating z-coordinate in test code.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;changing gears.  running matlab test on original input modelview and projection matrices.&lt;/p&gt;

&lt;p&gt;Modelview looks okay. Projection is way off.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;intrinsic matrix?&lt;/li&gt;
&lt;li&gt;NDC matrix?&lt;/li&gt;
&lt;li&gt;bounds?&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Intrinsic looks reasonable.&lt;/p&gt;

&lt;p&gt;probably NDC/bounds issue&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Bug in ndc math&lt;/p&gt;

&lt;p&gt;projecting outside from far plane&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;needed to flip axes to handle convention mismatch.&lt;/p&gt;

&lt;p&gt;Now getting something, but the positions are looking weird.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;was re-negating ppo; already flipped during convention resolution.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;now getting decent results, but off-center and smaller:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ksimek/research/img/2013-10-12-dump_3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;rough original to rendering offsets:  up by 56, left by 115.&lt;/p&gt;

&lt;h2&gt;non-uniform scaling; width is smaller than height.&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;Projecting plant base using
(a) intrinsic and extrinsic matrices from matlab
(b) modelview and projection matrices pulled from opengl

results:
(a) projects to the right place (tested using image and pixelstick)
(b) NDC coordinates look okay.  I manually remapped (scale and offset), and they look okay.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Since NDC look okay, the remapping must be wrong.  glViewport issue?  I'm manually setting it, but maybe it needs to be set for each shader?&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Or maybe it's a geometry shader issue?  I'm using different modelview and projection matrices now.&lt;/p&gt;

&lt;p&gt;=--&lt;/p&gt;

&lt;p&gt;Found it (Sunday night) -- Somehow the viewport transformation is getting reset. Possibly viewport is a shader-specific state that needs to be set each time?&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;now centered, need to diagnose silhouette issues:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ksimek/research/img/2013-10-13-dump_0.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2&gt;TODO (new)&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;rename matlab &quot;render_client&quot; code to &quot;likelihood_client&quot;&lt;/li&gt;
&lt;li&gt;rename likelihood_server/sampler2.cpp to something not nonsense.&lt;/li&gt;
&lt;/ul&gt;

</description>
				<pubDate>Fri, 11 Oct 2013 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2013/10/11/work-log</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2013/10/11/work-log</guid>
			</item>
		
			<item>
				<title>Work Log</title>
				<description>

&lt;div class=&quot;meta-info&quot;&gt;
&lt;table&gt;
    &lt;tr&gt;
        &lt;th&gt;Project&lt;/th&gt;
        &lt;td&gt;&lt;a href=&quot;/ksimek/research/projects/tulips.html&quot;&gt;Tulips&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Subproject&lt;/th&gt;
        &lt;td&gt;Likelihood Server&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Working path&lt;/th&gt;
        &lt;td&gt;projects/&amp;#8203;tulips/&amp;#8203;trunk/&amp;#8203;src/&amp;#8203;likelihood_server&lt;/td&gt;
    &lt;/tr&gt;

    &lt;tr&gt;
        &lt;th&gt;SVN Revision&lt;/th&gt;
        &lt;td&gt;15229&lt;/td&gt;
    &lt;/tr&gt;


&lt;/table&gt;

    Unless otherwise noted, all filesystem paths are relative to the &quot;Working path&quot; named above.
&lt;/div&gt;


&lt;p&gt;Spent most of the day finishing coding and compiling likelihood server.&lt;/p&gt;

&lt;p&gt;Next:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;build config file and make first run.

&lt;ul&gt;
&lt;li&gt;build camera files&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;write matlab TCP client mex code&lt;/li&gt;
&lt;li&gt;send ground truth model from matlab to server&lt;/li&gt;
&lt;li&gt;debug:

&lt;ul&gt;
&lt;li&gt;check rendering: silhouettes look okay?&lt;/li&gt;
&lt;li&gt;check y-axis flipping issue&lt;/li&gt;
&lt;li&gt;check likelihood vs. perturbed model vs. null model vs. overexpressive model&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;Issue: stem radius&lt;/h2&gt;

&lt;p&gt;Until now, our model and data have been infinitesimally thin curve (medial axis).&lt;/p&gt;

&lt;p&gt;Need to consider how to add width.  Options:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Train?&lt;/li&gt;
&lt;li&gt;Fixed?  (pass as CLI parameter to server)&lt;/li&gt;
&lt;li&gt;Marginalize over?&lt;/li&gt;
&lt;li&gt;Optimize?&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Since we're on short time, I'm leaning toward 2 for simplicity.&lt;/p&gt;

&lt;h2&gt;Building config file&lt;/h2&gt;

&lt;p&gt;Done, but need to double-check which dataset we're using in matlab at the moment.&lt;/p&gt;

&lt;h2&gt;Issues&lt;/h2&gt;

&lt;p&gt;When running batches of several datasets, need a way to ensure matlab and likelihood server are running on the same dataset.&lt;/p&gt;
</description>
				<pubDate>Wed, 09 Oct 2013 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2013/10/09/work-log</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2013/10/09/work-log</guid>
			</item>
		
			<item>
				<title>Work Log</title>
				<description>

&lt;div class=&quot;meta-info&quot;&gt;
&lt;table&gt;
    &lt;tr&gt;
        &lt;th&gt;Project&lt;/th&gt;
        &lt;td&gt;&lt;a href=&quot;/ksimek/research/projects/tulips.html&quot;&gt;Tulips&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Subproject&lt;/th&gt;
        &lt;td&gt;Likelihood Server&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Working path&lt;/th&gt;
        &lt;td&gt;projects/&amp;#8203;tulips/&amp;#8203;trunk/&amp;#8203;src/&amp;#8203;likelihood_server&lt;/td&gt;
    &lt;/tr&gt;

    &lt;tr&gt;
        &lt;th&gt;SVN Revision&lt;/th&gt;
        &lt;td&gt;15229&lt;/td&gt;
    &lt;/tr&gt;


&lt;/table&gt;

    Unless otherwise noted, all filesystem paths are relative to the &quot;Working path&quot; named above.
&lt;/div&gt;


&lt;p&gt;Working on compiling render server.&lt;/p&gt;

&lt;p&gt;Do I want to compute likelihood in C++ too?&lt;/p&gt;

&lt;p&gt;Code exists for it.  Maybe best to just re-use code from curve_sampling.cpp and abandon render server.&lt;/p&gt;

&lt;p&gt;Lets do that.&lt;/p&gt;

&lt;h2&gt;Reviewing old curve sampling code&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Pixel store&lt;/li&gt;
&lt;li&gt;renderer&lt;/li&gt;
&lt;li&gt;multi-view likelihood&lt;/li&gt;
&lt;li&gt;pixel likelihood&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Pixel likelihood receives a pointer to linear array of reals that represent the pixel matrix.&lt;/p&gt;

&lt;p&gt;Multi-view likelihood receives a renderable and handles all the rendering and pixel-retreival, and dispatches to pixel likelihood objects for computing.  is constructed with one or more cameras.  On evaluation it receives a renderable object, projects it under each camera, retreives the pixels, and passes to a pixel likelihood.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Refactor&lt;/strong&gt;: Separate rendering into a &quot;renderer&quot; object, which can be split into its own process if needed.  It will also make leapfrog pixel-reading simpler.&lt;/p&gt;

&lt;p&gt;End product will&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;receive message from matlab containing curves&lt;/li&gt;
&lt;li&gt;decode curves into vectors&lt;/li&gt;
&lt;li&gt;convert into gl_curves (renderables)&lt;/li&gt;
&lt;li&gt;pass to likelihood object&lt;/li&gt;
&lt;li&gt;convert log-posterior to message&lt;/li&gt;
&lt;li&gt;transmit back to matlab&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;all functionality is already implemented, just need to weed out code rot and put it together.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Getting weird link errors.  For some reason, the build system is using gcc instead of g++ to link my main program.  Will try re-running kjb_add_makefiles
&lt;strong&gt;Refactor&lt;/strong&gt;: specify all parameters at command-line (width, height, cameras, etc)&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Meanwhile, I'm planning the program&lt;/p&gt;

&lt;p&gt;inputs:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;* dimensions
* cameras
* likelihood parameters
* 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Steps&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;* initialize likelihood
* initialize TCP server
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;Abandoning GL_context from sampler_cpp.  writing one-off offscreen-buffer class.  writing new GL_context struct with just the stuff we need&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Reducing dependence on perspective_camera object in favor of using modelview and projection matrices.  We'll be working with matrices from matlab.&lt;/p&gt;

&lt;p&gt;Updated Camera_render_wrapper to use matrices instead of camera.&lt;/p&gt;

&lt;p&gt;Updated Abstract_mv_likelihood to use matrices in addition to cameras (for backward compatibility).&lt;/p&gt;
</description>
				<pubDate>Tue, 08 Oct 2013 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2013/10/08/work-log</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2013/10/08/work-log</guid>
			</item>
		
			<item>
				<title>Work Log</title>
				<description>

&lt;div class=&quot;meta-info&quot;&gt;
&lt;table&gt;
    &lt;tr&gt;
        &lt;th&gt;Project&lt;/th&gt;
        &lt;td&gt;&lt;a href=&quot;/ksimek/research/projects/tulips.html&quot;&gt;Tulips&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Subproject&lt;/th&gt;
        &lt;td&gt;Data Association v3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Working path&lt;/th&gt;
        &lt;td&gt;projects/&amp;#8203;tulips/&amp;#8203;trunk/&amp;#8203;src/&amp;#8203;matlab/&amp;#8203;data_association_3&lt;/td&gt;
    &lt;/tr&gt;

    &lt;tr&gt;
        &lt;th&gt;SVN Revision&lt;/th&gt;
        &lt;td&gt;15229&lt;/td&gt;
    &lt;/tr&gt;


&lt;/table&gt;

    Unless otherwise noted, all filesystem paths are relative to the &quot;Working path&quot; named above.
&lt;/div&gt;


&lt;p&gt;Thought more on split/merge.  Could make merge a special case of split, and the move becomes a split/split process.  At every step, pick a track, pick a subset of observations from that track, then reassign them all to an existing curve or a new curve.  It's symmetric, which is nice, but the probability of a merge being selected becomes vanishingly small very quickly.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Looking into issues with offline pair-candidate generation.  So many bad candidates are coming up, and their ML values look better than the good candidates.&lt;/p&gt;

&lt;p&gt;A big issue is that we aren't penalizing missing data (gaps/tails), and we don't enforce multiple-view consistency (only two views need to match).&lt;/p&gt;

&lt;p&gt;Option 1: use a stronger likelihood to rule out background curves.  Use per-pixel foreground/background classifier?  Use color consistency metric?  Sample from posterior, project, check pixels, repeat -- gets a monte-carlo of marginal likelihood.&lt;/p&gt;

&lt;p&gt;Option 2: use foreground/background classifier to classify fragments; misusing a background fragment in a foreground pair results in some penalty.&lt;/p&gt;

&lt;p&gt;Option 1 is nice theoretically, but has lots of moving parts (new features, training, monte-carlo issue, need to know how thick to make branches.)  Unlikely to get working in two weeks.  Also isn't clear what the role of the detector curves are.  Are they data?  data-driven proposals?&lt;/p&gt;

&lt;p&gt;Options 2 is a bit weird, but doesn't introduce dimensionality issues.  But also doesn't specifically address the issue of bizzare candidates being introduced.  For example, a bad pair could still be proposed as long as they're both foreground curves.&lt;/p&gt;
</description>
				<pubDate>Thu, 03 Oct 2013 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2013/10/03/work-log</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2013/10/03/work-log</guid>
			</item>
		
	</channel>
</rss>
