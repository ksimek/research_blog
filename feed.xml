<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>KLS Research Blog</title>
		<description>Nothing to see here...</description>
		<link>http://vision.sista.arizona.edu/ksimek/research</link>
		<atom:link href="http://vision.sista.arizona.edu/ksimek/research/feed.xml" rel="self" type="application/rss+xml" />
		
			<item>
				<title>FIRE - background reading, thinking and planning</title>
				<description>&lt;h2&gt;Structure Learning&lt;/h2&gt;

&lt;p&gt;The fact that we have a 500-dimensional dynamical system offers opportunities to learn high-dimensional relationships.  I spent some time looking into structure learning.&lt;br/&gt;
&lt;strong&gt;Variational Bayes&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://mlg.eng.cam.ac.uk/zoubin&quot;&gt;Zoubin Ghahramani slides on variational bayes&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Variational EM could learn LDS with unknown structure or switching state space model.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Dirichlet Process&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Video: &lt;a href=&quot;http://videolectures.net/mlss2010_griffiths_isfd/&quot;&gt;Inferring structure from data&lt;/a&gt;, Tom Griffiths, Cognitive Science and Machine Learning Summer School, 2010&lt;/p&gt;

&lt;p&gt;Maybe could be used to learn LDS structure. Griffiths shows a noisy-or model with unknown dimension, using a Dirichlet process prior.  At its center is a rank-defficient matrix constructed from product of NxM and MxN matrices, where M &amp;lt; N.  Could use something similar to learn sparse dynamics matrix, but we're dealing with continuous-valued data rather than binary-valued.  If this can be done, there must be existing literature on it, will dig further.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Parameter Learning&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This tech report from Ghahramani and Hinton derives the EM for learning LDS parameters and latent states jointly.  For the M step, they derive expressions for the full transition matrix, plus the system and observation noise covariance, and initial state.  For the E step, they use Kalman for forward estimation followed by a backward recursion.  We're more interested in a sparse representation of dynamics.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.learning.eng.cam.ac.uk/zoubin/papers/tr-96-2.pdf&quot;&gt;Parameter Estimation for Linear Dynamical Systems&lt;/a&gt;[pdf]&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;MARRS&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://journal.r-project.org/archive/2012-1/RJournal_2012-1_Holmes~et~al.pdf&quot;&gt;Multiple Auto-regressive State-Space models for Analyzing Time-series Data&lt;/a&gt; by Elizabeth E. Holmes, Eric J. Ward, Kellie Wills&lt;/p&gt;

&lt;p&gt;This &lt;a href=&quot;http://cran.r-project.org/web/packages/MARSS/index.html&quot;&gt;R package&lt;/a&gt; handles learning and inference in general state-space models, with unspecified or semi-specified model structure.  It uses EM to infer the model and latent state jointly.  On the plus side, it handles missing data, and the model is very flexible.  On the down side, it doesn't handle i.i.d. data in an obvious way (although could handle a small number by repeating matrix blocks).  Could probably implement some form of the TIES model, sans prior.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Other R Packages&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.jstatsoft.org/v36/i12/&quot;&gt;dlm - An R Package for Dynamic Linear Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://cran.r-project.org/web/packages/KFAS/index.html&quot;&gt;KFAS -  Kalman Filter and Smoother for Exponential Family State Space Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://cran.r-project.org/web/packages/FKF/FKF.pdf&quot;&gt;FKF: Fast Kalman Filter&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;Modeling&lt;/h2&gt;

&lt;p&gt;Kobus pointed out that the short time-frame means second-order dynamics likely won't emerge.&lt;/p&gt;

&lt;h2&gt;Matlab CSV File parsing&lt;/h2&gt;

&lt;p&gt;Matlab only handles CSV files with numeric-valued fields.  We have dates and strings (and possibly others), so we need to write our own CSV parser.&lt;/p&gt;

&lt;p&gt;Creating a &lt;em&gt;.meta file for each &lt;/em&gt;.csv file, which describes column names and datatypes.  Currently only three ways to parse a column: &quot;numeric&quot;, &quot;mm/dd/yy/ date&quot;, and &quot;ignore&quot;.  Possibly more in the future.&lt;/p&gt;

&lt;p&gt;Wrote code for parsing meta files and csv files (all code is in projects/fire/trunk/src):&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;io/fire_read_meta.m&lt;/code&gt; - Reads a .meta file into a 1xN structure array.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;io/fire_read_csv.m&lt;/code&gt; - Reads a .csv file, using the corresponding .meta file to determine names and datatypes.&lt;/li&gt;
&lt;/ul&gt;

</description>
				<pubDate>Tue, 04 Mar 2014 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2014/03/04/work-log</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2014/03/04/work-log</guid>
			</item>
		
			<item>
				<title>Proposal Practice Post-mortem</title>
				<description>&lt;h2&gt;General Advice&lt;/h2&gt;

&lt;p&gt;Take a more top-down approach; split into &quot;Modeling&quot; and &quot;Inference&quot; sections.  give details on request.&lt;/p&gt;

&lt;p&gt;Tailor more toward committee audience and less to a general audience.&lt;/p&gt;

&lt;p&gt;Questions to ask yourself:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;What is the purpose of this talk to this audience?&lt;/li&gt;
&lt;li&gt;What do you want the audience to remember?&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Structure the talk and paper more tree, with details on the leafs.&lt;/p&gt;

&lt;p&gt;Get the the Arabidopsis application faster.&lt;/p&gt;

&lt;p&gt;Have a &quot;map&quot; of the various research parts; show how they connect and where we are currently.    &lt;strong&gt;Need a stronger big picture.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Focus on the key pieces of research, ditch the rest (e.g. drop DTW focus).&lt;/p&gt;

&lt;h2&gt;Probably okay?  (not comments)&lt;/h2&gt;

&lt;p&gt;Related work (SfM and SfS).  I was worried I left out too many recent developments, but no one commented on it (but it's in the paper).&lt;/p&gt;

&lt;h2&gt;Issues&lt;/h2&gt;

&lt;p&gt;Need stronger transitions between topics.&lt;/p&gt;

&lt;p&gt;Unclear how much left there is to do.&lt;/p&gt;

&lt;p&gt;Unclear what the key contributions are, and what is just &quot;other stuff we did&quot;.&lt;/p&gt;

&lt;p&gt;Too much time talking about alternative approaches.  (I can probably cut quite a bit, time-wise by taking this advice).&lt;/p&gt;

&lt;p&gt;Graphics: backprojection lines too light.&lt;/p&gt;

&lt;h2&gt;Too Much:&lt;/h2&gt;

&lt;p&gt;Phenotyping&lt;/p&gt;

&lt;p&gt;projective geometry (a few good pictures would be better)&lt;/p&gt;

&lt;p&gt;Linear approximation details (e.g. emphasis on running time).&lt;/p&gt;

&lt;h2&gt;Confusion&lt;/h2&gt;

&lt;p&gt;Temporal component of model is not for camera motion, but for trackingnonrigid deformation.&lt;/p&gt;

&lt;p&gt;3-tuple slide: add a ground plane to images to convey 3D, maybe eliminate hard black outlines what falsely convey 2D image-plane context.&lt;/p&gt;

&lt;p&gt;How is DTW section connected to the rest?&lt;/p&gt;

&lt;p&gt;When I say parts are &quot;given&quot; or &quot;assumed&quot;, what does that mean?  i.e. how are they given?  (This should be clearer when I re-orgainze top-down.  Natually handled in inference)&lt;/p&gt;

&lt;p&gt;What does it mean that CS model is more &quot;expressive&quot; than squared exponential model?&lt;/p&gt;

&lt;p&gt;Likelihood linearization was confusing, esp. the justification.  Since local linearization isn't novel, could just say we linearize, and exploit conditional independence of points to do it in linear running time.&lt;/p&gt;

&lt;h2&gt;Misc TODO:&lt;/h2&gt;

&lt;p&gt;In paper, mention that index estimation is currently slow and ucnlear if fit for MCMCDA approach.&lt;/p&gt;

&lt;h2&gt;Questions&lt;/h2&gt;

&lt;p&gt;What constraints are there on data collection?  Are cameras required to be on a turntable?&lt;/p&gt;

&lt;p&gt;What is the connection between the covariance function and the species?  Do you think the cubic spline covariance function this is generally applicable?&lt;/p&gt;

&lt;p&gt;What is the connection to the science?  What can we learn about species from this?  (I could probably talk about two aspects - (a) can build models using data recovered from 3D reconstruction and (b) learning population models in heirarchical BGP (phenotypes as parameters))&lt;/p&gt;
</description>
				<pubDate>Sat, 08 Feb 2014 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2014/02/08/work-log</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2014/02/08/work-log</guid>
			</item>
		
			<item>
				<title>GPLVM & GPDM notes</title>
				<description>&lt;p&gt;[1] N. Lawrence, “Probabilistic Non-linear Principal Component Analysis with Gaussian Process Latent Variable Models,” The Journal of Machine Learning Research, vol. 6, Dec. 2005.&lt;/p&gt;

&lt;p&gt;Beautifully illustrates the relationship between GPLVM and kernel PCA with a unifying objective function.  PPCA marginalizes the input values and maximizes the linear parameters.  GPLVM marginalizes the &quot;linear parameters&quot; (more generally, the kernel that generalizes the linear parameters), and maximizes the inputs.&lt;/p&gt;

&lt;p&gt;Paper provides the derivative of the marginal likelihood w.r.t. K, which greatly simplifies our derivations in &lt;a href=&quot;/ksimek/research/2013/11/25/reference/&quot;&gt;this post&lt;/a&gt; and this one(/ksimek/research/2013/11/10/reference/).  We used inside-out derivation, Lawrences uses forward method, which is clearer.&lt;/p&gt;

&lt;p&gt;[2] R. Urtasun, D. J. Fleet, A. Hertzmann, and P. Fua, “Priors for people tracking from small training sets,” presented at the Computer Vision, 2005. ICCV 2005. Tenth IEEE International Conference on, 2005, vol. 1, pp. 403–410.&lt;/p&gt;

&lt;p&gt;Application: golf swing, walk&lt;/p&gt;

&lt;p&gt;Learn inputs, (\mathbf{x}), with independent prior, (exp(-\mathbf{x}&lt;sup&gt;\top&lt;/sup&gt; \mathbf{x})/2).&lt;/p&gt;

&lt;p&gt;\partial L / \partial K = K&lt;sup&gt;{-1}&lt;/sup&gt; Y Y&lt;sup&gt;\yop&lt;/sup&gt; K&lt;sup&gt;{-1}&lt;/sup&gt; - D K&lt;sup&gt;{-1}&lt;/sup&gt;&lt;/p&gt;
</description>
				<pubDate>Wed, 29 Jan 2014 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2014/01/29/reference</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2014/01/29/reference</guid>
			</item>
		
			<item>
				<title>Planning - Spring Interdisciplanry Computational Intelligence Seminar</title>
				<description>&lt;h2&gt;Spring Topics of Interest&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;Active learning / Deep Learning&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Active Learning of an Action Detector from Untrimmed Videos - Grauman&lt;/li&gt;
&lt;li&gt;A Convex Optimization Framework for Active Learning?&lt;/li&gt;
&lt;li&gt;ImageNet Classification with Deep Convolutional Neural Networks (hinton)&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;Optimization (not mcmc)&lt;/h2&gt;

&lt;p&gt;e.g. &quot;relaxation&quot; methods&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Estimating the 3D Layout of Indoor Scenes and its Clutter from Depth Sensors&lt;/li&gt;
&lt;li&gt;Holistic Scene Understanding for 3D Object Detection with RGBD cameras&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;Scenes and captions&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;From Large Scale Image Categorization to Entry-Level Categories - &quot;best paper, iccv 2013&quot;&lt;/li&gt;
&lt;li&gt;NEIL: Extracting Visual Knowledge from Web Data&lt;/li&gt;
&lt;li&gt;A Sentence is Worth a Thousand Pixels&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;Detection&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;HOGgles: Visualizing Object Detection Features&lt;/li&gt;
&lt;li&gt;Finding the Best from the Second Bests -- Inhibiting Subjective Bias in Evaluation of Visual Tracking Algorithms&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;Miscellaneous&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Latent Data Association: Bayesian Model Selection for Multi-target Tracking - ian reid  (possibly of interest to Ernesto?)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Relative Attributes For Large-scale Abandoned Object Detection (Quanfu and Prasad's paper) &lt;a href=&quot;http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Fan_Relative_Attributes_for_2013_ICCV_paper.pdf&quot;&gt;pdf&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Inferring “Dark Matter” and “Dark Energy” from Videos&lt;/p&gt;

&lt;h2&gt;Schedule &lt;/h2&gt;

&lt;p&gt;Rough schedule for first 7 weeks&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Practice Talk - Colin&lt;/li&gt;
&lt;li&gt;Practice Talk - Kyle&lt;/li&gt;
&lt;li&gt;Practice talk - Andrew&lt;/li&gt;
&lt;li&gt;Learning TBD  (Deep learning or active learning) - Kobus&lt;/li&gt;
&lt;li&gt;Learning TBD - Qiyam&lt;/li&gt;
&lt;li&gt;Fast object segmentation in unconstrained video - Kate?&lt;/li&gt;
&lt;li&gt;(ECCV, no session?)&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Remaining order TBD&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Parallel Markov Chain Monte Carlo for Nonparametric Mixture Models - Colin&lt;/li&gt;
&lt;li&gt;Tree Shape Priors with Connectivity Constraints using Convex Relaxation on General Graphs - kyle?&lt;/li&gt;
&lt;li&gt;MCMC Sampling - Jinyan&lt;/li&gt;
&lt;li&gt;TBD - Ernesto&lt;/li&gt;
&lt;/ul&gt;

</description>
				<pubDate>Fri, 17 Jan 2014 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2014/01/17/work-log</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2014/01/17/work-log</guid>
			</item>
		
			<item>
				<title>HPC meeting</title>
				<description>&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://sites.google.com/a/case.edu/hpc-upgraded-cluster/cluster-faq#TOC-What-are-modules-&quot;&gt;Modules&lt;/a&gt; automatically set path and library paths for specific libraries.&lt;/li&gt;
&lt;li&gt;HPC has a nice &lt;a href=&quot;&quot;&gt;web interface&lt;/a&gt; for subitting and managing jobs.  ATM, the only way to get stdout and stderr outputs.&lt;/li&gt;
&lt;li&gt;Intel compiler can use openMP to automatically leverage coprocessor cards.  Can use same code&lt;/li&gt;
&lt;li&gt;Thrust already installed (&lt;code&gt;module cuda&lt;/code&gt;); boost is header-only.&lt;/li&gt;
&lt;li&gt;Apparently, the copropocessor cards run linux, and I can ssh into them!  Still unsure what the host address is.&lt;/li&gt;
&lt;/ul&gt;

</description>
				<pubDate>Fri, 17 Jan 2014 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2014/01/17/hpc-meeting</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2014/01/17/hpc-meeting</guid>
			</item>
		
			<item>
				<title>Dis Prop (ctd); new HPC </title>
				<description>&lt;p&gt;Continue writing dissertation proposal.  Worked on SfM, MVS literature review.  Spent quite some time trying to understand self-calibration.  The issue is that with a general perspective camera, SfM can only perform reconstruction up to a projective ambiguity (most of the SfM literature of late is apparently reticent about this?).  It turns out, if we fix at least one intrinsic parameter (how about skew = 0? or aspect ration = 1?) then we get a metric reconstruction (which maybe explains why it's no longer covered in SfM papers).&lt;/p&gt;

&lt;p&gt;This shows that bundle adjustment can give a metric reconstruction, but the question remains how to initialize it.  Pollefeys et. al (1998) propose an analytical self-calibration solution.  Snavely et al. (2007) apparently just use bundle adjustment anyway, presumably using a simplified pinhole camera (no skew or ppo) with a reasonable default for &lt;em&gt;f&lt;/em&gt;, or EXIF tags when possible.  Brown and Lowe (2005) initialize each new camera with the old camera's intrinsics, no word on how the first pair is initialized (maybe obvious but I missed it?).&lt;/p&gt;

&lt;h2&gt;New HPC &lt;/h2&gt;

&lt;p&gt;UA just installed their new 80-node HPC cluster and by a stroke of luck, Ive gotten early access to it!  It looks like all machines have 16 CPU cores and 256 GB RAM; 60 nodes have multiple GPU cards while the other 20 have Intel PHI general purpose compute cards.  It's amazing to query the cluster and see the entire thing at 0% utilization... that won't last long!  Having fun poking around it and reading the IBM LSF manuals &lt;a href=&quot;http://publibfp.dhe.ibm.com/epubs/pdf/c2253460.pdf&quot;&gt;2&lt;/a&gt; (the job queueing system).&lt;/p&gt;

&lt;p&gt;I found the following resource to be very useful, even though it's from University of Miami's personal LSF installation:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.ccs.miami.edu/hpc/lsf/9.1.1/&quot;&gt;unofficial LSF 9.1.1 Documentation site&lt;/a&gt; (University of maimi)

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.ccs.miami.edu/hpc/lsf/9.1.1/print/lsf_foundations.pdf&quot;&gt;Basics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.ccs.miami.edu/hpc/lsf/9.1.1/print/lsf_admin.pdf&quot;&gt;Jobs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The hew official documents I could find were less useful:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Command Reference [&lt;a href=&quot;http://publibfp.dhe.ibm.com/epubs/pdf/c2753051.pdf&quot;&gt;pdf&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Administration Reference [&lt;a href=&quot;http://publibfp.dhe.ibm.com/epubs/pdf/c2253460.pdf&quot;&gt;pdf&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Configuration Reference[&lt;a href=&quot;http://publibfp.dhe.ibm.com/epubs/pdf/c2753061.pdf&quot;&gt;pdf&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;Notes&lt;/h3&gt;

&lt;p&gt;Okay great!  Got a general idea of how to use the system from the &lt;a href=&quot;http://www.ccs.miami.edu/hpc/lsf/9.1.1/print/lsf_users_guide.pdf&quot;&gt;user guide&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;bsub&lt;/code&gt; - submit default job queue&lt;/li&gt;
&lt;li&gt;&lt;code&gt;bsub -q &amp;lt;queue-name&amp;gt;&lt;/code&gt; - submit specific job queue&lt;/li&gt;
&lt;li&gt;&lt;code&gt;bsub -I&lt;/code&gt; - interactive job&lt;/li&gt;
&lt;li&gt;&lt;code&gt;bjobs&lt;/code&gt; - view submitted jobs&lt;/li&gt;
&lt;li&gt;&lt;code&gt;bqueues&lt;/code&gt; - list info for all queues&lt;/li&gt;
&lt;li&gt;&lt;code&gt;bparams&lt;/code&gt; - details for default queue&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lsload&lt;/code&gt; - list load on hosts&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lshosts&lt;/code&gt; - list hosts w/ configuration&lt;/li&gt;
&lt;li&gt;&lt;code&gt;bhosts&lt;/code&gt; - view batch server hosts (what's a batch server?)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lsid&lt;/code&gt; - cluster info (name and master host)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lsrun&lt;/code&gt; - run a command on a free host&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lsgrun&lt;/code&gt; - run a command on a group of free hosts&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lsltakss&lt;/code&gt; - view and add local tasks (huh?)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lsrtasks&lt;/code&gt; - view and add remote tasks (huh?)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;bkill 1234&lt;/code&gt; -  kill job 1234&lt;/li&gt;
&lt;li&gt;&lt;code&gt;bkill -r&lt;/code&gt; - force removal of job (if hung after kill?)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;bstop&lt;/code&gt; - suspend job&lt;/li&gt;
&lt;li&gt;`bresume - resume job&lt;/li&gt;
&lt;li&gt;&lt;code&gt;btop 1234&lt;/code&gt; - move job 1234 to top of queue&lt;/li&gt;
&lt;li&gt;&lt;code&gt;bbot 1234&lt;/code&gt; - move job 1234 to bottom of queue&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;On gpu* machines&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;nvidia-smi&lt;/code&gt; list details for all gpu cards (and running processes?)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;On phi* machines&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;micinfo&lt;/code&gt; lists details for all coprocessor cards&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Also MPI is supported&lt;/p&gt;

&lt;p&gt;Discovered two large gsfs disks (192 TB and 43 TB, resp.).  Apparently GSFS is a GPU-enabled encrypted disk.  No write permissions ATM&lt;/p&gt;

&lt;h3&gt;Questions&lt;/h3&gt;

&lt;p&gt;Some random thoughts while using the system&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;can/should we get Matlab?  Octave?&lt;/li&gt;
&lt;li&gt;Subversion?&lt;/li&gt;
&lt;li&gt;write permissions on GSFS disks?&lt;/li&gt;
&lt;li&gt;No job report email after calling &lt;code&gt;bsub -u ksimek@email.arizona.edu&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
				<pubDate>Wed, 15 Jan 2014 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2014/01/15/work-log</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2014/01/15/work-log</guid>
			</item>
		
			<item>
				<title>Talk w/ Kobus Re: Dissertation Proposal</title>
				<description>&lt;p&gt;Met w/ Kobus today to discuss the proposal for the first time.&lt;/p&gt;

&lt;h4&gt;Organization&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;Key idea&lt;/strong&gt;: Branching GP.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Close 2nd&lt;/strong&gt;: Model selection&lt;/p&gt;

&lt;p&gt;Other stuff like high-throughput phenotyping, biological modeling, multi-view stereo, etc. take a back seat (but should be mentioned)&lt;/p&gt;

&lt;h4&gt;Key sections&lt;/h4&gt;

&lt;p&gt;The structure isn't rigid, but the three main sections that need to be strong are: (1) Literature review, (2) current progress, (3) future work.&lt;/p&gt;

&lt;p&gt;Didn't ask about &quot;Assumptions and Limitations&quot;.  Kobus mentioned that things like that can protect you, but they don't come up very often.  Seems not critical, use best judgement.&lt;/p&gt;

&lt;p&gt;&quot;Broader impacts&quot; or &quot;Importance of Topic&quot; section could be a heading to what would otherwise just fall into the introduction.&lt;/p&gt;

&lt;p&gt;It seems the &quot;Outcomes&quot; section is probably best weaved into the &quot;proposed work&quot;.&lt;/p&gt;

&lt;p&gt;It seems listing the dissertation chapters isn't strictly necessarilly, either.&lt;/p&gt;

&lt;h4&gt;Future work&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;Full automatic system
Automatic camera detection
Apply to another domain (can be vague; can change later)

Less likely:
    leafs, flowers, etc.  Stick to GP's
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;Miscellaneous&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;Don't stress about correctness.  This is a proposal, i.e. *pre* investigation.  
Let's wait until the end of the week to decide if we need to reschedule.
&lt;/code&gt;&lt;/pre&gt;
</description>
				<pubDate>Mon, 13 Jan 2014 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2014/01/13/work-log</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2014/01/13/work-log</guid>
			</item>
		
			<item>
				<title>Work Log</title>
				<description>&lt;p&gt;Layout organization, pick a section, start writing.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.ohio.edu/eecs/graduate/documents/upload/PhDDissertationProposalOutline2-06.pdf&quot;&gt;Proposal guide, CS department, Ohio University&lt;/a&gt; [pdf]&lt;/p&gt;

&lt;p&gt;In researching multiple-view plant datasets, I came across the &lt;a href=&quot;http://www.imageclef.org/node/179&quot;&gt;LifeCLEF 2014 challenge&lt;/a&gt;.  The goal is plant-species identification from single images.  Images are of several different organs (leafs, fruit, stems, branches) or entire structures (branches, entire plant).  Most images are in the wild, but some (leafs) are from a flatbed scanner.  All images are given a one-to-five rating based on their quality.  Even this isn't the type of task we're focusing on, it's valuable to note what types of tasks the community is focusing on.&lt;/p&gt;

&lt;p&gt;Also available is a fish classification task from videos.  It might be interesting to try to track GP curves in an image and classify fish based on their GP parameters (temporal and spatial).  The cubic spline model is already scale-invariant, so scale issues might not be a big deal.  GP-LVM model might be even more interesting.&lt;/p&gt;

&lt;p&gt;TODO - look into CVPR 2013 &quot;thin branch&quot; paper.  Existing datasets?  Their dataset?  Literature reivew?&lt;/p&gt;
</description>
				<pubDate>Tue, 07 Jan 2014 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2014/01/07/work-log</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2014/01/07/work-log</guid>
			</item>
		
			<item>
				<title>Roughing out Proposal</title>
				<description>&lt;p&gt;Simultaneous stereo and tracking of nonrigid structure for semantic reconstruction&lt;/p&gt;

&lt;h2&gt;Summary&lt;/h2&gt;

&lt;h2&gt;Problem statement&lt;/h2&gt;

&lt;p&gt;We have collected a dataset consisting of multiple specimens of Arabidopsis Thaliana, imaged at several angles.  Specimens come from two different genetic strains, and imaging occurred at various stages of development.  The elapsed time between the first and last image is several minutes, and in many cases, plants exhibit noticible motion between the first and last image.  Our primary goal is to recover the full 3D branching structure of each specimen, but we also seek to recover the motion between frames as it may contain useful phenotype information.  Our reconstrution will be composed of geometric primitives, from which plant scientists may extract valuable phenotype traits like branch angle and curvature.&lt;/p&gt;

&lt;p&gt;In a sense, our problem encompasses two complementary areas in computer vision, tracking and multi-view stereo.  In classical tracking, the camera is fixed and the goal is to recover motion; in stereo, the camera is moving and the goal is to recover the fixed structure.  In our problem, both structure and camera undergo motion, with each object's motion confounding inference of the other.  Is an object's 2D motion best explained by parallax or by motion in 3D?   Either of these conclusions (or both) could the case; underconstrained problems like these require additional assumptions to be solved uniquely.  We a Bayesian approach to the problem, encoding these assumptions in the form of a prior distribution over structure and motion, and using Bayesian inference to recover both the optimal solution and a distribution over alternative solutions.&lt;/p&gt;

&lt;p&gt;Phenotype traits:
* branch depth,
* branch angles,
* stem curvature,
* torsion,
* phototropism,
* interbranch distances,
* biomass,
* etc.&lt;/p&gt;

&lt;p&gt;In modelling branching stem structures, we propose a representation that is simultaneously expressive and tractible.&lt;/p&gt;

&lt;p&gt;(The following might be best posed in related work, after describing SfM and SfS backgroun)&lt;/p&gt;

&lt;p&gt;In addition to the difficulties interent to simultaneous inference of structure and motion, the nature of plant structure poses specific challenges to the reconstruction task.  Our primary structures of interest are plant stems, which are nearly absent of texture features.  Most structure-from-motion algorithms use so-called keypoints to find matches between images, and high quality keypoints cannot be found without strong texture features.   The thin geometry of plant stems also poses difficulties, especially with popular shape-from-silhouette algorithms.  The thin backprojection cones that arise from stems often fail to intersect, because cameras are imperfectly calibrated and stems undergo motion between views.  Algorithms exist to improve camera pose estimates by minimizing reconstruction error, but these algorithms assume structure is stationary.&lt;/p&gt;

&lt;p&gt;Plant structure also poses challenges on the on the tracking side,&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  * nonrigid/nonparametric structure
  * nonrigid motion
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Modelling challenges&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  * unknown topology, cardinality
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;the primary difficulty is that the object and camera move simultaneously.  Since our goal is 3D tracking,&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;By jointly modeling camera error, 3D spatial structure, and temporal motion, we seek to improve upon existing approaches that ignore one or more of these aspects, while providing a rich description of the 4D scene.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We propose a Bayesian&lt;/p&gt;

&lt;p&gt;Model camera, structure, motion directly&lt;/p&gt;

&lt;p&gt;The proposed work will&lt;/p&gt;

&lt;p&gt;The primary contribution of this research will be a novel method for robust reconstruction of thin, textureless structure from multiple views, a specific case of multiple view reconstruction that is rarely considered.  To this end, our work will make novel contributions in several areas, including&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A probabilistic generative model for branching structure in 3D that is applicable across many domains and problem settings.&lt;/li&gt;
&lt;li&gt;A Bayesian formulation of multiple-view 4D reconstruction of thin branching structure that is robust to camera miscalibration and nonrigid motion.&lt;/li&gt;
&lt;li&gt;Several novel edge-based likelihood functions, which are robust to noise and missing data and can be evaluated efficiently on GPU hardware.&lt;/li&gt;
&lt;li&gt;A novel formulation of multiple-view reconstruction as a Bayesian data-association problem, and an approach for appoximate inference.&lt;/li&gt;
&lt;li&gt;An efficient dynamic programming algorithm for dense multiple-view point correspondences of linear structure.&lt;/li&gt;
&lt;li&gt;A novel, principled approach to the problem of Bayesian model selection in the presence of nonlinear likelihood terms.&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;Importance of Topic&lt;/h2&gt;

&lt;h3&gt;Plant biology, food source&lt;/h3&gt;

&lt;p&gt;Researchers estimate that global food production must double by 2050 to meet the expected growth in demand \cite{tilman2011}.  Advances in high-throughput genotyping have yielded great advancements in the understanding of plant biology at the micro- level, but without efficient methods for macro-level analysis, the relationship between genetic variation and practical measures like crop yields or drought resistance remains difficult to study.  High-throughput phenotyping provides a way to bridge this micro-/macro- gap by automatically quantifying observable traits (e.g morphology, behavior), allowing macro-level study of plants from different genetic strains at a large scale.&lt;/p&gt;

&lt;p&gt;Existing high-throughput systems&lt;/p&gt;

&lt;p&gt;and demand for simpler, lower-cost systems has increased in recent years&lt;/p&gt;

&lt;p&gt;The earliest high throughput phenotyping platforms (HTPPs) used expensive sensing equipment, proving the effectiveness of HTPPs but illustrating a need for lower-cost solutions \cite{TODO}.  TODO:  Make an argument about the lack of 3D analysis of full branching architecture.  Use \cite{fiorani2013} to survey existing methods,  use \cite{biskup2007} as example similar to ours.&lt;/p&gt;

&lt;p&gt;High-throughput phenotyping&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;understanding mutatations
phenotyping is a limiting factor in breeding
high-throughput genotyping has left a gap in the phenotyping 
relating genes to biological traits (e.g. crop yields, drought resistance, root system efficiency)
Understand the effects of genetic variation in terms of practical measures like crop yields or drought resistance.
understand connections between genetics and macro structure
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;Reconstruction&lt;/h3&gt;

&lt;p&gt;Multiple view 3D reconstruction is a widely-studied area in computer vision.  While this area has seen great success in recent years, most research has focused on reconstructing large structures with considerable surface area \cite{TODO}.  Most of these approaches fail in the presence of thin, textureless structure like those exhibited by plant stems.  The applications for multiple-view reconstruction are&lt;/p&gt;

&lt;h2&gt;#&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;By separating the concerns of modelling and inference, our approach should generalize well to other research areas that involve branching linear systems, like neuron tracing \cite{TODO}, vascular segmentation \cite{TODO}, and root structure architecture \cite{TODO}.  We intend to 
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Prior Research&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Biological application&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;RSA, Hypotrace, etc.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Multi-view Reconstruction&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;em&gt;PMVS first attempt&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;The well-known patch-based multiple view stereo algorithm (PMVS) uses full-color images to reconstruct a 3D mesh \cite{furukawa2010}, making them effective when a silhouette is unavailable.  For each image patch, a similar image patch is sought in other views such that both appearance and depth are roughly consistent between matches.  However, due to ambiguities that arise in flat image regionts, the algorithm starts by matching special keypoints whose surface exhibit distinct texture, and filling-in patches in-between.  In our situation, our surfaces are extremely thin (often three pixels or fewer in width) and exhibit no notable texture features, causing patch-based reconstructions to fail.  Further, PMVS assumes rigid structure and perfectly calibrated cameras; our plant's slight movements and our miscalibrated cameras would likely cause the algorithm's consistency checks to fail.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;PMVS Second attempt&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;The well known asdfjl;kj uses appearance consistency to estimate the depth of image patches.  It relies heavilly on texture data to find inital matches, which makes it ineffective at reconstructing textureless structure like plant stems.  Futhermore, like the visual-hull based methods, our miscalibrated cameras and slightly moving plant structure would cause the consistency checks in this algorithm to fail.
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Tracking&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Bayesian Model Choice&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Curve prior model&lt;/p&gt;

&lt;p&gt;  Methods for modeling smooth curves and surfaces have been widely studied since the early days of computer vision.  The popular active countour or &quot;snakes&quot; algorithm models smoothness by an energy functional penalizing discontinuities in position or higher-order derivatives \cite{asdf}.  When the energy function penalizes the second-derivative, the model becomes equivalent to Euler's &quot;elastica&quot; model of an ideal elastic rod, which also mimicks the classic mechanical splines used in traditional drafting and shipbuilding \cite{levien2008}.  Other spline models have been developed for different applications, including visual modelling, data interpolation (e.g. cubic splines), data smoothing (cubic smoothing splines), and visual modelling (B-splines).  In computer vision, splines provide a convenient representation for nonrigid structure and motion.  Thin-plate splines \cite{wood2003} have been applied to reconstruction of deformable surfaces \cite{schmid} \cite{mcinerney1993} \cite{perriollat2011}.&lt;/p&gt;

&lt;p&gt;  Gaussian process (GP) theory provides an elegant probabilistic representation of continous curves and surfaces\cite{williams2006}.  As shown in \cite{wahba1990}, classic cubic smoothing splines can be reformulated as the maximum posterior curve under a particular GP prior and i.i.d. Gaussian noise.  Other GP models can acheive different types of smoothness, like simple continuity (white noise process), or (C&lt;sup&gt;\inf)&lt;/sup&gt; smoothness (squared-exponential covariance process).  By formulating the curve model probabilisitically, GP's can represent and propagate uncertainty in continuous curves in a principled and tractible manner .&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Curve models&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;Edge-based likelihoods / energy functions&lt;/li&gt;
&lt;li&gt;Thin plate splines&lt;/li&gt;
&lt;li&gt;Deformable models&lt;/li&gt;
&lt;li&gt;Sampling-based Structure From Motion&lt;/li&gt;
&lt;li&gt;Misc Structure from Motion&lt;/li&gt;
&lt;li&gt;Model-based Reconstruction&lt;/li&gt;
&lt;li&gt;Evaluation
  Middlebury metric.
  Evaluation of&lt;/li&gt;
&lt;li&gt;Gaussian Process&lt;/li&gt;
&lt;li&gt;Miscellaneous&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;Limitations or Key Assumptions&lt;/h2&gt;

&lt;p&gt;foliage doesn't significantly obscure branching structure.&lt;/p&gt;

&lt;h2&gt;Potential Outcomes, Contributions to Knowledge&lt;/h2&gt;

&lt;h2&gt;Proposed Chapters&lt;/h2&gt;

&lt;h2&gt;TODO&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;We model stems as a set of points along the medial axis of a tube with circular cross-sections.&lt;/li&gt;
&lt;/ul&gt;

</description>
				<pubDate>Tue, 07 Jan 2014 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2014/01/07/proposal_rough</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2014/01/07/proposal_rough</guid>
			</item>
		
			<item>
				<title>Dissertation Proposal - Preparation, Organization</title>
				<description>&lt;p&gt;Spent morning and early afternoon doing preparation for my dissertation proposal by doing some background reading and laying out a rough sketch of what I'd like to cover.&lt;/p&gt;

&lt;p&gt;Read Ernesto's dissertation proposal.  The bulk of Ernesto's proposal seemed to be his two published papers, with an extended literature review and a brief description of remaining work to be done.  This isn't too surprising, since he was so far along in his research when he wrote the proposal.  Unfortunately, I have no such publications to draw on, but I may be able to use part of the tracking paper, which I was third author on.  But on the whole, I'll need to lean more in the &quot;proposal&quot; direction, and less in the &quot;dissertation&quot; direction than Ernesto was able to.  Time to dig for more representative examples of the proposal I'll be writing...&lt;/p&gt;

&lt;p&gt;Read &lt;a href=&quot;http://www.gwr.arizona.edu/writingproposal1.htm&quot;&gt;this article&lt;/a&gt;, describing a dissertation proposal in science.  The second page has a nice organization of possible sections for my proposal.&lt;/p&gt;

&lt;p&gt;According to the aforementioned article, length is 10-40 pages.  This is supported by Ernesto's proposal (25 pages w/ references), and &lt;a href=&quot;http://www.cs.unc.edu/~cssa/guides/proposals/&quot;&gt;these example proposals from computer science&lt;/a&gt;, which fall between 9 and 20 pages, with references.  The number of references is between 14 and 85, with a median around 20.&lt;/p&gt;

&lt;p&gt;I was surprised to see the level of brevity and abstractness in most of the example proposals above.  I'm assuming these were written early in the research phase, shortly after the end of coursework;  it is encouraging to see that this document need not be a &lt;em&gt;tour de force&lt;/em&gt;.  Overall, I'm thinking that since I've developed my research so extensively, my proposal will probably be heavier on references and detail, and likely longer than the average.  However, I need to avoid falling into the trap of trying to write my dissertation instead of a proposal.&lt;/p&gt;

&lt;p&gt;I'm feeling more confident now that I can finish this by the deadline I set for myself of January 31, and a reschedule hopefully won't be needed.  My initial investigation suggested that writing the proposal should take three to nine months, a surprise that knocked the wind out of me.   I realize now that much of that time is spent investigating topics, doing initial research, and reviewing literature, not specifically writing.  Since I've completed those steps (extensively!) it should be reasonable to assume I can write the full document in 2.5 weeks.  I'd like to get Kobus a first draft within the week, with at least the rough structure layed out, so he can correct my course if I'm way off.&lt;/p&gt;

&lt;p&gt;I briefly reviewed the computer science department's graduate program policy for comp exams (something I haven't looked it in probably far too long!) and realized I should have scheduled my dissertation proposal in Fall 2011!!  It should be no surprise the department was urging me to complete this right away!&lt;/p&gt;

&lt;h2&gt;Organizational Notes&lt;/h2&gt;

&lt;p&gt;Below are notes I jotted down while reading Ernesto's proposal.&lt;/p&gt;

&lt;h3&gt;Parts&lt;/h3&gt;

&lt;p&gt;Research items worth covering in the proposal (or dedicating chapters to in the dissertation proper)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Edge extraction, Stroke-width transform skeleton.&lt;/li&gt;
&lt;li&gt;Bayesian Model

&lt;ul&gt;
&lt;li&gt;GPU-enabled edge-based likelihood

&lt;ul&gt;
&lt;li&gt;Blurred-difference likelihood&lt;/li&gt;
&lt;li&gt;Chamfer likelihood&lt;/li&gt;
&lt;li&gt;GMM likelihood&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Prior: &quot;Branching Gaussian Process&quot;

&lt;ul&gt;
&lt;li&gt;Modification for multimodal likelihoods (Importance sampling)&lt;/li&gt;
&lt;li&gt;novel covariance function&lt;/li&gt;
&lt;li&gt;Temporal modeling&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Marginalization: Laplace Approximation&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Initial estimate: Dynamic programming algorithm for multi-view triangulation&lt;/li&gt;
&lt;li&gt;Inference: MCMCDA&lt;/li&gt;
&lt;li&gt;Index estimation

&lt;ul&gt;
&lt;li&gt;Analytical gradients derived&lt;/li&gt;
&lt;li&gt;Dimensionality reduction? (for pixel likelihood)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;Background / Related work&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Multi-view Reconstruction

&lt;ul&gt;
&lt;li&gt;Visual Hull&lt;/li&gt;
&lt;li&gt;Voxel-based (Hough transform)&lt;/li&gt;
&lt;li&gt;Space carving (Hough + photoconsistency)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Biological application

&lt;ul&gt;
&lt;li&gt;Root structure Architecture papers&lt;/li&gt;
&lt;li&gt;Neuron Tracing&lt;/li&gt;
&lt;li&gt;Vascular segmentation and modeling&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.google.com/url?sa=t&amp;amp;rct=j&amp;amp;q=&amp;amp;esrc=s&amp;amp;source=web&amp;amp;cd=1&amp;amp;cad=rja&amp;amp;ved=0CCwQFjAA&amp;amp;url=http%3A%2F%2Fwww.cv-foundation.org%2Fopenaccess%2Fcontent_cvpr_2013%2Fpapers%2FTabb_Shape_from_Silhouette_2013_CVPR_paper.pdf&amp;amp;ei=SELLUs63G4e9rgHwuYHYAw&amp;amp;usg=AFQjCNHAaFQi-2H2zTQUOSm67WI2p87odw&amp;amp;sig2=L0V4Txw-fqypkloITh-dlA&amp;amp;bvm=bv.58187178,d.aWM&quot;&gt;Tree branches - Amy Tabb, CVPR-2013&lt;/a&gt; [pdf]&lt;/li&gt;
&lt;li&gt;L-systems - &lt;a href=&quot;http://vladlen.info/publications/metropolis-procedural-modeling/&quot;&gt;Metropolis Procedural Modeling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;S-C Zhu plant paper - Bayesian reconstruction of 3d shapes and scenes from a single image&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Tracking

&lt;ul&gt;
&lt;li&gt;Oh et al.&lt;/li&gt;
&lt;li&gt;Ernesto&lt;/li&gt;
&lt;li&gt;Tracklets? (TODO)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Bayesian Model Choice

&lt;ul&gt;
&lt;li&gt;P.J. Green, RJMCMC&lt;/li&gt;
&lt;li&gt;Laplace approximation&lt;/li&gt;
&lt;li&gt;Candidates estimator&lt;/li&gt;
&lt;li&gt;Examples without model choice?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Curve models

&lt;ul&gt;
&lt;li&gt;Song-Chun Zhu - Parsing Images into Regions, Curves, and Curve Groups&lt;/li&gt;
&lt;li&gt;snakes&lt;/li&gt;
&lt;li&gt;Curve indicator random field&lt;/li&gt;
&lt;li&gt;Implicit definitions&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Edge-based likelihoods / energy functions

&lt;ul&gt;
&lt;li&gt;Curve indicator random field&lt;/li&gt;
&lt;li&gt;Joe Schlecht's papers&lt;/li&gt;
&lt;li&gt;Chamfer matching

&lt;ul&gt;
&lt;li&gt;Shotton, PAMI 2007 - Multi-Scale Categorical Object Recognition Using Contour Fragments&lt;/li&gt;
&lt;li&gt;Shotton, ICCV 2005 - Contour-Based Learning for Object Detection&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Poon &amp;amp; Fleet 2002 - Hybrid Monte Carlo Filtering: Edge-Based People Tracking&lt;/li&gt;
&lt;li&gt;TODO: More examples of edges in bayesian inference&lt;/li&gt;
&lt;li&gt;Gradient Vector Flow&lt;/li&gt;
&lt;li&gt;Blurred Gaussian&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Thin plate splines

&lt;ul&gt;
&lt;li&gt;Ferarri - Accurate Object Detection with Deformable Shape Models Learnt from Images&lt;/li&gt;
&lt;li&gt;TODO: others&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Deformable models

&lt;ul&gt;
&lt;li&gt;Fua, Uratsen (TODO)&lt;/li&gt;
&lt;li&gt;Monocular Template-based Reconstruction of Inextensible Surfaces Perriollat, Hartley, and Bartoli&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Sampling-based Structure From Motion

&lt;ul&gt;
&lt;li&gt;Dellaert - SfM Without Correspondence (and other?)&lt;/li&gt;
&lt;li&gt;Forsyth - Bayesian Structure From Motion; Joy of Sampling&lt;/li&gt;
&lt;li&gt;TODO: dig here&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Misc Structure from Motion

&lt;ul&gt;
&lt;li&gt;Semantic Structure From Motion?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Model-based Reconstruction

&lt;ul&gt;
&lt;li&gt;Joe, Luca's work&lt;/li&gt;
&lt;li&gt;Savarese, Fei-Fei - 3D generic object categorization, localization and pose estimation&lt;/li&gt;
&lt;li&gt;TODO: dig here&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Evaluation

&lt;ul&gt;
&lt;li&gt;Diadem Challenge&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Gaussian Process

&lt;ul&gt;
&lt;li&gt;Basic: Williams and Rasmussen&lt;/li&gt;
&lt;li&gt;GP-LVM&lt;/li&gt;
&lt;li&gt;Urstein Ulenbeck process&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Miscellaneous

&lt;ul&gt;
&lt;li&gt;Stroke width Transform&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;Layout Ideas&lt;/h3&gt;

&lt;p&gt;An initial strategy for laying out the proposal is below.  I may want to rethink this after reading &lt;a href=&quot;http://www.gwr.arizona.edu/writingproposal1.htm&quot;&gt;this guide&lt;/a&gt;, which suggests a much higher-level strategy.  However, the level of detail in the strategy that follows may be justified by the late stage I'm at with my research; could contribute to a stronger argument.  Should sleep on it.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Intro.&lt;/em&gt; describe problem, motivate and give background.
&lt;em&gt;Body.&lt;/em&gt; One Seciton per part, with one or more of the following parts&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Background and related work (show it's sensible and proven, but also novel in this case)&lt;/li&gt;
&lt;li&gt;Progress so far (include derived equations, intermediate results, etc.)&lt;/li&gt;
&lt;li&gt;Work to be done (defend why it's promising).&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;Future Work&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Leafs, flowers?&lt;/li&gt;
&lt;li&gt;Root structure architecture?&lt;/li&gt;
&lt;li&gt;Neurons?&lt;/li&gt;
&lt;li&gt;Vascular modeling&lt;/li&gt;
&lt;li&gt;Likelihood improvements - color, patch-based?&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;Diagrams&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Camera setup

&lt;ul&gt;
&lt;li&gt;One camera, multiple angles&lt;/li&gt;
&lt;li&gt;Multiple cameras, many angles&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Degenerate likelihood

&lt;ul&gt;
&lt;li&gt;(rough diagram in notes)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data / edges&lt;/li&gt;
&lt;li&gt;Likelihoods

&lt;ul&gt;
&lt;li&gt;BD Likelihood

&lt;ul&gt;
&lt;li&gt;GMM per-pixel&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;Equations&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Two-phase likelhood&lt;/li&gt;
&lt;li&gt;Curve Covariance - 1. smooth, 2. Rate and offset, 3. temporal&lt;/li&gt;
&lt;li&gt;Branching covariance&lt;/li&gt;
&lt;li&gt;Laplace approximation&lt;/li&gt;
&lt;li&gt;Marginal likelihood approx w/ Laplace&lt;/li&gt;
&lt;li&gt;Mean approx w/ Laplace&lt;/li&gt;
&lt;li&gt;Index gradients&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;Miscellaneous Thoughts&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Think more on diagrams; what do I have?  what do I need?&lt;/li&gt;
&lt;li&gt;Width as depth-cue; single-view reconstruction&lt;/li&gt;
&lt;li&gt;GPU-based gradient?  Can render index w/ each edge. tell GPU how index moves to avoid re-rendering full model.&lt;/li&gt;
&lt;li&gt;Is mean-offset really a problem?  If there's no size/shape distortion (pure translation), maybe not in many applications.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Use chicken/egg for index optimization in the wild&lt;/strong&gt;. As opposed to energy minimization we use for ground-truth.  The data will drive the fitting well enough so clever index fitting isn't necessary.&lt;/li&gt;
&lt;li&gt;Remember to draw from the blog (TODO)&lt;/li&gt;
&lt;li&gt;Add MRF smoothness to pixel Likelihood? (to address non-dependence)&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;Proposal TODO:&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Contact Dr. Zhang or Dr. Gniady about joining the committee.&lt;/li&gt;
&lt;li&gt;Complete form in UAccess.&lt;/li&gt;
&lt;li&gt;Look for quality blog posts to draw content/equations&lt;/li&gt;
&lt;li&gt;Lit Review

&lt;ul&gt;
&lt;li&gt;Look into tracklets; MCMCDA?  Ernesto has a referencek&lt;/li&gt;
&lt;li&gt;examples ignoring model choice problem?&lt;/li&gt;
&lt;li&gt;More edge-based likelihood applications

&lt;ul&gt;
&lt;li&gt;Ferrari papers?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;Misc TODO&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Dig into (Vladlen Koltun's literature)[http://vladlen.info/] on reconstruction.&lt;/li&gt;
&lt;li&gt;Dig into Ferrari edge/contour literature.&lt;/li&gt;
&lt;/ul&gt;

</description>
				<pubDate>Mon, 06 Jan 2014 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2014/01/06/work-log</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2014/01/06/work-log</guid>
			</item>
		
	</channel>
</rss>
