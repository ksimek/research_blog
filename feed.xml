<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>KLS Research Blog</title>
		<description>Nothing to see here...</description>
		<link>http://vision.sista.arizona.edu/ksimek/research</link>
		<atom:link href="http://vision.sista.arizona.edu/ksimek/research/feed.xml" rel="self" type="application/rss+xml" />
		
			<item>
				<title>Work Log</title>
				<description>

&lt;div class=&quot;meta-info&quot;&gt;
&lt;table&gt;
    &lt;tr&gt;
        &lt;th&gt;Project&lt;/th&gt;
        &lt;td&gt;&lt;a href=&quot;/ksimek/research/projects/tulips.html&quot;&gt;Tulips&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Subproject&lt;/th&gt;
        &lt;td&gt;Data Association v3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Working path&lt;/th&gt;
        &lt;td&gt;projects/&amp;#8203;tulips/&amp;#8203;trunk/&amp;#8203;src/&amp;#8203;matlab/&amp;#8203;data_association_3&lt;/td&gt;
    &lt;/tr&gt;

    &lt;tr&gt;
        &lt;th&gt;SVN Revision&lt;/th&gt;
        &lt;td&gt;15229&lt;/td&gt;
    &lt;/tr&gt;


&lt;/table&gt;

    Unless otherwise noted, all filesystem paths are relative to the &quot;Working path&quot; named above.
&lt;/div&gt;


&lt;p&gt;Goals:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ground truth - trace datasets 7 through 10&lt;/li&gt;
&lt;li&gt;build new attachment covariance&lt;/li&gt;
&lt;li&gt;reconstruct ground truth using new attachment covariance&lt;/li&gt;
&lt;li&gt;work attachment covariance function into ml&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;Building Full Attachment Covariance Matrix&lt;/h2&gt;

&lt;p&gt;See &lt;code&gt;attachment/construct_attachment_covariance.m&lt;/code&gt; (filename still in flux).&lt;/p&gt;

&lt;p&gt;Issue: The recursive definition of the attached curve kernel that we outlined yesterday is too expensive to implement naively.  Can implement by re-using precomputed values, but the branch point isn't necessarilly one of the observed points, so it's not necesarilly represented in the curve's &lt;code&gt;prior_K&lt;/code&gt;.  This means we need to construct covariance entries between each of the attachment points and their parent and child curves.  Then we can run the &quot;memoized&quot; recursive function.&lt;/p&gt;

&lt;h2&gt;Base self covariance&lt;/h2&gt;

&lt;p&gt;Key idea: each child curve has a &quot;base self covariance&quot; that is extra covariance inherited from the branch point on parent that is added to all points of the curve self-covariance matrix.  That curve, in turn, has a base covariance, that &lt;em&gt;it&lt;/em&gt; inherits, all the way to the root, whose base covariance is the &quot;position variance&quot; parameter.  Thus, the leaves have a base covariance that is the sum of all the incremental variance of all the branches to the root.&lt;/p&gt;

&lt;p&gt;The base covariance is an NxN matrix, where N is the number of views.  We construct each in isolation, and then cumulatively sum them from root to leaf.&lt;/p&gt;

&lt;p&gt;Every element of the curve's observed-point covariance matrix is increased by the base_covariance relative to it's entry; e.g. if element (k_{ij}) is the covariance between a point in view 3 and a point in view 5, you'll add the (3,5) element of the base covariance matrix.&lt;/p&gt;

&lt;h2&gt;Base Parent covariance&lt;/h2&gt;

&lt;p&gt;Each child curve also hase a &quot;parent covariance&quot; (for lack of a better term), which is the set of covariances between the branch point and each of the parent points.  Again, this is inherited recursively; just as the curve's covariance has it's self-covariance added, the parent covariance has the paren'ts self-covariance added.&lt;/p&gt;

&lt;p&gt;This will be used for the off-diagonal blocks of the full attachment covariance matrix.&lt;/p&gt;

&lt;h2&gt;Implementation Misc&lt;/h2&gt;

&lt;p&gt;Issues during implementation and testing of &lt;code&gt;construct_attachment_covariance&lt;/code&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;replacing Cell-of-structs with struct-array:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Corrs = cell2mat(Corrs);
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;The trivial code path of calling &lt;code&gt;blkdiag&lt;/code&gt; takes 500ms. Wow!&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Running on the WACV dataset is giving bad results.&lt;/p&gt;

&lt;p&gt;Looks like the covariance matrix is different from the one in the reference implementation.&lt;/p&gt;

&lt;p&gt;TODO:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Need to convert from &quot;index of branch index&quot; to simply &quot;branch index&quot;.&lt;/li&gt;
&lt;li&gt;More debugging.&lt;/li&gt;
&lt;/ul&gt;

</description>
				<pubDate>Thu, 12 Sep 2013 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2013/09/12/work-log</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2013/09/12/work-log</guid>
			</item>
		
			<item>
				<title>Work Log - Branching prior covariance</title>
				<description>

&lt;div class=&quot;meta-info&quot;&gt;
&lt;table&gt;
    &lt;tr&gt;
        &lt;th&gt;Project&lt;/th&gt;
        &lt;td&gt;&lt;a href=&quot;/ksimek/research/projects/tulips.html&quot;&gt;Tulips&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Subproject&lt;/th&gt;
        &lt;td&gt;Data Association v3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Working path&lt;/th&gt;
        &lt;td&gt;projects/&amp;#8203;tulips/&amp;#8203;trunk/&amp;#8203;src/&amp;#8203;matlab/&amp;#8203;data_association_3&lt;/td&gt;
    &lt;/tr&gt;

    &lt;tr&gt;
        &lt;th&gt;SVN Revision&lt;/th&gt;
        &lt;td&gt;15229&lt;/td&gt;
    &lt;/tr&gt;


&lt;/table&gt;

    Unless otherwise noted, all filesystem paths are relative to the &quot;Working path&quot; named above.
&lt;/div&gt;


&lt;p&gt;In the past, we've formulated the branching prior covariance matrix by starting with an independent-curve block-diagonal covariance matrix and multiplying by an &quot;attachment matrix.&quot;  This works when the branching point appears in the index set, but we'd like to allow branching from any continuous point along the curve.  Stated differently, we currently model branching using a discritized model, but we'd prefer to express branching using the underlying continuous gaussian process.  This means modelling branching using the covariance function, rather than by manipulating the covariance matrix.&lt;/p&gt;

&lt;div&gt;
&lt;p&gt;
The key observation here is that in addition to each point's smooth curvature variance, it inherits the covariance of its parent's branch point.   In order to model correlation between curves, we extend the definition of &quot;index&quot; to add the curve index, \(c_i\), in addition to point index and time/view index.  Thus, index is now a triple: (c_i, p_i, t_i).  Note that we've changed our notation; previously point index was \(t_i\) and time/view index was \(v_i\).  The new notation uses \(p_i\) and \(t_i\) respectively, to avoid confusion between spacial and temporal dimensions.  
&lt;/p&gt;

&lt;p&gt;
Let's introduce two functions, \(\text{branch_curve}(c_i)\) and \(\text{branch_point}(c_i)\), which return the curve index and point index of curve \(c_i\)'s branch point, resepectively, or zero if \(c_i\) is a root curve.  We'll also use the convenience function \(\text{branch}(i)\), which is shorthand for full branch index, i.e. the tuple \(\text{branch_curve}(c_i), \text{branch_point}(p_i), t_i)\).  Note that the time-index \(t_i\) is preserved when getting the branch index.
&lt;/p&gt;

&lt;p&gt;
Without loss of generality, we'll assume curves are indexed in topological order, with parents appearing occurring before descendants.  If there are multiple connected components in the graph, it will be important that all root nodes have a lower index than non-root nodes, so we can add a sentinal node with index \(c_i = 0\), and attach all root curves to it before ordering. (Note to self: breadth-first search order might be simpler to describe).   The branching covariance function is now:
&lt;/p&gt;

\[
\begin{align}
k\left( i, j \right) 
     &amp;= 
    k\left( (c_i, p_i, t_i), (c_j, p_j, t_j) \right)  \\
     &amp;= k_\text{base} ( i, j ) +
     \begin{cases}
     k(j, i) &amp; \text{if } c_i &gt; c_j = 0 \\
     \sigma_o  &amp; \text{if } \text{isroot}(c_i) \text{ and } \text{isroot}(c_j) \text{ and } c_i = c_j &amp;&amp;  \\
     0 &amp; \text{if } \text{isroot}(c_i) \text{ and } \text{isroot}(c_j) \text{ and } c_i \neq c_j \\
     k(i, \text{branch}(j)) &amp; \text{otherwise} 
    \end{cases}
\end{align}
\]

&lt;p&gt;
For convenience, we've used the \(k(i,j) \) to stand-in for \(k\left((c_i, p_i, t_i), (c_j, p_j, t_j)\right)\).
  Here, \(k_\text{base}(i,j)\) is the independent curve covariance (e.g. cubic spline covariance w/ perturbations).   In our case, \(k_\text{base}(\dot)\) is zero if \(c_i \neq c_j\), but this isn't necessarilly required.
  &lt;/p&gt;
&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;The first case just simplifies the definition by ensuring that if i and j are related, the ancestor always appears in the first position.&lt;/li&gt;
&lt;li&gt;The second case handles the offset variance that allow root curves to translate away from the origin.&lt;/li&gt;
&lt;li&gt;The third case ensures zero covariance between disconnected trees.&lt;/li&gt;
&lt;li&gt;The fourth case inherits covariance from the second parameter's parent curve.  Note that \(c_j\) is always a non-root curve; if it were, one of the first three cases would handle it.&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;Testing &lt;/h2&gt;

&lt;h2&gt;TODO&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Finish tracing wacv datasets 7 through 11.&lt;/li&gt;
&lt;li&gt;Test the new covariance function against a matrix-based approach.&lt;/li&gt;
&lt;li&gt;Test the new covariance function by reconstructing 9-view sequence using WACV datasets.&lt;/li&gt;
&lt;li&gt;implement attachment-based ml using new covariance function&lt;/li&gt;
&lt;/ul&gt;

</description>
				<pubDate>Tue, 10 Sep 2013 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2013/09/10/work-log</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2013/09/10/work-log</guid>
			</item>
		
			<item>
				<title>Work Log - WACV results</title>
				<description>

&lt;div class=&quot;meta-info&quot;&gt;
&lt;table&gt;
    &lt;tr&gt;
        &lt;th&gt;Project&lt;/th&gt;
        &lt;td&gt;&lt;a href=&quot;/ksimek/research/projects/tulips.html&quot;&gt;Tulips&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Subproject&lt;/th&gt;
        &lt;td&gt;Data Association v3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Working path&lt;/th&gt;
        &lt;td&gt;projects/&amp;#8203;tulips/&amp;#8203;trunk/&amp;#8203;src/&amp;#8203;matlab/&amp;#8203;data_association_3&lt;/td&gt;
    &lt;/tr&gt;

    &lt;tr&gt;
        &lt;th&gt;SVN Revision&lt;/th&gt;
        &lt;td&gt;15229&lt;/td&gt;
    &lt;/tr&gt;


&lt;/table&gt;

    Unless otherwise noted, all filesystem paths are relative to the &quot;Working path&quot; named above.
&lt;/div&gt;


&lt;p&gt;WACV deadline has passed, but still working on reconstructing ground truth, because it's  a good test on the end-to-end system.&lt;/p&gt;

&lt;p&gt;Open issues:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;weird issue with branching&lt;/li&gt;
&lt;li&gt;clear up math issue with branching&lt;/li&gt;
&lt;/ul&gt;


&lt;h1&gt;Branching bug&lt;/h1&gt;

&lt;p&gt;Fixed!  It was a bug in &lt;code&gt;infer_branch_points()&lt;/code&gt; function.  I was assuming Corr.curve_sm used the same  index set as Corr.ll_means_flat, which it was not.&lt;/p&gt;

&lt;p&gt;I wanted to use &lt;code&gt;Corr.curve_sm&lt;/code&gt;, because it is precomputed in &lt;code&gt;corr_to_likelihood()&lt;/code&gt;, and it would save me an extra semi-expensive call to the cubic spline smoother, &lt;code&gt;csaps()&lt;/code&gt;.  In the end, I modified &lt;code&gt;corr_to_likelihood&lt;/code&gt; to save the smoothing amount and used it to call csaps inside &lt;code&gt;run_wacv()&lt;/code&gt; to re-smooth the curves.  At least &lt;code&gt;csaps&lt;/code&gt; is faster (linear time) than computing the posterior mean (quadratic).&lt;/p&gt;

&lt;h2&gt;Test Results&lt;/h2&gt;

&lt;p&gt;Results on dataset 2:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ksimek/research/img/2013-09-06-result_dataset_2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Looks good!&lt;/p&gt;

&lt;h2&gt;All Results&lt;/h2&gt;

&lt;p&gt;Running on all 11 datasets...&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Matlab is running out of memory on the second dataset (apparently)&lt;/p&gt;

&lt;p&gt;When running directly on second dataset, it's fine.  Is the pass on the first dataset leaking memory or something?&lt;/p&gt;

&lt;p&gt;Maybe one of the mex files?&lt;/p&gt;

&lt;p&gt;It's weird, because we've run on dataset #2 tens of times without this problem...&lt;/p&gt;

&lt;p&gt;Now running directly on dataset #2 is resulting in a curve of over 1 million points.  investigating...&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Solution: the image dimensions were reversed (should be nrows X ncols, not width x height).  The triangulations were nutso, and after projecting and resampling, the number of points was in the millions.  It's interesting that it's so easy to make this algorithm blow up; are there other; will need to keep an eye out for more benign ways to trigger this kind of explosion.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2&gt;Ground truth issues&lt;/h2&gt;

&lt;p&gt;Encountered this error message when running on all ground truth datasets:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Warning: file wacv-2012/datasets/3/ground_truth_2d.gt2
Missing curves in view 6: 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16,

Warning: file wacv-2012/datasets/6/ground_truth_2d.gt2
Missing curves in view 2: 2, 3,

Warning: file wacv-2012/datasets/6/ground_truth_2d.gt2
Missing curves in view 3: 3,

Warning: file wacv-2012/datasets/6/ground_truth_2d.gt2
Missing curves in view 4: 2, 3,

Warning: file wacv-2012/datasets/6/ground_truth_2d.gt2
Missing curves in view 6: 2, 3,

Warning: file wacv-2012/datasets/6/ground_truth_2d.gt2
Missing curves in view 8: 1, 3,

Warning: file wacv-2012/datasets/6/ground_truth_2d.gt2
Missing curves in view 10: 3,

Warning: file wacv-2012/datasets/6/ground_truth_2d.gt2
Missing curves in view 15: 3,

Warning: file wacv-2012/datasets/6/ground_truth_2d.gt2
Missing curves in view 19: 3,

Warning: file wacv-2012/datasets/6/ground_truth_2d.gt2
Missing curves in view 23: 2, 3,

Warning: file wacv-2012/datasets/6/ground_truth_2d.gt2
Missing curves in view 27: 3,

Warning: file wacv-2012/datasets/6/ground_truth_2d.gt2
Missing curves in view 31: 3,

Warning: file wacv-2012/datasets/6/ground_truth_2d.gt2
Missing curves in view 35: 3,
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Dataset 6 looks to be totally crap; need to investigate.&lt;/p&gt;

&lt;h2&gt;Found a bug in &lt;code&gt;corr_to_likelihood&lt;/code&gt; that led to out-of-bound indexing.&lt;/h2&gt;

&lt;p&gt;Looks like Liu never finished ground-truthing dataset &lt;code&gt;2010-01-26/arab_1_36&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Skipping for now; lets see if others are okay...&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Dataset 9 is broken. investigating...&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Dataset 9 seems not terrible, actually.  A few missing views on the hard-to-trace views of a few curves.&lt;/p&gt;

&lt;p&gt;Some cuves were so short that they contained only one point, which violated an assert that requires all curves to be at least 2 points long.  Adjusted the bezier-to-sampled-curve code so that the final point is always included.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Finished running all.  issues&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;dataset 1 is very rough&lt;/li&gt;
&lt;li&gt;datasets 6 was skipped&lt;/li&gt;
&lt;li&gt;datasets 7 - 11 are worthless.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Need to re-trace 6 through 11.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Finished re-trace of 6.  Whew, 90 minutes... that sucked.  Reconstruction looks good now.&lt;/p&gt;

&lt;h2&gt;TODO&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Finish tracing datasets 7 through 11.&lt;/li&gt;
&lt;li&gt;Work on attached-curve-multi-view prior and reconstruction.&lt;/li&gt;
&lt;/ul&gt;

</description>
				<pubDate>Fri, 06 Sep 2013 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2013/09/06/work-log</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2013/09/06/work-log</guid>
			</item>
		
			<item>
				<title>Work Log - WACV Deadline</title>
				<description>&lt;p&gt;Late-hour realization: not sure how to handle attachment matrix when multiple-views are allowed.  Deriving the correct equations will take all afternoon; no time.  Decided to remove the tracking part from the paper.&lt;/p&gt;

&lt;h1&gt;Reconstructions&lt;/h1&gt;

&lt;p&gt;code in &lt;code&gt;wacv-2012/run_wacv.m&lt;/code&gt;.  Example call:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;gt_paths = arrayfun(@(x) sprintf('wacv-2012/datasets/%d', x), 1:11, 'UniformOutput', false);
gt_cam_fmt = [gt_paths{i} '/cal/calib_%d.txt'];
gt_fname = [gt_paths{i} '/ground_truth_2d.gt2'];
[mu, lengths] = run_wacv(gt_fname, gt_cam_fmt, 1:4:36, [397,530]', params, 1);
mu = reshape(mu, 3, []);
mu = mat2cell(mu, 3, lengths);
colors = lines(numel(mu));
for i = 1:numel(mu);
    c = mu{i};
    col = colors(i, :);
    plot3(c(1,:), c(2,:), c(3,:), '-o', 'Color', col);
    hold on
end
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Results&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;Dataset #1&lt;/em&gt;: curve #1 has some weird shape.  Probably and error in GT&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Dataset #2&lt;/em&gt;: again weirdness in curve #1.  Now I'm guessing it's an attachment issue:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ksimek/research/img/2013-09-05-bad_result_c2_pass1.png&quot; alt=&quot;bad result&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Run again without attachments.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Dataset #2&lt;/em&gt;: curve 1 issue is better; now exhibiting some weird stray points.  few views, bad indices?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ksimek/research/img/2013-09-05-c2-pass2.png&quot; alt=&quot;result 2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;It looks like the base curves are trying to attach to the &lt;em&gt;end&lt;/em&gt; of curve #1, instead of the beginning.&lt;/p&gt;
</description>
				<pubDate>Thu, 05 Sep 2013 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2013/09/05/work-log</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2013/09/05/work-log</guid>
			</item>
		
			<item>
				<title>Work Log - Branching ML, debugging, training</title>
				<description>

&lt;div class=&quot;meta-info&quot;&gt;
&lt;table&gt;
    &lt;tr&gt;
        &lt;th&gt;Project&lt;/th&gt;
        &lt;td&gt;&lt;a href=&quot;/ksimek/research/projects/tulips.html&quot;&gt;Tulips&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Subproject&lt;/th&gt;
        &lt;td&gt;Data Association v3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Working path&lt;/th&gt;
        &lt;td&gt;projects/&amp;#8203;tulips/&amp;#8203;trunk/&amp;#8203;src/&amp;#8203;matlab/&amp;#8203;data_association_3&lt;/td&gt;
    &lt;/tr&gt;

    &lt;tr&gt;
        &lt;th&gt;SVN Revision&lt;/th&gt;
        &lt;td&gt;15229&lt;/td&gt;
    &lt;/tr&gt;


&lt;/table&gt;

    Unless otherwise noted, all filesystem paths are relative to the &quot;Working path&quot; named above.
&lt;/div&gt;


&lt;h1&gt;Blockwise precision decomposition issue&lt;/h1&gt;

&lt;p&gt;Bug: when attaching, was getting incorrect results for estimated location of attachment.  Our copmutation used a subset of data points on the parent curve nearby the branch point to estimate the distribution of the branch point position.  We were simply taking a submatrix of the full (decomposed) precision matrix, which wasn't correct, due to the way the full decomposed matrix was constructed.&lt;/p&gt;

&lt;h2&gt;Submatrix of decomposition != decomposition of submatrix&lt;/h2&gt;

&lt;p&gt;When using subset of variables, need to be able to get submatrix of noise precision and prior.&lt;/p&gt;

&lt;p&gt;Let \((s' s) = S\), and let \(P\) be a matrix that selects rows of \(S\).  if you want to decompose the submatrix \(P S P'\), in general, you cannot simply take the submatrix \(P s P'\).  There are at-least two special case where this is valid:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;\(s\) is a Cholesky decomposition of \(S\).  But since \(S\) is degenerate in our case, we can't use Cholesky.&lt;/li&gt;
&lt;li&gt;\(S\) is block-diagonal, and \(P\) doesn't split-up the blocks.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;I thought that condition 2 was being satisfied, because I foolishly assumed the eigenvector matrix produced by eigenvalue decomposition was preserving block structure.  I had to modify &lt;code&gt;correspondence/flatten_sort_and_reverse.m&lt;/code&gt; to perform eigenvalue decomposition on each block individually.  I had previously determined that operating on groups of five blocks at once is faster than operating individually, but we'll have to sacrifice this speed-up for now.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Okay, fixed the precision problem.  After attaching stem 2 to stem 1, Corrs{2}.mu_b now looks reasonable.&lt;/p&gt;

&lt;p&gt;Still getting really low ML's...&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Bingo!  Bug in &lt;code&gt;curve_tree_ml_2.m&lt;/code&gt; that was introduced when we started allowing non-zero means when evaluating our conditional normal distribution.   Recall the equation for marginal likelihood (reproduced from &lt;a href=&quot;/ksimek/research/2013/07/12/marginal-likelihood/&quot;&gt;this post&lt;/a&gt;):&lt;/p&gt;

&lt;div&gt;
\[
\begin{align}
     p(y) &amp;= \frac{Z_{l,3d} }{Z_l}\frac{1}{Z}  \exp\{x^\top S(S + S K S)^{-1} S x \} \\
     &amp;= \frac{Z_{l,3d} }{Z_l}\frac{1}{Z}  \exp\{x^\top s^\top(I + s K s^\top)^{-1} s x \} \\
     &amp;= \frac{Z_{l,3d} }{Z_l} \mathcal{N}\left (sx ; 0, (I + s K s^\top) \right )
\end{align}
\]
&lt;/div&gt;




&lt;div&gt;Aside: in the second line, we've substituded the decomposition, \(s^\top s = S\), which we use in practice.  &lt;/div&gt;


&lt;p&gt;However, this equation assume zero mean.  If we include a nonzero mean, the \(s\) matrix distributes to both \(y\) and \(\mu\):&lt;/p&gt;

&lt;div&gt;
\[
\begin{align}
     p(y) &amp;= \frac{Z_{l,3d} }{Z_l}\frac{1}{Z}  \exp\{(x-\mu)^\top s^\top(I + s K s^\top)^{-1} s (x - \mu) \} \\
     &amp;= \frac{Z_{l,3d} }{Z_l} \mathcal{N}\left (sx ; s \mu, (I + s K s^\top) \right )
\end{align}
\]
&lt;/div&gt;


&lt;p&gt;In our implementation, we weren't multiplying \(\mu\) by \(s\).  Fixing this seems to fix the low ML issue:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Corrs = attach(Corrs, 2,1,12, -12, params);
curve_tree_ml_2(Corrs, params, data_)

    ans =

       2.0903e+04

Corrs_ind = attach(Corrs, 2,0,0,0, params);
curve_tree_ml_2(Corrs_ind, params, data_)

    ans =

       2.0804e+04
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the case above, ML is roughly maximized when branch index is -12 and start index is 12, which seems to agree with the data, visually.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Next:
* get attachment, reversal, and branch points from ground truth
* store ml_2d with corr. update on merge. use during ml computation instead of data_
* branching in training ML
* traing with branching
* branch-wise reconstruction.&lt;/p&gt;
</description>
				<pubDate>Tue, 03 Sep 2013 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2013/09/03/work-log</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2013/09/03/work-log</guid>
			</item>
		
			<item>
				<title>Work Log - Misc.</title>
				<description>

&lt;div class=&quot;meta-info&quot;&gt;
&lt;table&gt;
    &lt;tr&gt;
        &lt;th&gt;Project&lt;/th&gt;
        &lt;td&gt;&lt;a href=&quot;/ksimek/research/projects/tulips.html&quot;&gt;Tulips&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Subproject&lt;/th&gt;
        &lt;td&gt;Data Association v3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Working path&lt;/th&gt;
        &lt;td&gt;projects/&amp;#8203;tulips/&amp;#8203;trunk/&amp;#8203;src/&amp;#8203;matlab/&amp;#8203;data_association_3&lt;/td&gt;
    &lt;/tr&gt;

    &lt;tr&gt;
        &lt;th&gt;SVN Revision&lt;/th&gt;
        &lt;td&gt;15229&lt;/td&gt;
    &lt;/tr&gt;


&lt;/table&gt;

    Unless otherwise noted, all filesystem paths are relative to the &quot;Working path&quot; named above.
&lt;/div&gt;


&lt;h1&gt;Monday IVILAB infrastructure meeting&lt;/h1&gt;

&lt;p&gt;I'll be organizing the Computational Intelligence seminar this semester.&lt;/p&gt;

&lt;p&gt;Will need to&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Arrange volunteers&lt;/li&gt;
&lt;li&gt;send announcements&lt;/li&gt;
&lt;li&gt;send reminders to speakers&lt;/li&gt;
&lt;li&gt;Set up seminar web page&lt;/li&gt;
&lt;/ul&gt;


&lt;h1&gt;Building efficient curve-tree ML.&lt;/h1&gt;

&lt;p&gt;Significant rework.&lt;/p&gt;

&lt;p&gt;New field: branch_K and branch_mu to store mean and covariance of all points in curve.
Prior_k now does not include offset covariance; stored in branch_K.
mu_b and Sigma_b now store the branch point means and covariances for all views&lt;/p&gt;

&lt;p&gt;fix kernel to not include offset index&lt;/p&gt;

&lt;h1&gt;Issues&lt;/h1&gt;

&lt;p&gt;Finished implementation.  Has bugs.&lt;/p&gt;

&lt;h2&gt;Start-point has no effect&lt;/h2&gt;

&lt;p&gt;Example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;start_pt = [0 100];
ml = [];
for i = 1:2
    Corrs = attach(Corrs, 2, 1, start_pt(i), 0, params);
    ml(i) = curve_tree_ml_2(Corrs, params, data_);
end
assert(ml(1) == ml(2));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;Fixed&lt;/em&gt; - stupid bug in &lt;code&gt;attachment/attach.m&lt;/code&gt; - was index offset was hard-coded to zero due to a refactoring mishap.&lt;/p&gt;

&lt;h2&gt;Optimal Branch point isn't correct&lt;/h2&gt;

&lt;p&gt;Example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;start_pt = [0 10 50 100 1000 5000];
ml = [];
for i = 1:2
    Corrs = attach(Corrs, 2, 1, start_pt(i), 0, params);
    ml(i) = curve_tree_ml_2(Corrs, params, data_);
end
assert(all(diff(ml) &amp;gt; 0);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;Solved&lt;/em&gt; - curves were reversed.&lt;/p&gt;

&lt;h1&gt;Handling reversed curves&lt;/h1&gt;

&lt;p&gt;Should add a &lt;code&gt;reversed&lt;/code&gt; flag, which reverses indices before building likelihood and prior.  currently, constructing the likelihood occurs during the &quot;backproject and re-index&quot; phase, in file &lt;code&gt;correspondence/corr_to_likelihood.m&lt;/code&gt;.  Should refactor likelihood construction into its own function, so we don't have to re-backproject when we don't need to.&lt;/p&gt;

&lt;p&gt;Let's review the data-flow so we can see more clearly where everything happens.&lt;/p&gt;

&lt;h1&gt;Overview: end-to-end curve construction&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;propose association and attachment

&lt;ul&gt;
&lt;li&gt;By sampling (no code yet)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;train/labels_from_ground_truth&lt;/code&gt; - propose from ground truth.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Output&lt;/strong&gt;: assoc {}&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Construct track

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;correspondence/make_correspondence&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Output&lt;/strong&gt;: Corrs {};  Corr.ml_2d&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Correspondence and triangulation

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;correspondence/build_full_correspondence.m&lt;/code&gt; - build from scratch&lt;/li&gt;
&lt;li&gt;&lt;code&gt;correspondence/merge_correspondence_2.m&lt;/code&gt; - merge two pieces&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Output&lt;/strong&gt;: &lt;code&gt;corr&lt;/code&gt;, &lt;code&gt;means&lt;/code&gt;, &lt;code&gt;precisions&lt;/code&gt;, &lt;code&gt;cov_error&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;backproject and estimate curvature

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;correspondence/corr_to_likelihood.m&lt;/code&gt; -&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Output&lt;/strong&gt;: &lt;code&gt;ll_{means, precisions, indices}&lt;/code&gt;, &lt;code&gt;curve_sm*&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;construct likelihood (flatten, sort, and reverse if needed)

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;correspondence/flatten_sort_and_reverse.m&lt;/code&gt; - (doesn't exist yet)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Output&lt;/strong&gt;: &lt;code&gt;ll_{means_flat, precisions_flat, indices_flat, S}&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;handle attachment recursively

&lt;ol&gt;
&lt;li&gt;compute conditional prior

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;attachment/att_set_start_index.m&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Output&lt;/strong&gt;: &lt;code&gt;start_index&lt;/code&gt;, &lt;code&gt;prior_K&lt;/code&gt;, &lt;code&gt;prior_indices&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;compute branch point posterior

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;attachment/att_set_branch_index.m&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Output&lt;/strong&gt;: &lt;code&gt;branch_index&lt;/code&gt;, &lt;code&gt;mu_b&lt;/code&gt;, &lt;code&gt;sigma_b&lt;/code&gt;, &lt;code&gt;branch_K&lt;/code&gt;, &lt;code&gt;branch_mu&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Compute (ML, argmax, etc)&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Consider renaming step 4.  backproject against rough triangulation; estimate curvature at each point; determine index set.  At this point, the order of points don't matter, because the index set hasn't been put to use.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Action: reverse curve&lt;/strong&gt; - detach?, rerun step 5, 6.1 &amp;amp; 6.2 on self, update branch point &amp;amp; rerun 6.2 for children.&lt;/p&gt;

&lt;h1&gt;Test: optimize branch point and start index&lt;/h1&gt;

&lt;p&gt;(TODO)&lt;/p&gt;

&lt;h1&gt;TODO&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;optimize test&lt;/li&gt;
&lt;li&gt;get attachment, reversal, and branch points from ground truth&lt;/li&gt;
&lt;li&gt;store &lt;code&gt;ml_2d&lt;/code&gt; with corr.  update on merge.  use during ml computation instead of data_&lt;/li&gt;
&lt;/ul&gt;

</description>
				<pubDate>Mon, 26 Aug 2013 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2013/08/26/work-log</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2013/08/26/work-log</guid>
			</item>
		
			<item>
				<title>Work Log - Attachment ML Math (ctd); Implementing Attach()/Detach()</title>
				<description>

&lt;div class=&quot;meta-info&quot;&gt;
&lt;table&gt;
    &lt;tr&gt;
        &lt;th&gt;Project&lt;/th&gt;
        &lt;td&gt;&lt;a href=&quot;/ksimek/research/projects/tulips.html&quot;&gt;Tulips&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Subproject&lt;/th&gt;
        &lt;td&gt;Data Association v3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Working path&lt;/th&gt;
        &lt;td&gt;projects/&amp;#8203;tulips/&amp;#8203;trunk/&amp;#8203;src/&amp;#8203;matlab/&amp;#8203;data_association_3&lt;/td&gt;
    &lt;/tr&gt;

    &lt;tr&gt;
        &lt;th&gt;SVN Revision&lt;/th&gt;
        &lt;td&gt;15169&lt;/td&gt;
    &lt;/tr&gt;


&lt;/table&gt;

    Unless otherwise noted, all filesystem paths are relative to the &quot;Working path&quot; named above.
&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Note new working path: &lt;code&gt;data_association_3&lt;/code&gt;&lt;/strong&gt;&lt;br/&gt;
Fixed corrupt svn working copy.&lt;/p&gt;

&lt;h1&gt;Computing \(\mu_b\) and \(\Sigma_b\)&lt;/h1&gt;

&lt;div&gt; Since \(S\) is usually singular, we can't invert it, so we need to tweak yesterday's equations.  In what follows, the precision matrix \(S\) is decomposed into \(s s^\top\), which will allow us to keep the covariance matrix symmetric. 

&lt;div&gt;
The updated forumula for \(\mu_b\) is:&lt;/div&gt;
\[
    \begin{align}
    \mu_b &amp;= K_*^\top \left(K_{\mathcal{MB}} + S^{-1}\right)^{-1} y_{MB}  \\
    \tag{1}
          &amp;= K_*^\top s^\top \left(s K_{\mathcal{MB}} s^\top + I\right)^{-1} s y_{MB}  \\
    \end{align}
\]

The formula for \(\Sigma_b\) is:

\[
    \Sigma_b = K_b - K_*^\top s^\top \left(s K_{\mathcal{MB}} s^\top + I\right)^{-1} s K_*
\]

Recall that \(K_b\) is the prior covariance of the branch point.
&lt;/div&gt;


&lt;br /&gt;


&lt;h2&gt;Predictive covariance question&lt;/h2&gt;

&lt;div&gt;
&lt;p&gt;
I realized during implementation that it isn't clear what the predictive covariance, \(K_*\), should be.  I know it's the covariance between the true branch point and the observed points in the markov blanket, but the observed points have associated view-indices, while the branch point does not.  After some thought, I realized that the covariance arising from view-indices is essentially *likelihood* variance in this context (i.e. imaging noise), and according to Williams and Rasmussen, these parts of the likelihood should be omitted when computing the covariance between data and true unobserved points.  (See equation (2.21), notice that off-diagonal elements don't include the noise variance, \(\sigma_n I\)).
&lt;/p&gt;
&lt;p&gt;
To accomodate the use-case where you want to compute the covariance while ignoring view-index, I tweaked `kernel/get_model_kernel`; now, if you pass-in a `model_index` of zero, it returns a two-parameter no-perturb kernel where only spacial-indices are received.
&lt;/p&gt;
&lt;/div&gt;


&lt;h2&gt;&lt;code&gt;ll_indices_flat&lt;/code&gt; vs. &lt;code&gt;prior_indices&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;There's some ambiguity in these two fields of a curve-track.  The difference is simply that in &lt;code&gt;ll_indices_flat&lt;/code&gt;, indices &lt;em&gt;always&lt;/em&gt; start at zero, whereas in &lt;code&gt;prior_indices&lt;/code&gt; the offset &lt;code&gt;start_index&lt;/code&gt; is added to all values.  In practice, there are rules for where these two fields should be used:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;when passing indices to a kernel, always use &lt;code&gt;prior_indices&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;When dealing with geometry (e.g. referring to a point along a curve), always use ll_indices.  That way, the position of the referred point is unchanged if &lt;code&gt;start_index&lt;/code&gt; ever changes.&lt;/li&gt;
&lt;/ul&gt;


&lt;h1&gt;Task progress&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Finish &lt;code&gt;attachment/att_set_branch_index.m&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;rough test of attachment stuff - (does it parse? does it run?)

&lt;ul&gt;
&lt;li&gt;It runs, but with buggy output for \(\mu_b\) and \(\Sigma_b\).&lt;/li&gt;
&lt;li&gt;Found bug - incorrect re-indexing (xxyyzz to xyzxyz)&lt;/li&gt;
&lt;li&gt;Now giving apparently good results.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Implement efficient tree ML&lt;/li&gt;
&lt;li&gt;implement naive ML&lt;/li&gt;
&lt;li&gt;write tests

&lt;ol&gt;
&lt;li&gt;compare against &lt;code&gt;curve_ml5.m&lt;/code&gt; for independent curves&lt;/li&gt;
&lt;li&gt;compare against naive ML using full-covariance-matrix.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;invalidate children after calling attach/detach&lt;/li&gt;
&lt;/ul&gt;


&lt;h1&gt;Misc notes&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;should place a condition on \(\Sigma_b\).  If it's variance is too high, need to expand markov-blanket.&lt;/li&gt;
&lt;li&gt;Add &lt;code&gt;model_type to params&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Have &quot;make_correspondence&quot; initialize start_index, parent_index, branch_index.&lt;/li&gt;
&lt;/ul&gt;


&lt;h1&gt;chain of affects&lt;/h1&gt;

&lt;p&gt;How are children affected when properties of the parent change?&lt;/p&gt;

&lt;div&gt;
&lt;table border=&quot;1&quot;&gt;
&lt;tr&gt;
&lt;th width=&quot;33%&quot;&gt;parent property&lt;/th&gt;
&lt;th width=&quot;33%&quot;&gt;self affects&lt;/th&gt;
&lt;th&gt;child affects&lt;/th&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Assoc/Correspondence&lt;/td&gt;
&lt;td&gt;start_index (and inherited)&lt;/td&gt;
&lt;td&gt;Branch_index (and inherited.  easy to re-estimate deterministically), marginal likelihood, (not start index)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Start index&lt;/td&gt;
&lt;td&gt;prior_K, prior_indices, ML&lt;/td&gt;
&lt;td&gt;\(\mu_b\)*, \(\Sigma_b\)*, ML*&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Branch index&lt;/td&gt;
&lt;td&gt;\(\mu_b\), \(\Sigma_b\), &lt;/td&gt;
&lt;td&gt;none.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;


&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;/table&gt;
* Updating these might not be necessary
&lt;/div&gt;


&lt;h1&gt;TODO&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Implement Tree ML (2 ways, &quot;naive&quot; and &quot;fast&quot;)&lt;/li&gt;
&lt;li&gt;Test&lt;/li&gt;
&lt;li&gt;Get attachment for ground truth&lt;/li&gt;
&lt;li&gt;Re-train using attachment&lt;/li&gt;
&lt;/ul&gt;

</description>
				<pubDate>Thu, 22 Aug 2013 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2013/08/22/work-log</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2013/08/22/work-log</guid>
			</item>
		
			<item>
				<title>Work Log - Clique-tree math (ctd)</title>
				<description>

&lt;div class=&quot;meta-info&quot;&gt;
&lt;table&gt;
    &lt;tr&gt;
        &lt;th&gt;Project&lt;/th&gt;
        &lt;td&gt;&lt;a href=&quot;/ksimek/research/projects/tulips.html&quot;&gt;Tulips&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Subproject&lt;/th&gt;
        &lt;td&gt;Data Association v2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Working path&lt;/th&gt;
        &lt;td&gt;projects/&amp;#8203;tulips/&amp;#8203;trunk/&amp;#8203;src/&amp;#8203;matlab/&amp;#8203;data_association_2&lt;/td&gt;
    &lt;/tr&gt;


&lt;/table&gt;

    Unless otherwise noted, all filesystem paths are relative to the &quot;Working path&quot; named above.
&lt;/div&gt;


&lt;h1&gt;Conditional clique node&lt;/h1&gt;

&lt;p&gt;Continuing from yesterday, let's convert our conditional gaussian distribution to a gaussian function over \(x_c\) and \(\mu_b\).&lt;/p&gt;

&lt;p&gt;Let \(II\) represent a stack of identity matrices:&lt;/p&gt;

&lt;div&gt;
\[
II = \left( \begin{array}{c} I\\I\\...\\I \end{array}\right)
\]

The exponential expression for the conditional Gaussian distribution is

    \[
    -\frac{1}{2} (x_C - II \mu_b)^\top \left( \Sigma_C + II \Sigma_b II^\top \right )^{-1}(x_C - II \mu_b)
\]

Let's convert this to a linear function over \((x_C, \mu_b)\), instead of just \(x_C\):
        
    \[
    -\frac{1}{2} \left(\begin{array}{c}x_C \\ \mu_b \end{array} \right )^\top \left ( \begin{array}{cc}I &amp; -II\end{array}\right )^\top \left( \Sigma_C + II \Sigma_b II^\top \right )^{-1}\left ( \begin{array}{cc}I &amp; -II\end{array}\right )\left(\begin{array}{c}x_C \\ \mu_b \end{array}\right )
\]
&lt;/div&gt;


&lt;p&gt;Recall that \(\mu_b\) is a linear function of the data-points in the Markov-blanket, \(y_\mathcal{MB}\) (reproduced from &lt;a href=&quot;/ksimek/research/2013/08/19/work-log/&quot;&gt;yesterday's post&lt;/a&gt;)&lt;/p&gt;

&lt;div&gt;
\[
    \begin{align}
    \mu_b &amp;= K_*^\top \left(K_{\mathcal{MB}} + S^{-1}\right)^{-1} y_{MB}  \\
        &amp;= K_*^\top K^{-1}_{y_\mathcal{MB}}  y_\mathcal{MB}  \\
    \end{align}
\]

Rewriting the expression as a function of \((x_C, y_\mathcal{MB})\):

    \[
    \begin{align}
     &amp;=
    -\frac{1}{2} \left(\begin{array}{c}x_C \\ K_* K^{-1}_{y_\mathcal{MB}}  y_\mathcal{MB} \end{array} \right )^\top
    \left ( \begin{array}{cc}I &amp; -II\end{array}\right )^\top 
    \left( \Sigma_C + II \Sigma_b II^\top \right )^{-1}
    \left ( \begin{array}{cc}I &amp; -II\end{array}\right )
    \left(\begin{array}{c}x_C \\ K_* K^{-1}_{y_\mathcal{MB}}  y_\mathcal{MB} \end{array}\right )
    \\
     &amp;=
    -\frac{1}{2} \left(\begin{array}{c}x_C \\   y_\mathcal{MB} \end{array} \right )^\top
    \left ( \begin{array}{cc}I &amp; -II K_* K^{-1}_{y_\mathcal{MB}} \end{array}\right )^\top 
    \left( \Sigma_C + II \Sigma_b II^\top \right )^{-1}
    \left ( \begin{array}{cc}I &amp; -II K_* K^{-1}_{y_\mathcal{MB}}\end{array}\right )
    \left(\begin{array}{c}x_C \\ y_\mathcal{MB} \end{array}\right )
    \end{align}
\]

And expanding \(\Sigma_b\):
 
\[
    \begin{align}
    \Sigma_b &amp;= K_b - K_*^\top \left(K_{\mathcal{MB}} + S^{-1}\right)^{-1} K_* \\
             &amp;= K_b - K_*^\top K^{-1}_{y_\mathcal{MB}} K_*

    \end{align}
\]

The final expression is:

    \[
    \begin{align}
     &amp;=
    -\frac{1}{2} \left(\begin{array}{c}x_C \\   y_\mathcal{MB} \end{array} \right )^\top
    \left ( \begin{array}{cc}I &amp; -II K_* K^{-1}_{y_\mathcal{MB}} \end{array}\right )^\top 
    \left( \Sigma_C + II \left(K_b - K_*^\top K^{-1}_{y_\mathcal{MB}} K_* \right)  II^\top \right )^{-1}
    \left ( \begin{array}{cc}I &amp; -II K_* K^{-1}_{y_\mathcal{MB}}\end{array}\right )
    \left(\begin{array}{c}x_C \\ y_\mathcal{MB} \end{array}\right ) \\
     &amp;=
    -\frac{1}{2} \left(\begin{array}{c}x_C \\   y_\mathcal{MB} \end{array} \right )^\top
    \Lambda_{C \mid \mathcal{MB}}
    \left(\begin{array}{c}x_C \\ y_\mathcal{MB} \end{array}\right )
    \end{align}
\]

the normalization constant is:
    
\[
    Z = 
    (2 \pi)^\frac{k}{2} \left | \Sigma_C + II \left(K_b - K_*^\top K^{-1}_{y_\mathcal{MB}} K_* \right)  II^\top \right |^\frac{1}{2}
\]
&lt;/div&gt;


&lt;h2&gt;Test experiment&lt;/h2&gt;

&lt;p&gt;See  &lt;code&gt;exp_2013_08_21_clique_tree_test.m&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;sample N points for curve 1, \(C_1\)&lt;/li&gt;
&lt;li&gt;sample N points for curve 2, \(C_2\)&lt;/li&gt;
&lt;li&gt;offset curve 1: \(C_2 = C_2 + C_1(:,5)\)&lt;/li&gt;
&lt;li&gt;add noise to \(C_1\) and \(C_2\) to get data \(y_1\),\(y_2\)&lt;/li&gt;
&lt;li&gt;add noise to \(C_1\) and \(C_2\) to get data \(y_1\), \(y_2\).&lt;/li&gt;
&lt;li&gt;Construct full prior, \(\Sigma\) (see below for definition).&lt;/li&gt;
&lt;li&gt;Evaluate ML directly from \(p(y_1, y_2) = \mathcal{N}(0, (\Sigma + \sigm_n I))\).&lt;/li&gt;
&lt;li&gt;Construct ML decomposed: \(p(y_2 | y_1) p(y_1) \)&lt;/li&gt;
&lt;li&gt;(didn't implement) Construct clique tree using

&lt;ul&gt;
&lt;li&gt;Node 1: \((0, \Sigma_1)\)&lt;/li&gt;
&lt;li&gt;Node 2: \((0, inv(\Lambda_{C\mid \mathcal{MB}}))\)&lt;/li&gt;
&lt;li&gt;multiply by corresponding noise nodes.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;(didn't implement) Marginalize clique tree.  compare against result in 7.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;I originally thought the result from 8 was only an approximation (mainly because I hadn't originally written it out that way).  In fact, it's an exact computation, but it isn't very useful in this form, because deep trees still exhibit linear growth of the condition-set, meaning cubic growth in running time.  In practice, we can replace \(y_1\) to the data markov-blanket, \(y_{1,\mathcal{MB}}\).  The data markov-blanket is naturally larger than the prior m.b., which is a single point, but if the noise is low relative to the point-spacing, the data m.b. should still be relatively small.  Thus, we can approximate the ML with a decomposed form that avoids cubic growth.&lt;/p&gt;

&lt;p&gt;The alternative is to use the clique tree from step 9., but the former is simpler to implement, because we don't have to use the crazy linear form we developed above, and we don't have to do any message-passing.  We just need \(\Sigma_b\) and \(\mu_b\).&lt;/p&gt;

&lt;h2&gt;Computing max posterior with attachments&lt;/h2&gt;

&lt;p&gt;Since this operation won't be run during production, we can just implement it the naive way.&lt;/p&gt;

&lt;p&gt;But if we wanted a fast version, we could to a forward-pass approximation, i.e. find the max for the root curve, and then pass that as data to the child curves.&lt;/p&gt;

&lt;p&gt;A full forward-backward algorithm probably wouldn't be too hard, but probably not worth the trouble at the moment.&lt;/p&gt;

&lt;h1&gt;Build Tasks&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;apply attacment to trackset&lt;/li&gt;
&lt;li&gt;guess branch spacing&lt;/li&gt;
&lt;li&gt;construct independent cliques, given branch spacing.&lt;/li&gt;
&lt;li&gt;Guess branch point&lt;/li&gt;
&lt;li&gt;construct markov-blanket, \(\mathcal{MB}\).&lt;/li&gt;
&lt;li&gt;construct \(sigma_b\) and \(\mu_b\) from parent \(\mathcal{MB}\).&lt;/li&gt;
&lt;/ol&gt;


&lt;h1&gt;TODO &amp;amp; In-progress&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;attachment/attach.m&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;attachment/att_set_start_index.m&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;attachment/att_set_branch_index.m&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Next

&lt;ul&gt;
&lt;li&gt;pre-flatten and pre_sort ll_*.

&lt;ul&gt;
&lt;li&gt;remove all calls to flatten_inputs&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;precompute likelihood covariance matrix.

&lt;ul&gt;
&lt;li&gt;remove logic from &lt;code&gt;curve_ml5.m&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;compute full branching ML using cached values.

&lt;ul&gt;
&lt;li&gt;identify connected components&lt;/li&gt;
&lt;li&gt;topological sort&lt;/li&gt;
&lt;li&gt;root-to-leaf evaluation over each CC.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;

</description>
				<pubDate>Wed, 21 Aug 2013 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2013/08/21/work-log</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2013/08/21/work-log</guid>
			</item>
		
			<item>
				<title>cleanup</title>
				<description>

&lt;div class=&quot;meta-info&quot;&gt;
&lt;table&gt;
    &lt;tr&gt;
        &lt;th&gt;Project&lt;/th&gt;
        &lt;td&gt;&lt;a href=&quot;/ksimek/research/projects/tulips.html&quot;&gt;Tulips&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Subproject&lt;/th&gt;
        &lt;td&gt;Data Association v3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Working path&lt;/th&gt;
        &lt;td&gt;projects/&amp;#8203;tulips/&amp;#8203;trunk/&amp;#8203;src/&amp;#8203;matlab/&amp;#8203;data_association_3&lt;/td&gt;
    &lt;/tr&gt;


&lt;/table&gt;

    Unless otherwise noted, all filesystem paths are relative to the &quot;Working path&quot; named above.
&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Note new working path: &lt;code&gt;data_association_3&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Started realizing that there are a huge number of dead/obsolete files in the &lt;code&gt;data_association_2&lt;/code&gt; directory.  It's time to migrate to a clean code-base, &lt;code&gt;data_association_3&lt;/code&gt;.&lt;/p&gt;

&lt;h1&gt;Reorganization&lt;/h1&gt;

&lt;h2&gt;Setups&lt;/h2&gt;

&lt;p&gt;Realized that &lt;code&gt;tmp_setup_workspace.m&lt;/code&gt; is very valuable, but will probably need to change and evolve over time.  Created new directory called &lt;code&gt;setups/&lt;/code&gt;, where setup scripts will be stored, organized by date.  Related files that the setup scrip needs will be stored in the same directory, with a similar name to the script itself.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;tmp_setup_workspace.m&lt;/code&gt; is now in &lt;code&gt;setups/setup_workspace_2013_08_21.m&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Format is: &lt;code&gt;setup_&amp;lt;type&amp;gt;_&amp;lt;date&amp;gt;.m&lt;/code&gt;.  Currently only type is &quot;workspace&quot;.
Related &quot;load&quot; files have format: &lt;code&gt;setup_&amp;lt;type&amp;gt;_&amp;lt;date&amp;gt;.mat&lt;/code&gt;   or if multiple files, &lt;code&gt;setup_&amp;lt;type&amp;gt;_&amp;lt;date&amp;gt;.&amp;lt;N&amp;gt;.mat&lt;/code&gt;, where N is an increasing integer starting at 1.&lt;/p&gt;

&lt;h2&gt;Mex files&lt;/h2&gt;

&lt;p&gt;Propose creating a new file &lt;code&gt;compile_mex_scripts.m&lt;/code&gt;.  If called with no arguments, it will compile all scripts that are uncompiled.  Optional &quot;force_recompile&quot; parameter.&lt;/p&gt;

&lt;h1&gt;Misc Notes/Issues&lt;/h1&gt;

&lt;h2&gt;split_correspondence&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;split_correspondence.m&lt;/code&gt; is no longer available.  It became obsolete some time ago, around when we moved from &lt;code&gt;clean_correspondence.m&lt;/code&gt; to &lt;code&gt;corr_to_likelihood.m&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;When we return to end-to-end sampling, we'll need something like it.  Alternatively,  maybe full-rebuilding of the split curves is fast enough, now that we've mexed the bottlenecks?&lt;/p&gt;

&lt;h1&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;Not totally done, but we can at least run the workspace setup file.&lt;/p&gt;

&lt;p&gt;Will save the current workspace, re-open matlab, and see what issues arise as we continue to work toward the short-term goal of implementing branching-curve marginal likelihood.&lt;/p&gt;

&lt;p&gt;Workspace saved to &lt;code&gt;tmp/workspace_2013_08_21.mat&lt;/code&gt;.&lt;/p&gt;
</description>
				<pubDate>Wed, 21 Aug 2013 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2013/08/21/cleanup</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2013/08/21/cleanup</guid>
			</item>
		
			<item>
				<title>Work Log - Branching curve clique-tree</title>
				<description>

&lt;div class=&quot;meta-info&quot;&gt;
&lt;table&gt;
    &lt;tr&gt;
        &lt;th&gt;Project&lt;/th&gt;
        &lt;td&gt;&lt;a href=&quot;/ksimek/research/projects/tulips.html&quot;&gt;Tulips&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Subproject&lt;/th&gt;
        &lt;td&gt;Data Association v2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Working path&lt;/th&gt;
        &lt;td&gt;projects/&amp;#8203;tulips/&amp;#8203;trunk/&amp;#8203;src/&amp;#8203;matlab/&amp;#8203;data_association_2&lt;/td&gt;
    &lt;/tr&gt;


&lt;/table&gt;

    Unless otherwise noted, all filesystem paths are relative to the &quot;Working path&quot; named above.
&lt;/div&gt;


&lt;p&gt;Thinking about attachments.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Organize into connected components.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Reviewing ML code, with considerations to generalizing for attachments.&lt;/p&gt;

&lt;p&gt;Can we exploit the structure in the branching-prior covariance matrix to speed-up inversion in the marginal likelihood?  No obvious way.&lt;/p&gt;

&lt;p&gt;Why did we abandon the clique-tree method?  Because it wasn't clear that the perturb-models would be compatible with it.  Now, it seems like it might be, as long as we set the markov-order high enough.  More importantly, it might be &lt;em&gt;necessary&lt;/em&gt;, because after adding attachment, the covariance matrix is growing too large to allow direct evaluation.&lt;/p&gt;

&lt;p&gt;Construct clique tree per-track, conditioned on parent point.  In case of base-curves, the parent point is the prior.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;New fields&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;branch parent

&lt;ul&gt;
&lt;li&gt;curve index&lt;/li&gt;
&lt;li&gt;point index&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;branch distance

&lt;ul&gt;
&lt;li&gt;i.e. starting index of self&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;gaussian structure

&lt;ul&gt;
&lt;li&gt;in canonical form&lt;/li&gt;
&lt;li&gt;no position variance&lt;/li&gt;
&lt;li&gt;no branching variance&lt;/li&gt;
&lt;li&gt;yes branch distance&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;em&gt;Inferring branch distance&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The reconstructed lateral branch curves are usually have gaps of several millimeters from their parent branch.  Assigning an index of zero to the first point will almost certainly result in a worse marginal likelihood, because these gaps are not well-modelled.&lt;/p&gt;

&lt;p&gt;Instead, we should attempt to infer the branch distance(or better yet, try to marginalize over it).&lt;/p&gt;

&lt;p&gt;Spent some time trying to derive a &quot;fast update&quot; for covariance matrices for inferring branch distance.  In this scheme, the matrices are computed assuming branch distance is zero, and then a easily computed delta matrix is added to account for non-zero branch distance.&lt;/p&gt;

&lt;p&gt;After some work, it looks like the smoothing variance kernel is too complicated to permit such a method.  It's just easier to recompute the entire covariance matrix.&lt;/p&gt;

&lt;h2&gt;Constructing branching clique-tree&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Construct individual cliques trees, assuming zero position variance (but including branch distance).  Call this the &quot;raw prior.&quot;&lt;/li&gt;
&lt;li&gt;Given a branch-point-index, compute the markov-blanket of the data points on the parent.&lt;/li&gt;
&lt;li&gt;Given raw prior and markov-blanket, construct conditional clique  node from raw clique node.&lt;/li&gt;
&lt;li&gt;Given clique tree, multiply and marginalize from tips to root.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;All cliques will now be stored in track structure (currently named &lt;code&gt;Corrs&lt;/code&gt;).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;How to construct conditional prior?&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;\(\mathcal{MB}\) - indices of the parent curve markov blanket, centered at branch point.&lt;/li&gt;
&lt;li&gt;\(y_\mathcal{MB}\) - observations in the markov blanket&lt;/li&gt;
&lt;li&gt;\(x_b\) - branch point&lt;/li&gt;
&lt;li&gt;\(\Sigma_b\) - branch point predictive covariance, conditioned on markov blanket&lt;/li&gt;
&lt;li&gt;\(x_c\) - child curve points, relative to branch point.&lt;/li&gt;
&lt;li&gt;\(x_C\) - child curve points, relative to world origin&lt;/li&gt;
&lt;li&gt;\(N\) - number of points in child curve.&lt;/li&gt;
&lt;li&gt;\(\Sigma_c\) - curve predictive covariance, conditioned on branch point&lt;/li&gt;
&lt;li&gt;\(\Sigma_C\) - curve predictive covariance, conditioned on markov blanket&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;div&gt;
The branch point distribution is given by the GP predictive distribution:
    
\[
p(x_b | y_\mathcal{MB}) = \mathcal{N}(\mu_b, \Sigma_b) \]

where 

\[
\begin{align}
    \mu_b &amp;= K_* \left(K_{\mathcal{MB}} + S^{-1}\right)^{-1} y_{MB} \\
    \Sigma_b &amp;= K_b - K_*^\top \left(K_{\mathcal{MB}} + S^{-1}\right)^{-1} K_*

\end{align}
\]

Here, \(K_*\) is the kernel of the branch index vs. the markov blanket indices, \(k(t_\mathcal{MB}, t_b)\).
&lt;/div&gt;


&lt;p&gt;The conditional child curve distribution is&lt;/p&gt;

&lt;div&gt;
\[ p(x_C \mid x_b) = p(x_c) = \mathcal{N}(x_b, \Sigma_c) \]

Here, \(Sigma_c\) is the raw curve covariance, whatever it may be.
&lt;br /&gt;
The marginal over the child curve arises due to the linear combination of random variables \(x_c\) and \(x_b\):

\[
x_C = x_c + \left ( \begin{array}{c}I\\I\\ \ldots \\I \end{array}\right) x_b
\]

The corresponding distribution is:

\[
p(x_C | y_\mathcal{MB}) = \mathcal{N}(\mu_C, \Sigma_C)
\]

where

\[
\begin{align}
\mu_C &amp;= \left( \begin{array}{c}I\\I\\ \ldots \\I \end{array}\right) \mu_b \\
\Sigma_C &amp;= \Sigma_c + \left( \begin{array}{c}I\\I\\ \ldots \\I \end{array}\right) \Sigma_b \left ( I \; I \ldots I \right )
\end{align}
\]
&lt;/div&gt;



</description>
				<pubDate>Mon, 19 Aug 2013 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2013/08/19/work-log</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2013/08/19/work-log</guid>
			</item>
		
	</channel>
</rss>
