<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>KLS Research Blog</title>
		<description>Nothing to see here...</description>
		<link>http://vision.sista.arizona.edu/ksimek/research</link>
		<atom:link href="http://vision.sista.arizona.edu/ksimek/research/feed.xml" rel="self" type="application/rss+xml" />
		
			<item>
				<title>Deriving likelihood of camera parameters</title>
				<description>&lt;p&gt;It occurred to me that naively doing camera fitting causes strong correlations between camera pose and reconstruction position.  Originally, I planned on alternating between optimizing the conditional curve density \(p(x_i | y_i, c_i)\)  and the conditional camera density, \(p(c_i | y_i, x_i)\).  The problem here is that the optimal curve \(x_i\) for the current camera will be very close to the evidence \(y_i\), so optimizing the camera will only move the curve slightly.  We get into a situation where we move the camera slightly, which allows us to move the curve slightly, which allows us to move the curve slightly, etc. etc.  This is analogous to the problem in Gibbs sampling with strongly correlated variables, and like there, the solution is to integrate out one of the correlated variables.&lt;/p&gt;

&lt;p&gt;We should be optimizing \(p(c_i | Y)\) instead of \( p(c_i | x_i, Y)\).  For now, we&#39;ll assume the prior over \(c_i\) is flat, so this reduces to optimizing the likelihood function \(p(Y | c_i) \).  Let \(Y_- = y_{1:i-1}\) and let \(Y_+ = y_{i+1:n}\)&lt;/p&gt;

&lt;div&gt;
\[
  \begin{align}
    p(Y | c_i) &amp;= \int p(y_i | x_i, c_i) p(x_i | x_{i-1}, x_{i+1}) p(Y_- | x_{i-1}) p(Y_+ | x_{i+1}) p(x_{i-1}, x_{i+1}) dx_i dx_{i-1} dx_{i+1} \\
    &amp;\propto \int p(y_i | x_i, c_i) p(x_i | x_{i-1}, x_{i+1}) p(x_{i-1}, x_{i+1} | Y_-, Y_+) dx_i dx_{i-1} dx_{i+1} \\
    &amp;\approx\int p(y_i | x_i, c_i) p(x_i | x_{i-1}, x_{i+1}) p(x_{i-1}, x_{i+1}| Y)  dx_i dx_{i-1} dx_{i+1} \\
  \end{align}
\]
&lt;/div&gt;


&lt;p&gt;Below are the definitions of the terms above.&lt;/p&gt;

&lt;div&gt;
\[
\begin{align}
    p(x_{i-1}, x_{i+1} | Y) &amp;= \mathcal{N}(\mu_*, \Sigma_*) \\
    p(x_i | x_{i-1}, x_{i+1}) &amp;= \mathcal{N}(\mu_i, \Sigma_i) \\
    p(y_i | x_i, c_i) &amp;= \mathcal{N}(\mu_y, \Sigma_y) \\
    \mu_i &amp;= \mu_0 + A x_\pm \\
    x_\pm &amp;= \left ( \begin{array}{c} x_{i-1} \\ x_{i+1}\end{array} \right ) \\
    A &amp;= K_* K_{(i-1)(i+1)}^{-1}  \\
    \Sigma_i &amp;= K_i - A * K_*^\top \\
    \mu_y &amp;= d + J x_i \\
    d &amp;= \pi_c(\mu_i) - J \mu_i \\
\end{align}
\]
&lt;/div&gt;


&lt;p&gt;Here, \(\mu_0\) is the 3D prior mean, \(\pi_c(X)\) is the projection of 3D point \(X\),  \(J_c\) is the Jacobian of \(\pi_c\) centered at \(\mu_i\), \(\Sigma_*\) is the posterior covariance of \((x_{i-1}, x_{i+1})\), \(\Sigma_y\) is the likelihood covariance, and \(K_*\) is the prior cross covariance between \(x_i\) and \((x_{i-1}, x_{i+1})\).&lt;/p&gt;

&lt;p&gt;The integral above is a convolution that represents the sum of random variables.  We represent this sum below, where \(\epsilon_M \sim \mathcal{N}(0, M) \).&lt;/p&gt;

&lt;div&gt;
\[
  \begin{align}
    Y | c_i &amp;= \mu_y + \epsilon_y \\
            &amp;= d + J x_i + \epsilon_y \\
            &amp;= (\pi_c(\mu_i) - J \mu_i) + J (\mu_i + \epsilon_i ) + \epsilon_y \\
            &amp;= \pi_c(\mu_i) + J\epsilon_i + \epsilon_y \\
            &amp;= \mathcal{N} \left (\pi_c(\mu_i), J \Sigma_i J^\top + \Sigma_y \right ) \\
  \end{align}
\]
&lt;/div&gt;


&lt;p&gt;Both the covariance and prior depend on the camera (because the camera determines \(\Sigma_y\)), but if we assume the covariance is nearly isotropic, maximizing the expression above is equivalent to minimizing the norm of the residuals, \(| Y - \pi_c(\mu_i) |\).&lt;/p&gt;

&lt;p&gt;Recall that we never explicitly have an expression for the data Gaussian, so Y isn&#39;t known.  We could derive this from the posterior and the prior, but a simple approximation is to just use the posterior mean, under the weak assumption that the likelihood is much more peaked than the prior.  The optimization procedure is then:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Find the maximum posterior of the \(x_{i+1}\), \(x_i\) and \(x_{i-1}\) (from Kalman smoother step).&lt;/li&gt;
&lt;li&gt;Predict the current curve \(x_i\), given the only the adjacent curves.&lt;/li&gt;
&lt;li&gt;Find the camera that minimizes the residual between the maximum posterior and the predicted curve using nonlinear least squares (derived in yesterday&#39;s post).&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;In practice, isotropism isn&#39;t necessarily a good assumption,  so we can transform the residuals by the square-root inverse covariance before evaluating the error.  The square root and inverse operations will get expensive if performed at each iteration, so we can either only update it every Nth iteration, but my intuitions says the isotropic assumption should be good enough.  It would be nice to have a better argument for this.&lt;/p&gt;
</description>
				<pubDate>Sat, 07 Mar 2015 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2015/03/07/reference</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2015/03/07/reference</guid>
			</item>
		
			<item>
				<title>Camera refinement</title>
				<description>&lt;p&gt;To implement efficient camera refinement, I need to derive the Jacobian of the residial vector w.r.t. camera parameters.&lt;/p&gt;

&lt;p&gt;The parameterization of camera orientation deserves special discussion.  We prefer a parameterization that is free of constraints, so quaternions and rotation matrices aren&#39;t an option, leaving euler angles or an axis/angle vector. Both parameterizations have singularities, but we can avoid them by centering the parameterization at the camera&#39;s current orientation.  If we don&#39;t expect to drift too far from the current orientation, this should be okay; otherwise we can reparameterize after every step.  We follow Hartley and Zisserman&#39;s approach and use axis-angle parameterization.  For all other parameters, we will use no transformation.&lt;/p&gt;

&lt;p&gt;Let the vector \(\mathbf{t}_r\) represent a rotation of angle \(\|\mathbf{r}_r\|\) around axis \(\hat{\mathbf{t}}_r\), and let \(R_{\mathbf{t}_r}\) be the corresponding rotation matrix.  Let \(K\) be the intrinsic matrix, and let \(\mathbf{t}_0\) be the translation vector.&lt;/p&gt;

&lt;p&gt;The transformation of a point from from world coordinates to homogeneous image coordinates is using the camera \(P\)&lt;/p&gt;

&lt;div&gt;
\[
    \mathbf{x}_h(P) = K \, R_{\mathbf{t}_r} , R \, (\mathbf{X} - \mathbf{t}_0) .
  \]
&lt;/div&gt;


&lt;p&gt;We seek the Jacobian of this transformation centered on the current camera, \(P\):&lt;/p&gt;

&lt;div&gt;
\[
    \begin{align}
    J_h(P) &amp;= \frac{\partial x_h(P)}{\partial (f_x, f_y, s, x_0, y_0, \mathbf{t}_r, \mathbf{t}_0) } = \left ( J_K J_{\mathbf{t}_r} J_{\mathbf{t}_0} \right) \text{ , where} \\
      J_K &amp;= \frac{\partial x_h(P)}{\partial (f_x, f_y, s, x_0, y_0 ) } \\
      J_{\mathbf{t}_r} &amp;= \frac{\partial x_h(P)}{\partial (\mathbf{t}_r, \mathbf{t}_0) } \\
      J_{\mathbf{t}_0} &amp;= \frac{\partial x_h(P)}{\partial (\mathbf{t}_0) }
    \end{align}
  \]
&lt;/div&gt;


&lt;h2&gt;Deriving \(J_{\mathbf{t}_r}\)&lt;/h2&gt;

&lt;p&gt;When centered at the current camera, the rotation vector is zero, \(\mathbf{t}_r = (0,0,0)\).  For small \(\mathbf{t}_r\),  the rotation matrix is approximated by \( R_{\mathbf{t}_r} = I + [\mathbf{t}_r]_\times \).  The Jacobian of rotation \( R_{\mathbf{t}_r} \mathbf{X}\)  is then \( -[\mathbf{X}]_\times \), and the jacobian of \(x_h\) is&lt;/p&gt;

&lt;div&gt;
\[
    J_{\mathbf{t}_r} = -K [\mathbf{X}_c]_\times
  \]
&lt;/div&gt;


&lt;p&gt;where  \(\mathbf{X}_c = R (\mathbf{X} - \mathbf{t}_0)\) is the point in camera coordinates.&lt;/p&gt;

&lt;h2&gt;Deriving \(J_{\mathbf{t}_0}\) and \(J_K\)&lt;/h2&gt;

&lt;p&gt;The other derivatives are straightforward to derive.&lt;/p&gt;

&lt;p&gt;The Jacobian w.r.t. translation is:&lt;/p&gt;

&lt;div&gt;
\[
    J_{\mathbf{t}_0} = -K R 
\]
&lt;/div&gt;


&lt;p&gt;The Jacobian w.r.t. intrinsic parameters is&lt;/p&gt;

&lt;div&gt;
\[
    J_K = \frac{\partial x_h}{\partial (f_x, f_y, s, x_0, y_0 ) } = \left ( \begin{array}{ccccc}
        X_{c,1} &amp; 0 &amp; X_{c,2} &amp; X_{c,3} &amp; 0 \\
        0 &amp; X_{c,2} &amp; 0 &amp; 0 &amp; X_{c,3}  \\
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 0
        \end{array}\right )
  \]
&lt;/div&gt;


&lt;h2&gt;Jacobian of residuals&lt;/h2&gt;

&lt;p&gt;We&#39;ve derived the jacobian of the transformation from world to homogeneous image coordinates w.r.t. each camera parameter.  To get the Jacobian of the residuals, it remains to transform to nonhomogeneous screen coordinates.&lt;/p&gt;

&lt;div&gt;
\[
    \mathbf{x} = (x_{h,1} / x_{h,3}, x_{h,2} / x_{h,3})
  \]
&lt;/div&gt;


&lt;p&gt;The Jacobian of this is&lt;/p&gt;

&lt;div&gt;
\[
\begin{align}
    J_\mathbf{x}(\mathbf{x_h}) &amp;= 
    \left ( 
        \begin{array}{ccc}
        \frac{1}{x_{h,3}} &amp; 0 &amp; - \frac{x_{h,1}}{x_{h,3}^2} \\
        0 &amp; \frac{1}{x_{h,3}} &amp; - \frac{x_{h,2}}{x_{h,3}^2}
        \end{array}
    \right ) \\
      &amp;=
      \frac{1}{x_{c,3}} 
    \left ( 
        \begin{array}{ccc}
        1 &amp; 0 &amp; - x_1 \\
        0 &amp; 1 &amp; - x_2
        \end{array}
    \right )
\end{align}
  \]
&lt;/div&gt;


&lt;p&gt;where \(x_{c,3}\) is the point&#39;s depth in camera coordinates, and \((x_1, x_2)\) is the point in nonhomogeneous image coordinates.&lt;/p&gt;

&lt;p&gt;The Jacobian of the residuals w.r.t. camera parameters is then&lt;/p&gt;

&lt;div&gt;
\[
\begin{align}
    J &amp;= J_\mathbf{x} J_h \\
      &amp;= J_\mathbf{x} [ J_K J_{\mathbf{t}_r} J_{\mathbf{t}_0} ]
\end{align}
\]
&lt;/div&gt;


&lt;p&gt;In what follows, we&#39;ll drop the \(J_\mathbf{x}\) and use \(J_K\) to refer to the Jacobian of the residuals (and likewise for \(J_{\mathbf{t}_r}\) and \(J_{\mathbf{t}_0}\)).  In other words, let \(J_K \leftarrow J_\mathbf{x} J_K\).&lt;/p&gt;

&lt;h2&gt;Full Jacobian with Shared Intrinsics&lt;/h2&gt;

&lt;p&gt;We now derive the Jacobian of all residuals in all views, where cameras share the same intrinsic parameters.&lt;/p&gt;

&lt;p&gt;Let \(J_{K_{ij}}\) be the Jacobian of residuals the \(j\)th point in view \(i\) w.r.t. intrinsic parameters, and let \(J_\mathbf{R_{i,j}}\) be the same w.r.t. rotation.  Let \(J_{\mathbf{t}_i}\) be the Jacobian w.r.t. translation in view \(i\).&lt;/p&gt;

&lt;p&gt;The full Jacobian  is a block matrix with form:&lt;/p&gt;

&lt;div&gt;
\[
J = 
\left (
    \begin{array}{c|c|c|c}
    \overbrace{
      \begin{array}{c}
        J_{K_{11}}  \\
        J_{K_{12}}  \\
        J_{K_{13}}  \\
           \cdots   \\
           \hline
        J_{K_{11}} \\
        J_{K_{12}} \\
        J_{K_{13}} \\
           \cdots \\
      \end{array}}^\text{All} &amp; 
    \overbrace{
      \begin{array}{cc}
         J_{R_{11}} &amp; J_{\mathbf{t}_1} \\
         J_{R_{12}} &amp; J_{\mathbf{t}_1} \\
         J_{R_{13}} &amp; J_{\mathbf{t}_1} \\
           \cdots &amp; \cdots  \\
           \hline
         \mathbf{0} &amp; \mathbf{0}       \\
         \mathbf{0} &amp; \mathbf{0}       \\
         \mathbf{0} &amp; \mathbf{0}       \\
           \cdots &amp; \cdots  \\
      \end{array}}^\text{Camera 1} &amp; 
      \overbrace{
      \begin{array}{cc}
          \mathbf{0} &amp; \mathbf{0}  \\
          \mathbf{0} &amp; \mathbf{0}  \\
          \mathbf{0} &amp; \mathbf{0}  \\
           \cdots &amp; \cdots  \\
           \hline
           J_{R_{11}} &amp; J_{\mathbf{t}_1}  \\
           J_{R_{12}} &amp; J_{\mathbf{t}_1}  \\
           J_{R_{13}} &amp; J_{\mathbf{t}_1}  \\
           \cdots &amp; \cdots 
       \end{array}}^\text{Camera 2} &amp;
      \begin{array}{cc}
       \mathbf{0} &amp; \cdots \\
       \mathbf{0} &amp; \cdots \\
       \mathbf{0} &amp; \cdots \\
           \cdots &amp; \cdots &amp; \cdots  \\
           \hline
       \mathbf{0} &amp; \cdots \\
       \mathbf{0} &amp; \cdots \\
       \mathbf{0} &amp; \cdots \\
           \cdots &amp; \cdots &amp; \cdots  \\
      \end{array}
    \end{array}
    \right )
\]
&lt;/div&gt;

</description>
				<pubDate>Fri, 06 Mar 2015 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2015/03/06/reference</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2015/03/06/reference</guid>
			</item>
		
			<item>
				<title>Work Log</title>
				<description>

&lt;div class=&quot;meta-info&quot;&gt;
&lt;table&gt;
    &lt;tr&gt;
        &lt;th&gt;Project&lt;/th&gt;
        &lt;td&gt;&lt;a href=&quot;/ksimek/research/projects/fire.html&quot;&gt;FIRE&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Subproject&lt;/th&gt;
        &lt;td&gt;Piecewise Linear Clustering (tests)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Working path&lt;/th&gt;
        &lt;td&gt;projects/&amp;#8203;fire/&amp;#8203;trunk/&amp;#8203;src/&amp;#8203;piecewise_linear/&amp;#8203;test&lt;/td&gt;
    &lt;/tr&gt;

    &lt;tr&gt;
        &lt;th&gt;SVN Revision&lt;/th&gt;
        &lt;td&gt;unknown (see text)&lt;/td&gt;
    &lt;/tr&gt;


&lt;/table&gt;

    Unless otherwise noted, all filesystem paths are relative to the &quot;Working path&quot; named above.
&lt;/div&gt;



</description>
				<pubDate>Thu, 26 Feb 2015 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2015/02/26/work-log</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2015/02/26/work-log</guid>
			</item>
		
			<item>
				<title>Work Log</title>
				<description>&lt;p&gt;Current search method is ridiculous, because it doesn&#39;t search in the directions of greatest variation.&lt;/p&gt;
</description>
				<pubDate>Wed, 25 Feb 2015 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2015/02/25/work-log</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2015/02/25/work-log</guid>
			</item>
		
			<item>
				<title>Projecting Prior and Backprojecting Posterior</title>
				<description>&lt;p&gt;We have existing machinery that lets us find the optimal (maximum a-posteriori) 2D curve tree, given a 2D Gaussian prior and a foreground probability map.&lt;/p&gt;

&lt;p&gt;We&#39;d like to use that to perform tracking when we know a 3D Gaussian distribution over the tree position, given previous evidence.&lt;/p&gt;

&lt;p&gt;Given: \(p(x_n | y_{1:n-1}) \)&lt;/p&gt;

&lt;p&gt;Estimate: \(p(x_n | y_{1:n}) \)&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Rotate/scale the 3D prior to be aligned with the image plane in pixel coordinates, i.e. u,v, and depth&lt;/li&gt;
&lt;li&gt;Estimate the marginal posterior in (u,v) coordinates using our warping code&lt;/li&gt;
&lt;li&gt;Estimate the depth terms of the posterior analytically&lt;/li&gt;
&lt;li&gt;Un-rotate and unscale the posterior into world space.&lt;/li&gt;
&lt;/ol&gt;


&lt;h2&gt;Step 1&lt;/h2&gt;

&lt;p&gt;Let \(p(x_n | y_1, ..., y_{n-1})\) be the prior of \(x_n)\), conditioned on all previous data.  At the current prior mean, \(\mu\), the projection function \(\pi(x)\) has Jacobian, \(J(\mu)\), which can be decomposed using RQ decomposition into \(J = (R 0) Q\), where Q is a rotation and R is square, upper triangular, and nonsingular.  This corresponds to rotating to face the camera, followed by scaling and/or shearing corresponding to foreshortening at the given depth.  The projection function can be then approximated using taylor series expansion:&lt;/p&gt;

&lt;div&gt;
\[
  \pi(x) = \pi(\mu) + (R \,| \,0) Q (x - \mu)
  \]
&lt;/div&gt;


&lt;p&gt;We can project the 3D prior to 2D using this transformation:&lt;/p&gt;

&lt;div&gt;
\[
  \mathcal{N}(\mu_{2D}, A^{-1}_{2D}) = \mathcal{N}(\pi(\mu_{3D}), J A_{3D}^{-1} J^\top)
  \]
&lt;/div&gt;


&lt;p&gt;Here \(A_{2D}\) and \(A_{3D}\) are precision matrices.&lt;/p&gt;

&lt;h2&gt;Step 3&lt;/h2&gt;

&lt;p&gt;For this section, let \(\mu = \mu_{2D}\) as derived above, let \(A = Q A_{3D} Q^\top\)  and let \(x&#39; = \pi(x)\) be the projected point.
Let \(p(y_n | x&#39;_n) = \mathcal{N}([R^{-1} \; 0]^\top \mu_L, \, [R^{-1} \;  0]^\top L^{-1} [R^{-1} \; 0] )\) be the image likelihood in 3D space, where \(\mu_L\) is \((x&#39;_1, x&#39;_2)^\top\), and \(L\) is a 2x2 precision matrix.  Let \(L&#39; = R^{-\top} L R^{-1}\) and \(\mu&#39;_L = R^{-1} \mu_L\) Running warping in step 2 gives us the hessian \(H\) of the marginal in-plane posterior.  This is the negative marginal posterior covariance for the (u,v) space.  Since the likelihood is uninformative in the dpeth direction, the deriving the full posterior covariance, (Z), is straightforward:&lt;/p&gt;

&lt;div&gt;
\begin{align}
      Z &amp;= A + \left( \begin{array}{cc}L&#39; &amp; 0 \\ 0 &amp; 0\end{array} \right)  \\
       &amp;= \left ( \begin{array}{cc} -H &amp; A_{1:2,3} \\ A_{3,1:2} &amp; A_{3,3} \end{array} \right )
\end{align}
&lt;/div&gt;


&lt;p&gt;Warping also gives us the marginal posterior mean \(\pi_x, \pi_y\), in the image space.  Let \(\pi&#39;_x = \pi(\mu) + R^{-1} \pi_x\) and \(\pi&#39;_y = R^{-1} \pi_y\) be the marginal posterior mean in camera space.  Deriving \(\pi&#39;_z\) takes a few steps  (primes are omitted below, all quantities are assumed to be in camera space)&lt;/p&gt;

&lt;div&gt;
\begin{align}
      \mathbf{\pi} &amp;= \left[ A + \left( \begin{array}{cc}L &amp; 0 \\ 0 &amp; 0\end{array} \right)\right]^{-1} \left [ A \mu + \left ( \begin{array}{c}L \mu_L \\ 0\end{array} \right ) \right ]  \\
      \mathbf{\pi} &amp;= Z^{-1} \left [ A \mu + \left ( \begin{array}{c}L \mu_L \\ 0\end{array} \right ) \right ]  \\
      Z \mathbf{\pi} &amp;= \left [ A \mu + \left ( \begin{array}{c}L \mu_L \\ 0\end{array} \right ) \right ]  \\
\end{align}
&lt;/div&gt;


&lt;p&gt;Let \(A = (\mathbf{a_1}  \mathbf{a_2} \mathbf{a_3} )^\top \) be the rows of A.   Omitting all but the third row gives:&lt;/p&gt;

&lt;div&gt;
\begin{align}
      z_{31} \pi_x + z_{32} \pi_y + z_{33} \pi_z &amp;= \mathbf{a_3^\top} \mu \\
        \pi_z &amp;= (\mathbf{a}^\top_3 \mu - \pi_x z_{31} - \pi_y z_{32}) / z_{33} 
\end{align}
&lt;/div&gt;


&lt;p&gt;Observing that \(z_{3i} = a_{3i}\),&lt;/p&gt;

&lt;div&gt;
\[
\begin{align}
        \pi_z &amp;= a_{33}^{-1} \left ( \mathbf{a}^\top_3 \left (\mu - \left ( \begin{array}{c} \pi_x \\ \pi_y \\ 0\end{array}\right)\right)\right)
\end{align}
\]
&lt;/div&gt;


&lt;p&gt;Written compactly:&lt;/p&gt;

&lt;div&gt;
\begin{align}
        \pi_z &amp;= \mu_3 + a_{33}^{-1} a_{3,1:2}(\mu_{1:2} - \pi_{1:2});
\end{align}
&lt;/div&gt;


&lt;p&gt;Testing in matlab:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A = rand(3,3); A = A * A&#39;;
L = rand(2,2); L = L * L&#39;;
mu = randn(3,1);
mu_L = randn(2,1);
pi = inv(A + [L zeros(2,1);0 0 0]) * (A * mu + [L*mu_L; 0]);
true_pi_z = pi(3);
test_pi_z = mu(3) + A(3,1:2)*(mu(1:2) - pi(1:2))/A(3,3);
err = test_pi_z - true_pi_z

err =

  -2.2204e-16
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It remains to rotate \(\mathbf{\pi}\) and \(A\)  by \(Q^\top\) to convert back to world space.&lt;/p&gt;
</description>
				<pubDate>Tue, 24 Feb 2015 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2015/02/24/reference</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2015/02/24/reference</guid>
			</item>
		
			<item>
				<title>Work Log</title>
				<description>&lt;p&gt;Today: continue refactor, pipeline building&lt;/p&gt;

&lt;h2&gt;Queue:&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Investigate 2d curve finding bug&lt;/li&gt;
&lt;li&gt;2D evaluation&lt;/li&gt;
&lt;li&gt;investigate &quot;zero covariance&quot; bug&lt;/li&gt;
&lt;li&gt;Extend to third view&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;Later&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Third view
&lt;strong&gt; Project 3D estimate into 2d
&lt;/strong&gt; grow/shrink curves
** add/break branches&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;Pipeline tasks&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;move logic from tmp_track_all to a function&lt;/li&gt;
&lt;li&gt;write pipeline script - all input/output in one directory&lt;/li&gt;
&lt;li&gt;write intermediate output at each stage
&lt;strong&gt; curve extraction
&lt;/strong&gt; branch estimation
&lt;strong&gt; warping
&lt;/strong&gt; likelihood estimate
&lt;strong&gt; pair-wise 3d reconstruction
&lt;/strong&gt; 3rd-view warping
&lt;strong&gt; likelihood estimate
&lt;/strong&gt; 3-view reconstruction
&lt;strong&gt; ...
&lt;/strong&gt; nth view warping
** n-th view reconstruction&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;For each view, keep likelihood estimate&lt;/p&gt;
</description>
				<pubDate>Fri, 20 Feb 2015 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2015/02/20/work-log</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2015/02/20/work-log</guid>
			</item>
		
			<item>
				<title>Work Log</title>
				<description>&lt;p&gt;Kalman smoother is tested and appears to be working well.  70% faster than direct method.&lt;/p&gt;

&lt;h2&gt;Queue&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Investigate &quot;zero covariance&quot; bug&lt;/li&gt;
&lt;li&gt;infer liklihood variance during reconstruction&lt;/li&gt;
&lt;li&gt;build pipeline, w/ intermediate results&lt;/li&gt;
&lt;li&gt;project 3D posterior into third view&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;Later&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;after projecting into third view:
&lt;strong&gt; Add-remove curves
&lt;/strong&gt; grow/shrink curves
** add/break branches&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Today: Cleaning up and building pipeline&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;move logic from tmp_track_all to a function&lt;/li&gt;
&lt;li&gt;write pipeline script - all input/output in one directory&lt;/li&gt;
&lt;li&gt;write intermediate output at each stage
&lt;strong&gt; curve extraction
&lt;/strong&gt; branch estimation
&lt;strong&gt; warping
&lt;/strong&gt; likelihood estimate
&lt;strong&gt; pair-wise 3d reconstruction
&lt;/strong&gt; 3rd-view warping
&lt;strong&gt; likelihood estimate
&lt;/strong&gt; 3-view reconstruction
&lt;strong&gt; ...
&lt;/strong&gt; nth view warping
** n-th view reconstruction&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;for each view, keep likelihood estimate&lt;/p&gt;
</description>
				<pubDate>Thu, 19 Feb 2015 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2015/02/19/work-log</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2015/02/19/work-log</guid>
			</item>
		
			<item>
				<title>Work Log</title>
				<description>

&lt;div class=&quot;meta-info&quot;&gt;
&lt;table&gt;
    &lt;tr&gt;
        &lt;th&gt;Project&lt;/th&gt;
        &lt;td&gt;&lt;a href=&quot;/ksimek/research/projects/fire.html&quot;&gt;FIRE&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Subproject&lt;/th&gt;
        &lt;td&gt;Piecewise Linear Clustering (tests)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;th&gt;Working path&lt;/th&gt;
        &lt;td&gt;projects/&amp;#8203;fire/&amp;#8203;trunk/&amp;#8203;src/&amp;#8203;piecewise_linear/&amp;#8203;test&lt;/td&gt;
    &lt;/tr&gt;

    &lt;tr&gt;
        &lt;th&gt;SVN Revision&lt;/th&gt;
        &lt;td&gt;unknown (see text)&lt;/td&gt;
    &lt;/tr&gt;


&lt;/table&gt;

    Unless otherwise noted, all filesystem paths are relative to the &quot;Working path&quot; named above.
&lt;/div&gt;


&lt;p&gt;Rerunning tracking to get perturbed curves.  Fixed bug in branch estimation causing suboptimal branches to be chosen. Added penalty to avoid branching in the middle of a child curve by penalizing large negative offsets.  Added parameter to adjust only the temperature of the local prior, leaving epipolar prior unchanged.  However, setting it too high causes initial tree to be far from the optimal tree, and the optimal is never found.  I&#39;d really like to get this solved, possibly using a deeper likelihood pyramid and a mixture model rather than product of experts.&lt;/p&gt;

&lt;p&gt;Debugged &quot;mirrored reconstruction&quot; issue -- it turned out to be a plotting mode in Matlab set wrong.  Calling &lt;code&gt;axis xy&lt;/code&gt; fixed it.&lt;/p&gt;

&lt;p&gt;MAP reconstruction now appears to be working:&lt;/p&gt;

&lt;p&gt;View 1&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ksimek/research/img/2015-02-18-map_reconstruction_full_prior.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;View 2&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ksimek/research/img/2015-02-18-maop2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Compare with maximum likelihood:&lt;/p&gt;

&lt;p&gt;View 1&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ksimek/research/img/2015-02-18-ml2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;View 2&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ksimek/research/img/2015-02-18-ml1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;If the perturbation sigma is very high, we get some drifting toward the camera&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ksimek/research/img/2015-02-18-pert_bad.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Another reconstruction with uncertainty bounds shown:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ksimek/research/img/2015-02-18-recons_w_uncertainty.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Testing kalman filter...&lt;/p&gt;

&lt;p&gt;OK Kalman filter works:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ksimek/research/img/2015-02-18-klaman_map_w_error.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Results are slightly different; I wonder if this is due to numerical error.  Kalman filter requires more intermediate matrix operations, which could allow error to drift in.  However, most operations involve smaller matrices, whose operations should be more stable.&lt;/p&gt;

&lt;p&gt;Next up: port kalman smoother so we can reconstruct more than just the last curve.&lt;/p&gt;

&lt;p&gt;Next Goal:  project and track in 3rd view.&lt;/p&gt;

&lt;p&gt;Later:  Add/remove curves.  Grow/shrink curves.&lt;/p&gt;

&lt;p&gt;Misc: Kalman filter; deep pyramid likelihood; mixture likelihood&lt;/p&gt;

&lt;h2&gt;Queue:&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Infer branch direction&lt;/li&gt;
&lt;li&gt;fix &quot;zero covariance&quot; bug&lt;/li&gt;
&lt;li&gt;infer noise variance from 2d data.&lt;/li&gt;
&lt;li&gt;implement kalman smoother&lt;/li&gt;
&lt;li&gt;build pipelline, w/ intermediate results output&lt;/li&gt;
&lt;/ul&gt;

</description>
				<pubDate>Wed, 18 Feb 2015 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2015/02/18/work-log</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2015/02/18/work-log</guid>
			</item>
		
			<item>
				<title>Work Log</title>
				<description>&lt;p&gt;Upon weaking the likelihood variance, we get this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ksimek/research/img/2015-02-17-weak_likelihood.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The bug is now clear: the independent curves (blue, red, yellow, green), are treated as attached at their root point.  This is due to how the offset prior is handled -- the same offset variance is added to all curves, even the cross-covariance between independent trees..  Modified to measure the hamming distance between curves.  If greater than zero, it receives the constant covariance.&lt;/p&gt;

&lt;p&gt;The maximum posterior after fixing:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ksimek/research/img/2015-02-17-fixed_const_cov.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Compare to maximum likelihood:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ksimek/research/img/2015-02-17-max_posterior.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Notice max posterior is smoother and blue, magenta and cyan curves are attached to the blue parent.  This is with zero temporal perturbation.&lt;/p&gt;

&lt;p&gt;This explains the bad results yesterday; we should now be able to expoeriment with fancier priors.&lt;/p&gt;

&lt;h2&gt;Adding temporal perturbation&lt;/h2&gt;

&lt;p&gt;At temporal scale = 9, we get drift toward camera:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ksimek/research/img/2015-02-17-temporal1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;At scale 10, 100, 1000, still bad.  It isn&#39;t until we get to scale=10,000 that we start to approach the results above (which used arbitrarilly large scale = 1e10)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ksimek/research/img/2015-02-17-temporal2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;One downside of using a nonstationary covariance is apparent here: large blue curve is reversed in direction; its top is forced to be near-stationary, while the tip can drift quite far.   During inference, we&#39;ll have to try both directions and keep the better.  A stationary covariance function won&#39;t have this problem, should consider.&lt;/p&gt;

&lt;p&gt;Wait -- setting all elements of perturbation covariance to zero should have no affect...  Found bug in constructing prior covariance matrix. Fixed.&lt;/p&gt;

&lt;p&gt;Now, adding the smallest amount of perturbation variance results in something like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ksimek/research/img/2015-02-17-smaller_perturb.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The problem here is fundamental to the cubic spline covariance: it can accellerate slowly but constantly until it&#39;s dramatically longer than its undeformed shape.  Possible solution: prevent perturbations toward camera.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Getting reversed triangulation.&lt;/p&gt;

&lt;p&gt;Due to reversed camera direction? (is negating camera valid here?)&lt;/p&gt;

&lt;p&gt;When testing new camera direction, lost curves from view2.  In rebuilding, realized our method for tracking curves was flawed -- it assumed optimization should start from the previous tree, but it should start at the mean of the perturbation prior distribution.&lt;/p&gt;

&lt;p&gt;Also, the pattern-search method seems to be failing to find a good second view.  Implemented quasi-newton method to test against the pattern-search method.&lt;/p&gt;

&lt;p&gt;To test:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;quasi-newton perturbation search&lt;/li&gt;
&lt;li&gt;new approach to initializing optimization&lt;/li&gt;
&lt;li&gt;reversed cameras&lt;/li&gt;
&lt;li&gt;maximum posterior curves (naive method)&lt;/li&gt;
&lt;li&gt;maximum posterior curves (kalman filter method)&lt;/li&gt;
&lt;/ul&gt;

</description>
				<pubDate>Tue, 17 Feb 2015 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2015/02/17/work-log</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2015/02/17/work-log</guid>
			</item>
		
			<item>
				<title>Work Log</title>
				<description>&lt;p&gt;Troubleshooting bad Kalman filter results.  Results project correctly, but appear behind camera&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;F (transition matrix) - seems OK&lt;/li&gt;
&lt;li&gt;Q (system noise) - seems OK (maybe high, could increase time-scale)&lt;/li&gt;
&lt;li&gt;H (observation matrix) - indentity plus 1e-8 precision noise&lt;/li&gt;
&lt;li&gt;R (sqrt observation precision) -  seems OK; projects correctly&lt;/li&gt;
&lt;li&gt;P0 (initial uncertainty) - prior uncertainty (OK)&lt;/li&gt;
&lt;li&gt;x (initial state) - prior mean (zero; OK)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Triangulation looks good, but posterior reconstruction is terrible.&lt;/p&gt;

&lt;p&gt;wrong coordinate frame?&lt;/p&gt;

&lt;p&gt;Spent hours troubleshooting math and tweaking parameters to understand the problem.  Softening the prior seems to give better results.  This doesn&#39;t tell us much, except that the data is doing its job correctly (which we already knew by observing the triangulation).  Struggling to find the right combination of prior parameters.&lt;/p&gt;

&lt;p&gt;Is the cubic prior simply not the right model?&lt;/p&gt;
</description>
				<pubDate>Mon, 16 Feb 2015 00:00:00 -0700</pubDate>
				<link>http://vision.sista.arizona.edu/ksimek/research/2015/02/16/work-log</link>
				<guid isPermaLink="true">http://vision.sista.arizona.edu/ksimek/research/2015/02/16/work-log</guid>
			</item>
		
	</channel>
</rss>
