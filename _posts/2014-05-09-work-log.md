---
layout: post
title: "FIRE Debugging cluster model"
description: ""
category: 'Work Log'
tags: []
meta: 
    "SVN Revision": "unknown (see text)"
---
{% include JB/setup %}
{% include research/fire_plm1_test_meta %}

Initial cluster estimation, something like k-means.


likelihood isn't monotonically increasing over time.

1. we aren't updating cluster weights
2. we're doing soft assignment

--

found bug: 


Run #1: initialize by K-means (part 1)
----------------------------------

**Description**: do k-means to initialize cluster assignments.   

**Details**:  

    Estimate A, B: no
    estimate epsilon: no
    shared observation model: yes
    continuity constraints: yes
    num clusters: 3
    observed dimensions: 7
    num observations: 150
    A estimation method: regression

**Revision**: 16767

**Method**: Build first cluster from all data.  Iteratively choose "bad" points under current model as prototypes for new cluster.  Then run k-means.

**Result**:  Converges after 15 iterations.
