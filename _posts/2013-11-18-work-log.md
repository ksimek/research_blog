---
layout: post
title: "Work Log"
description: ""
category: 'Work Log'
tags: []
---
{% include JB/setup %}
{% include research/tulips_da3_meta %}


Now that gradient is working, lets try using fminunc to optimize indices.

---

Getting nonsense results.  Looking into curve data.

...

Inspecting the data, it's clear that our method of linearly sampling points along the bezier curve is resulting in very jagged curves.  Example in dataset 8, curve 7:

![]({{site.baseurl}}/img/2013-11-18-dataset8_curve7_view9.png)

*view 9*



![]({{site.baseurl}}/img/2013-11-18-dataset8_curve7_view4.png)

*view 4*

It's not totally clear how best to resolve this.  Ideally, we would sample at a finer grain, but this caused big slow-downs for the longer curves.  Could use coarse-grain sampling for long curves, but some curves are long in some views and short in others, and nonuniform sampling breaks some assumptions we make in the library.  Furthermore, associations are unknown at the time of samplingz

It's possible 

It's possible the bad reconstruction we're seeing from this curve isn't due to bad correspondence, but a bad indexing estimation (a later stage of inference).  We see that although the correspondence places c7v9 toward the end of the 3D curve, our re-indexing code places it more spread out, but unevenly: the first point has index 4, while the subsequent points have indieces [21, 23, 27, 27].  We usually prevent large amounts of index-skipping during re-indexing, but possibly the second-pass refinement is destroying this.
