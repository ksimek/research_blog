---
layout: post
title: ""
description: ""
category: "Work Log"
tags: []
---
{% include JB/setup %}
{% include research/tulips_da2_meta %}

Background:  This weekend, I worked out the math for two new foreground models, which differ in how 3D perturbations between views are modelled.  The first assumes a single "mean" curve, and all observations are small 3D perturbations of it.  The second assumes the unobserved curve follows Brownian motion over time.

Also developed a new approach to evaluate marginal likelhoods thats much simpler, but need to confirm that it matches reference implementation.

**Goals:** 

* Implement both new foreground models, plus old one in new "kernel function" way.
* Implement new evaluation method and test against reference.
* Learn parameters for all three models (needs some ground truthing).


Implementing new models
----------------------
Worked on general framework for evaluating ML under general new model framework.

After some struggling with covariance degeneracies inherent in backprojection, I realized that the 3D marginal likelihood is naturally degenerate, because it isn't the true likelihood function (which is in 2D).  

I'm kicking myself for not remembering that I struggled with this exact problem 5 months ago.  At that time, I realized the better approach is to use Candidate's estimator, which is the ratio of the unnormalized posterior to the normalized posterior.  The unnormalized posterior comes from the prior and 2D likelIhood;  the normalized posterior is obtainable from the 3D likelihood and the prior.

This was already implemented in `curve_ml.m`, but was  O(n^3 ), so was all but abandoned in favor of the junction-tree method in `curve_ml2.m`, which is O(n).  

However, it's recently become clear that the candidate's estimator should be evaluated in \\(O(n)\\)  by exploiting the Markovian nature of the covariance matrix.  

It should be easy to try both, by simply swapping out covariance matrices with ones arising from the new covariance functions.  Tomorrow...


