---
layout: post
title: "Work Log"
description: ""
category: 'Work Log'
tags: []
---
{% include JB/setup %}

Resuming from yesterday's discussion about Markov sampling.  I was concerned about piecewise sampling of interpolated values with insufficient data being used.  After some thought, realized there's a better approach: construct blocks from input indices, not output indices.


Secondly: only use the markov approach when there's too much data to eat at once.  Those cases are also the ones with the least probability of poor-data issues.

---

Implemented (`curve_tree_ml_5.ml`), geting weird results.  Huge negative eigenvalues


symptom: 30 output indices, 1000 output indices
symptom: K has 26k elements!

This code is a mess, proving hard to debug.  I'm going to roll back to version 4, use ideas developed in v5 to implement Markov sampling.

---

Done.  No errors, but results aren't great.  Is it possible the markov blanket is wrong, or maybe we're misusing previous data?

...

I think I found it... wasn't conditioning on previous sampled values
