---
layout: post
title: "Work Log - Visualizing Results; New training method"
description: ""
category: 
tags: []
javascript: ["png_animation.js"]
---
{% include JB/setup %}
{% include research/tulips_da2_meta %}



Visualization
==============

I reconstructed the curves using the models I trained yesterday.  I was able to recover both the overall structure and track it's motion over 9 views.  For each of these results, use the slider below to change between each of the 9 views (the changes are subtle).

I'm still struggling with smoothing variance being too low, which causes curves to be too straight.  For all of these results, I manually changed `smoothing_variance` to be 0.1.

<script>
$(function(){
    var ind_urls = [
        "{{site.base_url}}/img/2013-08-08-ind-reconstruction_v1.png",
        "{{site.base_url}}/img/2013-08-08-ind-reconstruction_v2.png",
        "{{site.base_url}}/img/2013-08-08-ind-reconstruction_v3.png",
        "{{site.base_url}}/img/2013-08-08-ind-reconstruction_v4.png",
        "{{site.base_url}}/img/2013-08-08-ind-reconstruction_v5.png",
        "{{site.base_url}}/img/2013-08-08-ind-reconstruction_v6.png",
        "{{site.base_url}}/img/2013-08-08-ind-reconstruction_v7.png",
        "{{site.base_url}}/img/2013-08-08-ind-reconstruction_v8.png",
        "{{site.base_url}}/img/2013-08-08-ind-reconstruction_v9.png" 
        ]

    construct_animation($("#ind-reconstruction"), ind_urls);


    var ou_urls = [
        "{{site.base_url}}/img/2013-08-08-ou-reconstruction_v1.png",
        "{{site.base_url}}/img/2013-08-08-ou-reconstruction_v2.png",
        "{{site.base_url}}/img/2013-08-08-ou-reconstruction_v3.png",
        "{{site.base_url}}/img/2013-08-08-ou-reconstruction_v4.png",
        "{{site.base_url}}/img/2013-08-08-ou-reconstruction_v5.png",
        "{{site.base_url}}/img/2013-08-08-ou-reconstruction_v6.png",
        "{{site.base_url}}/img/2013-08-08-ou-reconstruction_v7.png",
        "{{site.base_url}}/img/2013-08-08-ou-reconstruction_v8.png",
        "{{site.base_url}}/img/2013-08-08-ou-reconstruction_v9.png" 
        ]

    construct_animation($("#ou-reconstruction"), ou_urls);

    var sqexp_urls = [
        "{{site.base_url}}/img/2013-08-08-sqexp-reconstruction_v1.png",
        "{{site.base_url}}/img/2013-08-08-sqexp-reconstruction_v2.png",
        "{{site.base_url}}/img/2013-08-08-sqexp-reconstruction_v3.png",
        "{{site.base_url}}/img/2013-08-08-sqexp-reconstruction_v4.png",
        "{{site.base_url}}/img/2013-08-08-sqexp-reconstruction_v5.png",
        "{{site.base_url}}/img/2013-08-08-sqexp-reconstruction_v6.png",
        "{{site.base_url}}/img/2013-08-08-sqexp-reconstruction_v7.png",
        "{{site.base_url}}/img/2013-08-08-sqexp-reconstruction_v8.png",
        "{{site.base_url}}/img/2013-08-08-sqexp-reconstruction_v9.png" 
        ]

    construct_animation($("#sqexp-reconstruction"), sqexp_urls);

});
</script>

Ind-Perturb Reconstruction
--------------------------

Below is the reconstruction for the independent-perturbation model.  The curves in each view are independently perturbed versions of central mean curves (not shown).

<div id="ind-reconstruction" style="width: 200px"> </div>

It is unclear how much of this motion is due to camera miscalibration, and how much is actual plant motion.  Nevertheless, this shows that we can use the perturbation models to simultaneously triangulate and track over time.

First, although each *view's* perturbation is independent of the others, the perturbation is correlated between nearby points within the same view.  In other words, perturbations don't violate the smoothness constraint.  

OU-Perturb Reconstruction
--------------------------

Next is the Ornstein-Ulenbeck perturbation model.  As opposed to the previous model, which modeled each view's perturbations as white noise, this model assumes Brownian motion over time.  Thus, we see a more naturally evolving time-series.

<div id="ou-reconstruction" style="width: 200px"> </div>
The OU process models brownian motion 

SQEXP-Perturb Reconstruction
------------------------------


Finally we have the squared-exponential perturbation model.  Now Brownian motion has been replaced by smooth motion.  I'm doubtful that this is a natural motion model for these plants.  The scale parameter is so low, I question whether it has any significant effect. 

<div id="sqexp-reconstruction" style="width: 200px"> </div>

New Training Method
======================

Need to determine why learned smoothing variance is so low.

Is it even valid to do max-likelihood to train the parameters of the covariance function?

Should we be training the smoothness parameter using the noiseless ground-truth data?

Two-pass Learning Procedure
------------------------------

1. First learn using noiseless data:
    1. Set rate-variance to fixed ~0.23 (see [yesterday's results]({{site.baseurl}}{% post_url 2013-08-07-work-log %}/#optimal-rate-variance))
    2. Estimate  position_variance by emperical distribution over all point positions in ground truth.
    3. Estimate smoothing_variance by maximum likelihood over ground truth.
2. Learn the noise variance for the no-perturb model.
    1. Find point correspondence between detected curves and corresponding ground truth curve.
    2. Compute variance between projected points and observed points.  This should maximize \\(p(D \mid \Theta_0) \\), where \\(\Theta_0\\) are the ground truth curves.
3. Learn perturb model parameters: noise_variance, perturb_{smoothing_variance, rate_varaince, position_variance}
    1. Use nonlinear optimization to maximize \\(p(D \mid \Theta_0) \\), as defined below.  Start with no-perturb parameters.  

<div>Let \(\theta_0\) be the ground-truth curve, and \(\{\theta_i\}\) be the set of all (unobserved) per-view curves \(\theta_i\). Let \(S_i\) be the virtual point precision matrices, assuming noise variance \(\sigma_n^2 = 1\).  The likelihood conditioned on the ground truth data \(p(D \mid \theta_0)\) is given by: </div>

<div> 
\begin{align}
p(D \mid \theta_0) &= \int_{\{\theta_i\}}  p(D_i, \{\theta_i\} \mid \theta_0)  d\{\theta_i\} \\
                   &= \int_{\{\theta_i\}} \prod_{i=1}^N p(\theta_i \mid \theta_0) p(D_i | \theta_i) d\{\theta_i\} \\
                   &= \prod_{i=1}^N \int_{\theta_i}  p(\theta_i \mid \theta_0) p(D_i | \theta_i) d\theta_i \\
                   &= \prod_{i=1}^N \int_{\theta_i}  \mathcal{N}(\theta_i; \theta_0, \Sigma_p) \mathcal{N}(D_i;  \theta_i, \sigma_n^2 S_i^{-1}) d\theta_i \\
                   &= \prod_{i=1}^N \int_{\theta_i}  \mathcal{N}(D_i ; \theta_0, \Sigma_p + \sigma_n^2 S_i^{-1})
\end{align}
</div>

<div> where  \(\Sigma_p\) is the perturbation variance. </div>

This should be an improvement over the current method, where we use only ground-truth labellings (not positions) and fit all parameters simultaneously.  This method assumed too much noise variance and not enough smoothness variance.

Since we actually know the noiseless curves, we should train to that, to avoid the confounding of smoothness variance and noise variance.  The ground truth curves are aso stronger sources of evidence, compared to the curves reconstructed from data.

TODO:
====

* reproject per-view reconstructions and overlay with original image.
* obtain & visualize unobserved "central curve"
* investigate the low smoothness variance.

Later TODO

* automatic curve reversing?
* add branching
