---
layout: post
title: "Debugging reconstruction anomalies"
description: ""
category: 'Work Log'
tags: []
---
{% include JB/setup %}

Continuing from yesterday.  Issue: strange reconstruction results after retraining.

Experiments
---------------

###Experiment #1

Add a small amount to the diagonal of the covariance and re-run reconstruction.  

Result:  Adding a moderate amount of covariance to the diagonal seems to fix the results but probably due to additional smoothing.

Adding 1.5 - makes results worse, bizarre jutting sections. This counterintuitive if the phenomenon is due to increasing noise variance.
Adding 2 - makes reconstruction look good.
Adding 10000 - reconstruction becomes straight sticks.

Discussion: analytically this is equivalent to multiplying the noise variance by a constant.  We already know that increasing noise variance solves the issue.  The question remains: why did our training algorithm prefer this? Also, why does decreasing noise variance force the reconstruction *away* from the data?  Strong contradiction between data and 

###Experiment #2

Plot likelihood (reference implementation) against noise variance.


Miscellaneous thoughts
----------------------

It kind of makes sense that iid noise would be zero, since the data we're drawing from is so smooth to begin with, and basically noiseless. Any errors arise from mistracing and are strongly correlated due to the smoothness of the Bezier curves.
