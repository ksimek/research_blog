---
layout: post
title: "Work Log"
description: ""
category: 'Work Log'
tags: []
meta: 
    "SVN Revision": "unknown (see text)"
---
{% include JB/setup %}

Finished training.  

  training_result = 

             final_const_variance: 1.1669e-04
      final_branch_const_variance: 1.7636e+03
            final_linear_variance: 1.4425e+03
          final_geodesic_variance: 195.4912
             final_geodesic_scale: 0.0065
                      final_noise: 0.0776

  training_result.initial

  ans = 

             const_variance: 831.7886
      branch_const_variance: 0.8552
            linear_variance: 0.1183
         euclidean_variance: 1.7367
            euclidean_scale: 1.0000
          geodesic_variance: 225.8247
             geodesic_scale: 1.0000
          epipolar_variance: 1.7367

These just don't make sense.  It allows for almost zero total translation, but lots of pert-curve translation (const_variance vs. branch_const_variance).  Linear variance allows for way too much scaling.  Geodesic variance seems sensible, but the (inverse-squared) geodesic scale is way too low... Basically this becomes a stand-in for const_variance.  Perhaps this is just a local minimum, we could try fixing const_variance to some large number and forcing geodesic variance to serve its intended purpose.

But the strangest thing is that 

I sampled some curves from this prior, and they are about what I'd expect: rotated and scaled with very little nonrigid deformation.   Below is a sample, along with the mean tree barely visible in the center:
  
![tree sample]({{site.baseurl}}/img/2015-01-11-tree_sample.png)



* Branches remain connected to tree, despite large per-curve offset variance.
* covariance matrix is singular

Ruled-out causes of error:

* badly implemented logmvnpdf.  Tested against reference implementation.

Training observations
-------------------
The simulated annealing algorithm is very sensitive to our local minima.  It can sometimes find a good result in less than 500 iterations, but other times it gets stuck after less than 100 and never improves.  I can probably tweak the annealing schedule to increase temperature earlier(is "reannealing" the right value to tweak?").  

Misc results
------------

![]({{site.baseurl}}/img/2015-01-11-tree_sample2.png)

  log-likleihood = -3.1787e+03
  training_result = 
  
             final_const_variance: 6.0197e+06
      final_branch_const_variance: 1.5774e-09
            final_linear_variance: 1.6250
          final_geodesic_variance: 238.6891
             final_geodesic_scale: 0.0039
             final_noise_variance: 0.1487

Not bad.  Lots of geodesic variance to account for distortion.  Why is const variance so high?  Linear variance seems a bit high, but reasonable.  

It might be a good idea to allow each branch to have a linear distortion relative to its initial point.

  log-likelihood = -2.5318e+03
  training_result = 
  
           final_const_variance: 2.3156e+09
    final_branch_const_variance: 2.4988
          final_linear_variance: 33.8221
        final_geodesic_variance: 1.7165e+03
           final_geodesic_scale: 0.0029
           final_noise_variance: 0.0880

